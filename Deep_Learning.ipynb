{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1: Introduction to Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию `function01`. Она должна иметь следующую сигнатуру:\n",
    "\n",
    "`def function01(tensor: torch.Tensor, count_over: str) -> torch.Tensor:`\n",
    "\n",
    "Если `count_over` равен `'columns'`, верните среднее тензора по колонкам. Если равен `'rows'`, то верните среднее по рядам. Гарантируется, что тензор будет матрицей (то есть будет иметь размерность 2).  \n",
    "Отправляемый файл должен иметь расширение **.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function01(tensor: torch.tensor, count_over: str) -> torch.Tensor:\n",
    "    if count_over == \"columns\":\n",
    "        return torch.mean(tensor, dim=0) # dim=0 means columns dim=1 means rows\n",
    "    else:\n",
    "        return torch.mean(tensor, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 5.])\n",
      "tensor([2.5000, 3.5000, 4.5000])\n"
     ]
    }
   ],
   "source": [
    "# let's create a tensor\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "\n",
    "# calculate mean over columns\n",
    "print(function01(t, \"columns\"))\n",
    "\n",
    "# calculate mean over rows\n",
    "print(function01(t, \"rows\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию `function02`. Функции на вход должен приходить датасет — тензор-матрица признаков объектов. Ваша функция должна создать тензор-вектор с весами (пусть они будут из равномерного распределения на отрезке от 0 до 1) и вернуть их для дальнейшего обучения линейной регрессии без свободного коэффициента. Сделайте эти веса типа `float32`, для них нужно будет в процессе обучения вычислять градиенты (воспользуйтесь `requires_grad`).\n",
    "\n",
    "Отправляемый файл должен иметь расширение **.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function02(tensor: torch.tensor) -> torch.Tensor:\n",
    "    # calculate the number of columns in the tensor\n",
    "    num_features = tensor.size(1)\n",
    "    \n",
    "    # creating the tensor of weights with the same shape as the input tensor и разрешаем вычисление градиента\n",
    "    weights = torch.rand(num_features, dtype=torch.float32, requires_grad=True)\n",
    "       \n",
    "    return weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию `function03`. Она должна принимать тензор-матрицу с объектами и тензор-вектор с правильными ответами, будем решать задачу регрессии: `def function03(x: torch.Tensor, y: torch.Tensor):`\n",
    "\n",
    "Создайте внутри функции веса для линейной регрессии (без свободного коэффициента), можете воспользоваться функцией из предыдущего степа. С помощью градиентного спуска подберите оптимальные веса для входных данных (используйте длину шага около `1e-2`). Верните тензор-вектор с оптимальными весами из функции. Ваши обученные веса должны давать **MSE** на обучающей выборке меньше единицы.\n",
    "\n",
    "Отправляемый файл должен иметь расширение .py\n",
    "\n",
    "Входные данные будут выглядеть примерно так:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Input] ---> [(Weights)] ---> [Output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Задаём количество признаков (фичей) и количество объектов в нашей модели\n",
    "n_features = 2\n",
    "n_objects = 300\n",
    "\n",
    "# Генерируем истинные веса для нашей модели. Они случайны и следуют нормальному (гауссовскому) распределению.\n",
    "w_true = torch.randn(n_features)\n",
    "\n",
    "# Создаём матрицу объектов X. Размер матрицы - это (n_objects x n_features). \n",
    "# Мы вычитаем 0.5, чтобы центрировать данные вокруг 0, а затем умножаем на 5, чтобы получить более широкий диапазон значений.\n",
    "# Это делается для того, чтобы сделать данные более \"интересными\" и сложными для модели.\n",
    "X = (torch.rand(n_objects, n_features) - 0.5) * 5\n",
    "\n",
    "# Сгенерируем \"истинные\" значения y, используя линейное преобразование наших объектов с истинными весами. \n",
    "# Затем добавляем нормальный шум, поделенный на два. \n",
    "# Это делается для того, чтобы внести некоторое количество случайности и непредсказуемости в наши данные, сделать их более \"реалистичными\".\n",
    "Y = X @ w_true + torch.randn(n_objects) / 2\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "- Инициализируем веса как в прошлом задании\n",
    "- Пока ошибка больше заданного уровня вычисляем ошибку\n",
    "- Вычисляем градиенты (обратное распространение)\n",
    "- Обновляем веса (не забывая отключать подсчет градиентов)\n",
    "- Обновляем параметры\n",
    "- Включаем подсчет градиентов\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "def function03(x: torch.Tensor, y: torch.Tensor):\n",
    "    # Количество признаков\n",
    "    n_features = x.shape[1]\n",
    "    \n",
    "    # Инициализируем веса\n",
    "    w = torch.randn(n_features, requires_grad=True)\n",
    "    \n",
    "    # Параметры обучения\n",
    "    learning_rate = 1e-2\n",
    "    tolerance = 1e-1\n",
    "    max_iter = 1000\n",
    "    loss = torch.tensor(float('inf'))\n",
    "    \n",
    "    # Градиентный спуск\n",
    "    for i in range(max_iter):\n",
    "        # Вычисляем ошибку\n",
    "        y_pred = x @ w\n",
    "        loss = torch.mean((y - y_pred)**2)\n",
    "        \n",
    "        if loss.item() < tolerance:\n",
    "            break\n",
    "\n",
    "        # Вычисляем градиенты\n",
    "        loss.backward()\n",
    "        \n",
    "        # Отключаем подсчет градиентов для обновления весов\n",
    "        with torch.no_grad():\n",
    "            w -= learning_rate * w.grad\n",
    "        \n",
    "        # Включаем подсчет градиентов и обнуляем градиенты\n",
    "        w.grad.zero_()\n",
    "\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = function03(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1741,  0.8195], requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1942,  0.7977])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Backpropagation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию `create_model`, которая должна возвращать полносвязную нейронную сеть из двух слоев. На вход должно быть 100 чисел, на выход 1, посередине 10. В качестве нелинейности используйте ReLU. Воспользуйтесь `nn.Sequential` и передайте слои как последовательность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    # Создание объекта нелинейного слоя\n",
    "    net = nn.Sequential(\n",
    "        nn.Linear(100, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, 1)\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = create_model()\n",
    "net"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию `train`. Она должна принимать на вход нейронную сеть, даталоадер, оптимизатор и функцию потерь. Она должна иметь следующую сигнатуру: `def train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn):`\n",
    "\n",
    "Внутри функции сделайте следующие шаги:\n",
    "\n",
    "1\\. Переведите модель в режим обучения.\n",
    "\n",
    "2\\. Проитерируйтесь по даталоадеру.\n",
    "\n",
    "3\\. На каждой итерации:\n",
    "\n",
    "    - Занулите градиенты с помощью оптимизатора\n",
    "\n",
    "    - Сделайте проход вперед (forward pass)\n",
    "\n",
    "    - Посчитайте ошибку\n",
    "\n",
    "    - Сделайте проход назад (backward pass)\n",
    "\n",
    "    - Напечатайте ошибку на текущем батче с точностью до 5 символов после запятой (только число)\n",
    "\n",
    "    - Сделайте шаг оптимизации\n",
    "\n",
    "Функция должна вернуть среднюю ошибку за время прохода по даталоадеру.\n",
    "\n",
    "2 урок > шаг 9\n",
    "\n",
    "Как перевести модель в режим обучения?\n",
    "\n",
    "Для этого необходимо использовать метод функцию .train() у функции\n",
    "\n",
    "Как итерироваться по даталоадеру?\n",
    "\n",
    "for x, y in data\\_loader:\n",
    "\n",
    "Как занулять градиенты и делать шаг?\n",
    "\n",
    "Для зануления градиентов можно воспользоваться функцией optimizer.zero\\_grad(). Для того чтобы сделать шаг оптимизации можно воспользоваться функцией optimizer.step().\n",
    "\n",
    "Ответ не принимается в LMS\n",
    "\n",
    "В LMS сдается скрипт в формате .py, c реализацией функции и со всеми необходимыми импортами. Обязательно проверяем код локально перед сдачей в LMS.\n",
    "\n",
    "Обратите внимание, что значение loss нужно брать как loss.item() чтобы получить число, а не тензор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "def train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        # Разделите данные на входные данные и целевые значения\n",
    "        inputs, targets = batch\n",
    "\n",
    "        # Обнулите градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Проход вперед\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Вычислите ошибку\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Проход назад\n",
    "        loss.backward()\n",
    "\n",
    "        # Шаг оптимизации\n",
    "        optimizer.step()\n",
    "\n",
    "        # Напечатайте ошибку на текущем батче\n",
    "        print(f'{loss.item():.5f}')\n",
    "\n",
    "        # Суммируйте ошибку\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Верните среднюю ошибку\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "def train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        # Разделите данные на входные данные и целевые значения\n",
    "        inputs, targets = batch\n",
    "\n",
    "        # Обнулите градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Проход вперед\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Вычислите ошибку\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Проход назад\n",
    "        loss.backward()\n",
    "\n",
    "        # Напечатайте ошибку на текущем батче\n",
    "        print(f'MSE на шаге: {loss.item():.5f}')\n",
    "        \n",
    "        # Шаг оптимизации\n",
    "        optimizer.step()\n",
    "\n",
    "        # Суммируйте ошибку\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Верните среднюю ошибку\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию `evaluate`. Она должна принимать на вход нейронную сеть, даталоадер и функцию потерь. Она должна иметь следующую сигнатуру: `def evaluate(model: nn.Module, data_loader: DataLoader, loss_fn):`\n",
    "\n",
    "Внутри функции сделайте следующие шаги:\n",
    "\n",
    "1\\. Переведите модель в режим инференса (применения)\n",
    "\n",
    "2\\. Проитерируйтесь по даталоадеру\n",
    "\n",
    "3\\. На каждой итерации:\n",
    "\n",
    "    - Сделайте проход вперед (forward pass)\n",
    "\n",
    "    - Посчитайте ошибку\n",
    "\n",
    "Функция должна вернуть среднюю ошибку за время прохода по даталоадеру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def evaluate(model: nn.Module, data_loader: DataLoader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # Разделите данные на входные данные и целевые значения\n",
    "            inputs, targets = batch\n",
    "\n",
    "            # Проход вперед\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Вычислите ошибку\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            # Суммируйте ошибку\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    # Верните среднюю ошибку\n",
    "    return total_loss / len(data_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
