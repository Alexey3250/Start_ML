{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_26928\\428365890.py:63: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "# Импортируем необходимые модули и библиотеки\n",
    "import os\n",
    "from catboost import CatBoostClassifier, Pool, CatBoost\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.orm import sessionmaker, Session\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from typing import List\n",
    "from fastapi import FastAPI, Depends \n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "\n",
    "'''\n",
    "ФУНКЦИИ ПО ЗАГРУЗКЕ МОДЕЛЕЙ\n",
    "'''\n",
    "# Проверка если код выполняется в лмс, или локально\n",
    "def get_model_path(path: str) -> str:\n",
    "    \"\"\"Просьба не менять этот код\"\"\"\n",
    "    if os.environ.get(\"IS_LMS\") == \"1\":  # проверяем где выполняется код в лмс, или локально. Немного магии\n",
    "        MODEL_PATH = 'catboost_model_1.cbm'\n",
    "    else:\n",
    "        MODEL_PATH = path\n",
    "    return MODEL_PATH\n",
    "\n",
    "class CatBoostWrapper(CatBoost):\n",
    "    def predict_proba(self, X):\n",
    "        return self.predict(X, prediction_type='Probability')\n",
    "\n",
    "# Загрузка модели\n",
    "def load_models():\n",
    "    model_path = get_model_path(\"catboost_model_1.cbm\")\n",
    "    model = CatBoostWrapper()\n",
    "    model.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "Получение данных из базы данных\n",
    "'''\n",
    "\n",
    "# Определяем функцию для получения данных из базы данных PostgreSQL\n",
    "def batch_load_sql(query: str) -> pd.DataFrame:\n",
    "    CHUNKSIZE = 200000\n",
    "    engine = create_engine(\n",
    "        \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )\n",
    "    conn = engine.connect().execution_options(stream_results=True)\n",
    "    chunks = []\n",
    "    for chunk_dataframe in pd.read_sql(query, conn, chunksize=CHUNKSIZE):\n",
    "        chunks.append(chunk_dataframe)\n",
    "    conn.close()\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "def load_features() -> pd.DataFrame:\n",
    "    query = \"a-efimik_features_lesson_22_4\"\n",
    "    return batch_load_sql(query)\n",
    "\n",
    "# Определяем переменные для подключения к базе данных\n",
    "SQLALCHEMY_DATABASE_URL = \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@postgres.lab.karpov.courses:6432/startml\"\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "Base = declarative_base()\n",
    "\n",
    "# Определяем класс Post для работы с таблицей базы данных post\n",
    "class Post(Base):\n",
    "    __tablename__ = 'post'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    text = Column(String)\n",
    "    topic = Column(String)\n",
    "\n",
    "class PostGet(BaseModel):\n",
    "    id: int\n",
    "    text: str\n",
    "    topic: str\n",
    "\n",
    "    class Config:\n",
    "        orm_mode = True\n",
    "\n",
    "# Определяем функцию для получения сессии базы данных\n",
    "def get_db():\n",
    "    with SessionLocal() as db:\n",
    "        return db\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = load_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163205\n"
     ]
    }
   ],
   "source": [
    "# print how much users there in total\n",
    "print(features['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_data = features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we prepare the data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caching_predictions(feed_data):\n",
    "    # Get a list of unique users\n",
    "    unique_users = feed_data['user_id'].unique()\n",
    "\n",
    "    # Create a group ID based on the 'user_id'\n",
    "    group_id_dict = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "    feed_data['group_id'] = feed_data['user_id'].map(group_id_dict)\n",
    "\n",
    "    # Sort by 'group_id'\n",
    "    feed_data.sort_values(by='group_id')\n",
    "\n",
    "    # Create Pool object with the 'group_id' column\n",
    "    data_pool = Pool(feed_data.drop(columns=['user_id']), group_id=feed_data['group_id'])\n",
    "\n",
    "    y_pred_proba = model.predict_proba(data_pool)[:, 1]\n",
    "    # Add the prediction probabilities to the test dataset\n",
    "    features['pred_proba'] = y_pred_proba\n",
    "\n",
    "    # Group by 'user_id' and find the top 5 predicted 'post_id' for each user\n",
    "    top_5_posts = features.groupby('user_id').apply(lambda x: x.nlargest(5, 'pred_proba')['post_id'])\n",
    "    \n",
    "    # Convert the multi-index Series to a dictionary\n",
    "    top_5_posts_dict = top_5_posts.reset_index().groupby('user_id')['post_id'].apply(list).to_dict()\n",
    "    \n",
    "    # return the top 5 posts in a dictionary\n",
    "    return top_5_posts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_posts_dict = caching_predictions(feed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6661, 5989, 5257, 5181, 45]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_posts_dict[200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the text data from sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6661, 5989, 5257, 5181, 45]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 200\n",
    "top_5_posts_dict[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение данных таблицы post_text_df\n",
    "query = \"SELECT * FROM post_text_df\"\n",
    "post_text_df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>UK economy facing major risks\\n\\nThe UK manufa...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Aids and climate top Davos agenda\\n\\nClimate c...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Asian quake hits European shares\\n\\nShares in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India power shares jump on debut\\n\\nShares in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lacroix label bought by US firm\\n\\nLuxury good...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                               text     topic\n",
       "0        1  UK economy facing major risks\\n\\nThe UK manufa...  business\n",
       "1        2  Aids and climate top Davos agenda\\n\\nClimate c...  business\n",
       "2        3  Asian quake hits European shares\\n\\nShares in ...  business\n",
       "3        4  India power shares jump on debut\\n\\nShares in ...  business\n",
       "4        5  Lacroix label bought by US firm\\n\\nLuxury good...  business"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5525e501b23e2010ab883f77d6209697fb9a7ecd2dc8bb136f049441ff2c9ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
