{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed data shape: (15378483, 51)\n"
     ]
    }
   ],
   "source": [
    "# Чтение feed_data из csv файла\n",
    "feed_data = pd.read_csv(r'C:\\Users\\Alex\\Desktop\\data_for_training.csv')\n",
    "print(f\"Feed data shape: {feed_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_10_percent(group):\n",
    "    frac = 0.5\n",
    "    return group.sample(frac=frac)\n",
    "\n",
    "feed_data = feed_data.groupby('user_id', group_keys=False).apply(sample_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'post_id_x', 'action', 'target', 'gender', 'age', 'country',\n",
       "       'city', 'exp_group', 'os', 'source', 'topic', 'word_count',\n",
       "       'sentence_count', 'avg_word_length', 'punctuation_count', 'month',\n",
       "       'day_of_week', 'hour_of_day', 'time_since_last_action', 'day_of_month',\n",
       "       'year', 'user_views', 'user_likes', 'post_views', 'post_likes',\n",
       "       '0_exp_group_likes', '0_exp_group_views', '1_exp_group_likes',\n",
       "       '1_exp_group_views', '2_exp_group_likes', '2_exp_group_views',\n",
       "       '3_exp_group_likes', '3_exp_group_views', '4_exp_group_likes',\n",
       "       '4_exp_group_views', '5_exp_group_likes', '5_exp_group_views',\n",
       "       '6_exp_group_likes', '6_exp_group_views', 'component_1', 'component_2',\n",
       "       'component_3', 'component_4', 'component_5', 'component_6',\n",
       "       'component_7', 'component_8', 'component_9', 'component_10',\n",
       "       'post_id_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename post_id_x to post_id \n",
    "feed_data = feed_data.rename(columns={'post_id_x': 'post_id'})\n",
    "\n",
    "# drop post_id_y\n",
    "feed_data = feed_data.drop('post_id_y', axis=1)\n",
    "\n",
    "# drop action\n",
    "feed_data = feed_data.drop('action', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the first few rows of the DataFrame\n",
    "print(feed_data.head())\n",
    "\n",
    "# Print the summary statistics of the DataFrame\n",
    "print(feed_data.describe())\n",
    "\n",
    "# Print the information of the DataFrame\n",
    "print(feed_data.info())\n",
    "\n",
    "# Print the number of unique users\n",
    "print(\"Number of unique users:\", feed_data['user_id'].nunique())\n",
    "\n",
    "# Print the number of unique posts\n",
    "print(\"Number of unique posts:\", feed_data['post_id'].nunique())\n",
    "\n",
    "# Print the distribution of the number of posts per user\n",
    "print(\"Number of posts per user:\\n\", feed_data['user_id'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features  = ['gender', 'age', 'country', 'city', 'exp_group', 'os', 'source', 'topic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Get a list of unique users\n",
    "unique_users = feed_data['user_id'].unique()\n",
    "\n",
    "# Split unique users into training and testing sets\n",
    "train_users, test_users = train_test_split(unique_users, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = feed_data[feed_data['user_id'].isin(train_users)]\n",
    "X_train = X_train.drop('target', axis=1)\n",
    "\n",
    "X_test = feed_data[feed_data['user_id'].isin(test_users)]\n",
    "X_test = X_test.drop('target', axis=1)\n",
    "\n",
    "y_train = feed_data[feed_data['user_id'].isin(train_users)]['target']\n",
    "y_test = feed_data[feed_data['user_id'].isin(test_users)]['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a group ID based on the 'user_id' column\n",
    "\n",
    "group_id_dict = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "X_train['group_id'] = X_train['user_id'].map(group_id_dict) # map() function returns a map object(which is an iterator) of the results after applying the given function to each item of a given iterable (list, tuple etc.)\n",
    "X_test['group_id'] = X_test['user_id'].map(group_id_dict)\n",
    "\n",
    "# Sort the train and test sets by 'group_id'\n",
    "X_train = X_train.sort_values(by='group_id')\n",
    "y_train = y_train.loc[X_train.index] # loc() function is used to access a group of rows and columns by label(s) or a boolean array.\n",
    "\n",
    "X_test = X_test.sort_values(by='group_id')\n",
    "y_test = y_test.loc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Get a list of unique users\n",
    "unique_users = feed_data['user_id'].unique()\n",
    "\n",
    "# Split unique users into training and testing sets\n",
    "train_users, test_users = train_test_split(unique_users, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = feed_data[feed_data['user_id'].isin(train_users)]\n",
    "X_train = X_train.drop('target', axis=1)\n",
    "\n",
    "X_test = feed_data[feed_data['user_id'].isin(test_users)]\n",
    "X_test = X_test.drop('target', axis=1)\n",
    "\n",
    "y_train = feed_data[feed_data['user_id'].isin(train_users)]['target']\n",
    "y_test = feed_data[feed_data['user_id'].isin(test_users)]['target']\n",
    "\n",
    "# Create a group ID based on the 'user_id' column in the training set\n",
    "group_id_dict_train = {user_id: idx for idx, user_id in enumerate(train_users)}\n",
    "X_train['group_id'] = X_train['user_id'].map(group_id_dict_train)\n",
    "\n",
    "# Create a group ID based on the 'user_id' column in the test set\n",
    "group_id_dict_test = {user_id: idx for idx, user_id in enumerate(test_users)}\n",
    "X_test['group_id'] = X_test['user_id'].map(group_id_dict_test)\n",
    "\n",
    "# Sort the train and test sets by 'group_id'\n",
    "X_train = X_train.sort_values(by='group_id')\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "X_test = X_test.sort_values(by='group_id')\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "# Create train and test Pool objects with the 'group_id' column\n",
    "train_pool = Pool(X_train.drop(columns=['user_id']), y_train, group_id=X_train['group_id'])\n",
    "test_pool = Pool(X_test.drop(columns=['user_id']), y_test, group_id=X_test['group_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6841068\ttest: 0.6842059\tbest: 0.6842059 (0)\ttotal: 282ms\tremaining: 4m 42s\n",
      "100:\tlearn: 0.3607832\ttest: 0.3608844\tbest: 0.3608844 (100)\ttotal: 27s\tremaining: 4m\n",
      "200:\tlearn: 0.3270229\ttest: 0.3271149\tbest: 0.3271149 (200)\ttotal: 53.4s\tremaining: 3m 32s\n",
      "300:\tlearn: 0.3213309\ttest: 0.3214325\tbest: 0.3214325 (300)\ttotal: 1m 19s\tremaining: 3m 5s\n",
      "400:\tlearn: 0.3193298\ttest: 0.3194465\tbest: 0.3194465 (400)\ttotal: 1m 46s\tremaining: 2m 38s\n",
      "500:\tlearn: 0.3184363\ttest: 0.3185650\tbest: 0.3185650 (500)\ttotal: 2m 12s\tremaining: 2m 12s\n",
      "600:\tlearn: 0.3178537\ttest: 0.3179899\tbest: 0.3179899 (600)\ttotal: 2m 38s\tremaining: 1m 45s\n",
      "700:\tlearn: 0.3174319\ttest: 0.3175736\tbest: 0.3175736 (700)\ttotal: 3m 5s\tremaining: 1m 19s\n",
      "800:\tlearn: 0.3171070\ttest: 0.3172561\tbest: 0.3172561 (800)\ttotal: 3m 31s\tremaining: 52.5s\n",
      "900:\tlearn: 0.3168777\ttest: 0.3170353\tbest: 0.3170353 (900)\ttotal: 3m 56s\tremaining: 26s\n",
      "999:\tlearn: 0.3166943\ttest: 0.3168609\tbest: 0.3168609 (999)\ttotal: 4m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3168609027\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2dfa71c0520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the training parameters \n",
    "params = {'loss_function': 'Logloss', # suitable for binary classification\n",
    "          'custom_metric': ['AUC', 'NDCG'], # evaluation metrics\n",
    "          'thread_count': 16,\n",
    "          'verbose': 100,\n",
    "          'random_seed': 42,\n",
    "          'iterations': 1000,\n",
    "          'learning_rate': 0.01,\n",
    "          }\n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "# Fit model\n",
    "model.fit(train_pool, eval_set=test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 30.905743873401633\n",
      "user_views: 19.139807644100106\n",
      "post_views: 16.488681822328388\n",
      "post_likes: 9.628621136365949\n",
      "month: 5.231191510676601\n",
      "user_likes: 4.787093854020484\n",
      "time_since_last_action: 3.00661916953293\n",
      "hour_of_day: 2.144813484544992\n",
      "city: 1.7847359346798373\n",
      "country: 1.6490598548654003\n",
      "4_exp_group_likes: 0.5872170980684919\n",
      "topic: 0.5302533427564742\n",
      "1_exp_group_likes: 0.45781957325047157\n",
      "gender: 0.40401728981105817\n",
      "post_id: 0.38367674530640633\n",
      "3_exp_group_views: 0.372007957144139\n",
      "5_exp_group_likes: 0.3504371176586997\n",
      "2_exp_group_likes: 0.33646112256309424\n",
      "3_exp_group_likes: 0.2969667042724532\n",
      "component_2: 0.27383448893953305\n",
      "4_exp_group_views: 0.26688254309501613\n",
      "0_exp_group_likes: 0.2643346503607561\n",
      "6_exp_group_likes: 0.15641322658753923\n",
      "1_exp_group_views: 0.10655812366124458\n",
      "2_exp_group_views: 0.08864624762113689\n",
      "exp_group: 0.0667488063263353\n",
      "0_exp_group_views: 0.05753102742903716\n",
      "component_4: 0.03585172410745325\n",
      "5_exp_group_views: 0.03373393860632913\n",
      "6_exp_group_views: 0.03154921641389342\n",
      "component_10: 0.028300018167133265\n",
      "component_5: 0.02456705551130731\n",
      "avg_word_length: 0.014955641098308896\n",
      "component_1: 0.012170719040207289\n",
      "component_3: 0.011746248269277346\n",
      "component_6: 0.01055772692953222\n",
      "component_7: 0.007760979881670387\n",
      "component_8: 0.007706845416325445\n",
      "word_count: 0.005793191346082669\n",
      "component_9: 0.0020448895668512762\n",
      "day_of_week: 0.0016569462704980153\n",
      "sentence_count: 0.0015175641156491239\n",
      "punctuation_count: 0.0014255856259012677\n",
      "group_id: 0.0008301685759476716\n",
      "day_of_month: 0.0007432285363378907\n",
      "os: 0.0006288392082828535\n",
      "source: 0.00028512394477589833\n",
      "year: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_importances = model.get_feature_importance(train_pool)\n",
    "feature_names = X_train.drop(columns=['user_id']).columns\n",
    "\n",
    "for score, name in sorted(zip(feature_importances, feature_names), reverse=True):\n",
    "    print(f'{name}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m feature_importances \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_feature_importance(train_pool)\n\u001b[0;32m      4\u001b[0m feature_names \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m      6\u001b[0m sorted_scores, sorted_names \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39msorted\u001b[39m(\u001b[39mzip\u001b[39m(feature_importances, feature_names), reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importances = model.get_feature_importance(train_pool)\n",
    "feature_names = X_train.drop(columns=['user_id']).columns\n",
    "\n",
    "sorted_scores, sorted_names = zip(*sorted(zip(feature_importances, feature_names), reverse=True))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(sorted_names, sorted_scores)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0670078\ttest: 0.0670384\tbest: 0.0670384 (0)\ttotal: 253ms\tremaining: 4m 12s\n",
      "100:\tlearn: 0.1732239\ttest: 0.1734873\tbest: 0.1735363 (97)\ttotal: 23s\tremaining: 3m 25s\n",
      "200:\tlearn: 0.1739377\ttest: 0.1732913\tbest: 0.1738979 (147)\ttotal: 45.3s\tremaining: 2m 59s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train the CatBoost model using PrecisionAt:top=5 evaluation metric\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(iterations=1000,\n",
    "                           learning_rate=0.1,\n",
    "                           depth=6,\n",
    "                           custom_metric='PrecisionAt:top=5',\n",
    "                           eval_metric='PrecisionAt:top=5',\n",
    "                           random_seed=42,\n",
    "                           verbose=100)\n",
    "\n",
    "model.fit(train_pool, eval_set=test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(test_pool)[:, 1]\n",
    "# Add the prediction probabilities to the test dataset\n",
    "X_test['pred_proba'] = y_pred_proba\n",
    "\n",
    "# Group by 'user_id' and find the top 5 predicted 'post_id' for each user\n",
    "top_5_posts = X_test.groupby('user_id').apply(lambda x: x.nlargest(5, 'pred_proba')['post_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id          \n",
       "200      75          5181\n",
       "         37          6404\n",
       "         57          3890\n",
       "         38          1936\n",
       "         23          5989\n",
       "                     ... \n",
       "168551   15378387    2474\n",
       "         15378377     361\n",
       "         15378390    4217\n",
       "         15378375    1669\n",
       "         15378388    5691\n",
       "Name: post_id, Length: 163205, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HitRate@5: 0.09368657129728529\n"
     ]
    }
   ],
   "source": [
    "def hitrate_at_k(top_k_posts, k=5):\n",
    "    hits = 0\n",
    "    user_data = top_k_posts.groupby(level=0).apply(list).to_dict()\n",
    "\n",
    "    for user_id, top_k_posts in user_data.items():\n",
    "        true_post_ids = X_test[(X_test['user_id'] == user_id) & (y_test == 1)]['post_id']\n",
    "        hits += len(set(top_k_posts) & set(true_post_ids))\n",
    "\n",
    "    return hits / len(y_test[y_test == 1])\n",
    "\n",
    "hitrate_at_5 = hitrate_at_k(top_5_posts, k=5)\n",
    "print(\"HitRate@5:\", hitrate_at_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "model.save_model(\"catboost_model.cbm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
