{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed data shape: (15378483, 51)\n"
     ]
    }
   ],
   "source": [
    "# Чтение feed_data из csv файла\n",
    "feed_data = pd.read_csv(r'C:\\Users\\Alex\\Desktop\\data_for_training.csv')\n",
    "print(f\"Feed data shape: {feed_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename post_id_x to post_id \n",
    "feed_data = feed_data.rename(columns={'post_id_x': 'post_id'})\n",
    "\n",
    "# drop post_id_y\n",
    "feed_data = feed_data.drop('post_id_y', axis=1)\n",
    "\n",
    "# drop action\n",
    "feed_data = feed_data.drop('action', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['user_views', 'user_likes',\n",
    "                     'component_2', '4_exp_group_views', '0_exp_group_likes', '6_exp_group_likes', \n",
    "                     '1_exp_group_views', '2_exp_group_views', 'exp_group', '0_exp_group_views', \n",
    "                     'component_4', '5_exp_group_views', '6_exp_group_views', 'component_10', \n",
    "                     'component_5', 'avg_word_length', 'component_1', 'component_3', 'component_6', \n",
    "                     'component_7', 'component_8', 'word_count', 'component_9', 'day_of_week', \n",
    "                     'sentence_count', 'punctuation_count', 'day_of_month', 'os', \n",
    "                     'source', 'year','1_exp_group_likes', '2_exp_group_likes',\n",
    "                     '3_exp_group_likes', '3_exp_group_views', '4_exp_group_likes',\n",
    "                     '5_exp_group_likes' , 'time_since_last_action']\n",
    "\n",
    "feed_data = feed_data.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_10_percent(group):\n",
    "    frac = 0.1\n",
    "    return group.sample(frac=frac)\n",
    "\n",
    "#feed_data = feed_data.groupby('user_id', group_keys=False).apply(sample_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'post_id', 'target', 'gender', 'age', 'country', 'city',\n",
       "       'topic', 'month', 'hour_of_day', 'post_views', 'post_likes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the first few rows of the DataFrame\n",
    "print(feed_data.head())\n",
    "\n",
    "# Print the summary statistics of the DataFrame\n",
    "print(feed_data.describe())\n",
    "\n",
    "# Print the information of the DataFrame\n",
    "print(feed_data.info())\n",
    "\n",
    "# Print the number of unique users\n",
    "print(\"Number of unique users:\", feed_data['user_id'].nunique())\n",
    "\n",
    "# Print the number of unique posts\n",
    "print(\"Number of unique posts:\", feed_data['post_id'].nunique())\n",
    "\n",
    "# Print the distribution of the number of posts per user\n",
    "print(\"Number of posts per user:\\n\", feed_data['user_id'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features  = ['gender', 'age', 'country', 'city', 'exp_group', 'os', 'source', 'topic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Get a list of unique users\n",
    "unique_users = feed_data['user_id'].unique()\n",
    "\n",
    "# Split unique users into training and testing sets\n",
    "train_users, test_users = train_test_split(unique_users, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = feed_data[feed_data['user_id'].isin(train_users)]\n",
    "X_train = X_train.drop('target', axis=1)\n",
    "\n",
    "X_test = feed_data[feed_data['user_id'].isin(test_users)]\n",
    "X_test = X_test.drop('target', axis=1)\n",
    "\n",
    "y_train = feed_data[feed_data['user_id'].isin(train_users)]['target']\n",
    "y_test = feed_data[feed_data['user_id'].isin(test_users)]['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a group ID based on the 'user_id' column\n",
    "\n",
    "group_id_dict = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "X_train['group_id'] = X_train['user_id'].map(group_id_dict) # map() function returns a map object(which is an iterator) of the results after applying the given function to each item of a given iterable (list, tuple etc.)\n",
    "X_test['group_id'] = X_test['user_id'].map(group_id_dict)\n",
    "\n",
    "# Sort the train and test sets by 'group_id'\n",
    "X_train = X_train.sort_values(by='group_id')\n",
    "y_train = y_train.loc[X_train.index] # loc() function is used to access a group of rows and columns by label(s) or a boolean array.\n",
    "\n",
    "X_test = X_test.sort_values(by='group_id')\n",
    "y_test = y_test.loc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Get a list of unique users\n",
    "unique_users = feed_data['user_id'].unique()\n",
    "\n",
    "# Split unique users into training and testing sets\n",
    "train_users, test_users = train_test_split(unique_users, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = feed_data[feed_data['user_id'].isin(train_users)]\n",
    "X_train = X_train.drop('target', axis=1)\n",
    "\n",
    "X_test = feed_data[feed_data['user_id'].isin(test_users)]\n",
    "X_test = X_test.drop('target', axis=1)\n",
    "\n",
    "y_train = feed_data[feed_data['user_id'].isin(train_users)]['target']\n",
    "y_test = feed_data[feed_data['user_id'].isin(test_users)]['target']\n",
    "\n",
    "# Create a group ID based on the 'user_id' column in the training set\n",
    "group_id_dict_train = {user_id: idx for idx, user_id in enumerate(train_users)}\n",
    "X_train['group_id'] = X_train['user_id'].map(group_id_dict_train)\n",
    "\n",
    "# Create a group ID based on the 'user_id' column in the test set\n",
    "group_id_dict_test = {user_id: idx for idx, user_id in enumerate(test_users)}\n",
    "X_test['group_id'] = X_test['user_id'].map(group_id_dict_test)\n",
    "\n",
    "# Sort the train and test sets by 'group_id'\n",
    "X_train = X_train.sort_values(by='group_id')\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "X_test = X_test.sort_values(by='group_id')\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "# Create train and test Pool objects with the 'group_id' column\n",
    "train_pool = Pool(X_train.drop(columns=['user_id']), y_train, group_id=X_train['group_id'])\n",
    "test_pool = Pool(X_test.drop(columns=['user_id']), y_test, group_id=X_test['group_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6844017\ttest: 0.6841802\tbest: 0.6841802 (0)\ttotal: 615ms\tremaining: 10m 14s\n",
      "100:\tlearn: 0.3625198\ttest: 0.3623879\tbest: 0.3623879 (100)\ttotal: 43.3s\tremaining: 6m 25s\n",
      "200:\tlearn: 0.3302596\ttest: 0.3301469\tbest: 0.3301469 (200)\ttotal: 1m 25s\tremaining: 5m 38s\n",
      "300:\tlearn: 0.3249783\ttest: 0.3248456\tbest: 0.3248456 (300)\ttotal: 2m 7s\tremaining: 4m 56s\n",
      "400:\tlearn: 0.3235143\ttest: 0.3233678\tbest: 0.3233678 (400)\ttotal: 2m 49s\tremaining: 4m 13s\n",
      "500:\tlearn: 0.3228368\ttest: 0.3226871\tbest: 0.3226871 (500)\ttotal: 3m 32s\tremaining: 3m 31s\n",
      "600:\tlearn: 0.3223864\ttest: 0.3222310\tbest: 0.3222310 (600)\ttotal: 4m 13s\tremaining: 2m 48s\n",
      "700:\tlearn: 0.3219961\ttest: 0.3218416\tbest: 0.3218416 (700)\ttotal: 4m 55s\tremaining: 2m 6s\n",
      "800:\tlearn: 0.3216953\ttest: 0.3215385\tbest: 0.3215385 (800)\ttotal: 5m 37s\tremaining: 1m 23s\n",
      "900:\tlearn: 0.3214469\ttest: 0.3212862\tbest: 0.3212862 (900)\ttotal: 6m 20s\tremaining: 41.8s\n",
      "999:\tlearn: 0.3212380\ttest: 0.3210762\tbest: 0.3210762 (999)\ttotal: 7m 1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3210762475\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x192cb48ab90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the training parameters \n",
    "params = {'loss_function': 'Logloss', # suitable for binary classification\n",
    "          'custom_metric': ['AUC', 'NDCG'], # evaluation metrics\n",
    "          'thread_count': 16,\n",
    "          'verbose': 100,\n",
    "          'random_seed': 42,\n",
    "          'iterations': 1000,\n",
    "          'learning_rate': 0.01,\n",
    "          }\n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "# Fit model\n",
    "model.fit(train_pool, eval_set=test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 38.56572866588417\n",
      "post_views: 19.535627294930872\n",
      "post_likes: 12.487347118434892\n",
      "city: 10.604408251025319\n",
      "month: 6.649052249053987\n",
      "country: 6.053510425135744\n",
      "hour_of_day: 2.9700227173565383\n",
      "gender: 1.331094677697266\n",
      "post_id: 1.1585140540901286\n",
      "topic: 0.6437094293089937\n",
      "group_id: 0.0009851170820787826\n"
     ]
    }
   ],
   "source": [
    "feature_importances = model.get_feature_importance(train_pool)\n",
    "feature_names = X_train.drop(columns=['user_id']).columns\n",
    "\n",
    "for score, name in sorted(zip(feature_importances, feature_names), reverse=True):\n",
    "    print(f'{name}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(test_pool)[:, 1]\n",
    "# Add the prediction probabilities to the test dataset\n",
    "X_test['pred_proba'] = y_pred_proba\n",
    "\n",
    "# Group by 'user_id' and find the top 5 predicted 'post_id' for each user\n",
    "top_5_posts = X_test.groupby('user_id').apply(lambda x: x.nlargest(5, 'pred_proba')['post_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id          \n",
       "200      37          6404\n",
       "         39          6697\n",
       "         25          6934\n",
       "         30          6661\n",
       "         23          5989\n",
       "                     ... \n",
       "168551   15378388    5691\n",
       "         15378390    4217\n",
       "         15378376    3337\n",
       "         15378387    2474\n",
       "         15378377     361\n",
       "Name: post_id, Length: 163205, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HitRate@5: 0.09007142052906575\n"
     ]
    }
   ],
   "source": [
    "def hitrate_at_k(top_k_posts, k=5):\n",
    "    hits = 0\n",
    "    user_data = top_k_posts.groupby(level=0).apply(list).to_dict()\n",
    "\n",
    "    for user_id, top_k_posts in user_data.items():\n",
    "        true_post_ids = X_test[(X_test['user_id'] == user_id) & (y_test == 1)]['post_id']\n",
    "        hits += len(set(top_k_posts) & set(true_post_ids))\n",
    "\n",
    "    return hits / len(y_test[y_test == 1])\n",
    "\n",
    "hitrate_at_5 = hitrate_at_k(top_5_posts, k=5)\n",
    "print(\"HitRate@5:\", hitrate_at_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "model.save_model(\"catboost_model.cbm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
