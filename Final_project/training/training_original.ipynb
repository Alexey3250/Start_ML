{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.83 GiB for an array with shape (16, 15378483) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Чтение feed_data из csv файла\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m feed_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mAlex\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mDesktop\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mdata_for_training.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeed data shape: \u001b[39m\u001b[39m{\u001b[39;00mfeed_data\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1721\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1719\u001b[0m         new_rows \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(index)\n\u001b[1;32m-> 1721\u001b[0m     df \u001b[39m=\u001b[39m DataFrame(col_dict, columns\u001b[39m=\u001b[39;49mcolumns, index\u001b[39m=\u001b[39;49mindex)\n\u001b[0;32m   1723\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m new_rows\n\u001b[0;32m   1724\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:708\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    703\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    704\u001b[0m     )\n\u001b[0;32m    706\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    707\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    709\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    710\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:153\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    150\u001b[0m axes \u001b[39m=\u001b[39m [columns, index]\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    154\u001b[0m         arrays, axes, consolidate\u001b[39m=\u001b[39;49mconsolidate, refs\u001b[39m=\u001b[39;49mrefs\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    156\u001b[0m \u001b[39melif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2137\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2120\u001b[0m     arrays: \u001b[39mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2121\u001b[0m     axes: \u001b[39mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2133\u001b[0m     \u001b[39m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2134\u001b[0m     \u001b[39m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2137\u001b[0m         blocks \u001b[39m=\u001b[39m _form_blocks(arrays, consolidate, refs)\n\u001b[0;32m   2138\u001b[0m         mgr \u001b[39m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2139\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2215\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[0;32m   2212\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(dtype\u001b[39m.\u001b[39mtype, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m)):\n\u001b[0;32m   2213\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39mobject\u001b[39m)\n\u001b[1;32m-> 2215\u001b[0m values, placement \u001b[39m=\u001b[39m _stack_arrays(\u001b[39mlist\u001b[39;49m(tup_block), dtype)\n\u001b[0;32m   2216\u001b[0m \u001b[39mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2217\u001b[0m     values \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2255\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2252\u001b[0m first \u001b[39m=\u001b[39m arrays[\u001b[39m0\u001b[39m]\n\u001b[0;32m   2253\u001b[0m shape \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(arrays),) \u001b[39m+\u001b[39m first\u001b[39m.\u001b[39mshape\n\u001b[1;32m-> 2255\u001b[0m stacked \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(shape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   2256\u001b[0m \u001b[39mfor\u001b[39;00m i, arr \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arrays):\n\u001b[0;32m   2257\u001b[0m     stacked[i] \u001b[39m=\u001b[39m arr\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.83 GiB for an array with shape (16, 15378483) and data type int64"
     ]
    }
   ],
   "source": [
    "# Чтение feed_data из csv файла\n",
    "feed_data = pd.read_csv(r'C:\\Users\\Alex\\Desktop\\data_for_training.csv')\n",
    "print(f\"Feed data shape: {feed_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'post_id_x', 'action', 'target', 'gender', 'age', 'country',\n",
       "       'city', 'exp_group', 'os', 'source', 'topic', 'word_count',\n",
       "       'sentence_count', 'avg_word_length', 'punctuation_count', 'month',\n",
       "       'day_of_week', 'hour_of_day', 'time_since_last_action', 'day_of_month',\n",
       "       'year', 'user_views', 'user_likes', 'post_views', 'post_likes',\n",
       "       '0_exp_group_likes', '0_exp_group_views', '1_exp_group_likes',\n",
       "       '1_exp_group_views', '2_exp_group_likes', '2_exp_group_views',\n",
       "       '3_exp_group_likes', '3_exp_group_views', '4_exp_group_likes',\n",
       "       '4_exp_group_views', '5_exp_group_likes', '5_exp_group_views',\n",
       "       '6_exp_group_likes', '6_exp_group_views', 'component_1', 'component_2',\n",
       "       'component_3', 'component_4', 'component_5', 'component_6',\n",
       "       'component_7', 'component_8', 'component_9', 'component_10',\n",
       "       'post_id_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features  = ['gender', 'age', 'country', 'city', 'exp_group', 'os', 'source', 'topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_10_percent(group):\n",
    "    frac = 0.5\n",
    "    return group.sample(frac=frac)\n",
    "\n",
    "#feed_data = feed_data.groupby('user_id', group_keys=False).apply(sample_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data with selected features, top k with mutual information, without data leakage, timestamp, 'action' and 'text'\n",
    "X = feed_data.drop(['action', 'target'], axis=1)\n",
    "y = feed_data['target']\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a group ID based on the 'user_id' column\n",
    "unique_user_ids = X_train['user_id'].unique()\n",
    "group_id_dict = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}\n",
    "X_train['group_id'] = X_train['user_id'].map(group_id_dict)\n",
    "X_test['group_id'] = X_test['user_id'].map(group_id_dict)\n",
    "\n",
    "# Sort the train and test sets by 'group_id'\n",
    "X_train = X_train.sort_values(by='group_id')\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "X_test = X_test.sort_values(by='group_id')\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "# Create train and test Pool objects with the 'group_id' column\n",
    "from catboost import Pool\n",
    "\n",
    "train_pool = Pool(X_train.drop(columns=['user_id']), y_train, group_id=X_train['group_id'])\n",
    "test_pool = Pool(X_test.drop(columns=['user_id']), y_test, group_id=X_test['group_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping user_ids: 163196\n"
     ]
    }
   ],
   "source": [
    "# Check for overlapping user_id values\n",
    "train_user_ids = set(X_train['user_id'])\n",
    "test_user_ids = set(X_test['user_id'])\n",
    "\n",
    "overlapping_user_ids = train_user_ids.intersection(test_user_ids)\n",
    "\n",
    "# Count the overlapping user_ids\n",
    "overlapping_count = len(overlapping_user_ids)\n",
    "\n",
    "print(\"Number of overlapping user_ids:\", overlapping_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X_train:\n",
      "user_id                   0\n",
      "post_id_x                 0\n",
      "gender                    0\n",
      "age                       0\n",
      "country                   0\n",
      "city                      0\n",
      "exp_group                 0\n",
      "os                        0\n",
      "source                    0\n",
      "topic                     0\n",
      "word_count                0\n",
      "sentence_count            0\n",
      "avg_word_length           0\n",
      "punctuation_count         0\n",
      "month                     0\n",
      "day_of_week               0\n",
      "hour_of_day               0\n",
      "time_since_last_action    0\n",
      "day_of_month              0\n",
      "year                      0\n",
      "user_views                0\n",
      "user_likes                0\n",
      "post_views                0\n",
      "post_likes                0\n",
      "0_exp_group_likes         0\n",
      "0_exp_group_views         0\n",
      "1_exp_group_likes         0\n",
      "1_exp_group_views         0\n",
      "2_exp_group_likes         0\n",
      "2_exp_group_views         0\n",
      "3_exp_group_likes         0\n",
      "3_exp_group_views         0\n",
      "4_exp_group_likes         0\n",
      "4_exp_group_views         0\n",
      "5_exp_group_likes         0\n",
      "5_exp_group_views         0\n",
      "6_exp_group_likes         0\n",
      "6_exp_group_views         0\n",
      "component_1               0\n",
      "component_2               0\n",
      "component_3               0\n",
      "component_4               0\n",
      "component_5               0\n",
      "component_6               0\n",
      "component_7               0\n",
      "component_8               0\n",
      "component_9               0\n",
      "component_10              0\n",
      "post_id_y                 0\n",
      "group_id                  0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in X_test:\n",
      "user_id                   0\n",
      "post_id_x                 0\n",
      "gender                    0\n",
      "age                       0\n",
      "country                   0\n",
      "city                      0\n",
      "exp_group                 0\n",
      "os                        0\n",
      "source                    0\n",
      "topic                     0\n",
      "word_count                0\n",
      "sentence_count            0\n",
      "avg_word_length           0\n",
      "punctuation_count         0\n",
      "month                     0\n",
      "day_of_week               0\n",
      "hour_of_day               0\n",
      "time_since_last_action    0\n",
      "day_of_month              0\n",
      "year                      0\n",
      "user_views                0\n",
      "user_likes                0\n",
      "post_views                0\n",
      "post_likes                0\n",
      "0_exp_group_likes         0\n",
      "0_exp_group_views         0\n",
      "1_exp_group_likes         0\n",
      "1_exp_group_views         0\n",
      "2_exp_group_likes         0\n",
      "2_exp_group_views         0\n",
      "3_exp_group_likes         0\n",
      "3_exp_group_views         0\n",
      "4_exp_group_likes         0\n",
      "4_exp_group_views         0\n",
      "5_exp_group_likes         0\n",
      "5_exp_group_views         0\n",
      "6_exp_group_likes         0\n",
      "6_exp_group_views         0\n",
      "component_1               0\n",
      "component_2               0\n",
      "component_3               0\n",
      "component_4               0\n",
      "component_5               0\n",
      "component_6               0\n",
      "component_7               0\n",
      "component_8               0\n",
      "component_9               0\n",
      "component_10              0\n",
      "post_id_y                 0\n",
      "group_id                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values in X_train\n",
    "train_missing_values = X_train.isnull().sum()\n",
    "print(\"Missing values in X_train:\")\n",
    "print(train_missing_values)\n",
    "\n",
    "# Count missing values in X_test\n",
    "test_missing_values = X_test.isnull().sum()\n",
    "print(\"\\nMissing values in X_test:\")\n",
    "print(test_missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1175552\ttest: 0.1034550\tbest: 0.1034550 (0)\ttotal: 669ms\tremaining: 11m 8s\n",
      "100:\tlearn: 0.1697975\ttest: 0.1353045\tbest: 0.1353095 (99)\ttotal: 45.1s\tremaining: 6m 41s\n",
      "200:\tlearn: 0.1708416\ttest: 0.1355491\tbest: 0.1355897 (197)\ttotal: 1m 28s\tremaining: 5m 51s\n",
      "300:\tlearn: 0.1721442\ttest: 0.1356892\tbest: 0.1357224 (250)\ttotal: 2m 11s\tremaining: 5m 6s\n",
      "400:\tlearn: 0.1735314\ttest: 0.1357740\tbest: 0.1357777 (398)\ttotal: 2m 55s\tremaining: 4m 22s\n",
      "500:\tlearn: 0.1746147\ttest: 0.1356843\tbest: 0.1358281 (431)\ttotal: 3m 40s\tremaining: 3m 39s\n",
      "600:\tlearn: 0.1760130\ttest: 0.1357814\tbest: 0.1358281 (431)\ttotal: 4m 25s\tremaining: 2m 56s\n",
      "700:\tlearn: 0.1774541\ttest: 0.1357310\tbest: 0.1358367 (661)\ttotal: 5m 10s\tremaining: 2m 12s\n",
      "800:\tlearn: 0.1787592\ttest: 0.1357482\tbest: 0.1358367 (661)\ttotal: 5m 54s\tremaining: 1m 28s\n",
      "900:\tlearn: 0.1798928\ttest: 0.1357298\tbest: 0.1358367 (661)\ttotal: 6m 39s\tremaining: 43.9s\n",
      "999:\tlearn: 0.1809405\ttest: 0.1357187\tbest: 0.1358367 (661)\ttotal: 7m 24s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1358367028\n",
      "bestIteration = 661\n",
      "\n",
      "Shrink model to first 662 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ef65cf7820>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the CatBoost model using PrecisionAt:top=5 evaluation metric\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(iterations=1000,\n",
    "                           learning_rate=0.1,\n",
    "                           depth=6,\n",
    "                           custom_metric='PrecisionAt:top=5',\n",
    "                           eval_metric='PrecisionAt:top=5',\n",
    "                           random_seed=42,\n",
    "                           verbose=100)\n",
    "\n",
    "model.fit(train_pool, eval_set=test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(test_pool)[:, 1]\n",
    "# Add the prediction probabilities to the test dataset\n",
    "X_test['pred_proba'] = y_pred_proba\n",
    "\n",
    "# Group by 'user_id' and find the top 5 predicted 'post_id' for each user\n",
    "top_5_posts = X_test.groupby('user_id').apply(lambda x: x.nlargest(5, 'pred_proba')['post_id_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id          \n",
       "200      63          6919\n",
       "         45          4438\n",
       "         0           5057\n",
       "         41          1864\n",
       "         31          1150\n",
       "                     ... \n",
       "168551   15378364    1390\n",
       "         15378350    2831\n",
       "         15378343    6978\n",
       "168552   15378468    3205\n",
       "         15378439    5246\n",
       "Name: post_id_x, Length: 763361, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HitRate@5: 0.6447881156963307\n"
     ]
    }
   ],
   "source": [
    "def hitrate_at_k(top_k_posts, k=5):\n",
    "    hits = 0\n",
    "    user_data = top_k_posts.groupby(level=0).apply(list).to_dict()\n",
    "\n",
    "    for user_id, top_k_posts in user_data.items():\n",
    "        true_post_ids = X_test[(X_test['user_id'] == user_id) & (y_test == 1)]['post_id_x']\n",
    "        hits += len(set(top_k_posts) & set(true_post_ids))\n",
    "\n",
    "    return hits / len(y_test[y_test == 1])\n",
    "\n",
    "hitrate_at_5 = hitrate_at_k(top_5_posts, k=5)\n",
    "print(\"HitRate@5:\", hitrate_at_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "model.save_model(\"catboost_model.cbm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
