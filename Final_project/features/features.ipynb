{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\n",
    "        \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User data shape: (163205, 8)\n",
      "Post text data shape: (7023, 3)\n"
     ]
    }
   ],
   "source": [
    "# Чтение данных таблицы user_data\n",
    "query = \"SELECT * FROM user_data\"\n",
    "user_data = pd.read_sql(query, engine)\n",
    "print(f\"User data shape: {user_data.shape}\")\n",
    "\n",
    "# Чтение данных таблицы post_text_df\n",
    "query = \"SELECT * FROM post_text_df\"\n",
    "post_text_df = pd.read_sql(query, engine)\n",
    "print(f\"Post text data shape: {post_text_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "def word_count(X):\n",
    "    return np.array([len(re.findall(r'\\b\\w+\\b', text)) for text in X])\n",
    "\n",
    "def sentence_count(X):\n",
    "    return np.array([len(re.findall(r'[.!?]+', text)) for text in X])\n",
    "\n",
    "def avg_word_length(X):\n",
    "    return np.array([sum(len(word) for word in re.findall(r'\\b\\w+\\b', text)) / len(re.findall(r'\\b\\w+\\b', text)) if len(re.findall(r'\\b\\w+\\b', text)) > 0 else 0 for text in X])\n",
    "\n",
    "def punctuation_count(X):\n",
    "    return np.array([sum(1 for char in text if char in punctuation) for text in X])\n",
    "\n",
    "# Apply the feature extraction functions to the 'text' column\n",
    "word_counts = word_count(post_text_df['text'])\n",
    "sentence_counts = sentence_count(post_text_df['text'])\n",
    "avg_word_lengths = avg_word_length(post_text_df['text'])\n",
    "punctuation_counts = punctuation_count(post_text_df['text'])\n",
    "\n",
    "# Add the new features as columns in the user_dataFrame\n",
    "post_text_df['word_count'] = word_counts\n",
    "post_text_df['sentence_count'] = sentence_counts\n",
    "post_text_df['avg_word_length'] = avg_word_lengths\n",
    "post_text_df['punctuation_count'] = punctuation_counts\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_gender = LabelEncoder()\n",
    "le_os = LabelEncoder()\n",
    "le_source = LabelEncoder()\n",
    "le_action = LabelEncoder()\n",
    "\n",
    "# Label encoding for 'gender', 'os', and 'source'\n",
    "user_data['gender'] = le_gender.fit_transform(user_data['gender'])\n",
    "user_data['os'] = le_os.fit_transform(user_data['os'])\n",
    "user_data['source'] = le_source.fit_transform(user_data['source'])\n",
    "post_text_df['topic'] = le_action.fit_transform(post_text_df['topic'])\n",
    "user_data['country'] = le_action.fit_transform(user_data['country'])\n",
    "user_data['city'] = le_action.fit_transform(user_data['city'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed data shape: (76892800, 5)\n"
     ]
    }
   ],
   "source": [
    "# Чтение feed_data из csv файла\n",
    "feed_data = pd.read_csv(r'C:\\Users\\Alex\\Desktop\\feed_data.csv')\n",
    "print(f\"Feed data shape: {feed_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>action</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-26 16:40:07</td>\n",
       "      <td>52431</td>\n",
       "      <td>6920</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-26 16:42:42</td>\n",
       "      <td>52431</td>\n",
       "      <td>3840</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-26 16:45:27</td>\n",
       "      <td>52431</td>\n",
       "      <td>1716</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-26 16:46:39</td>\n",
       "      <td>52431</td>\n",
       "      <td>1054</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-26 16:48:54</td>\n",
       "      <td>52431</td>\n",
       "      <td>963</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  user_id  post_id action  target\n",
       "0  2021-12-26 16:40:07    52431     6920   view       0\n",
       "1  2021-12-26 16:42:42    52431     3840   view       0\n",
       "2  2021-12-26 16:45:27    52431     1716   view       0\n",
       "3  2021-12-26 16:46:39    52431     1054   view       0\n",
       "4  2021-12-26 16:48:54    52431      963   view       0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after load_and_merge_data: (76892800, 12)\n",
      "Index(['timestamp', 'user_id', 'post_id', 'action', 'target', 'gender', 'age',\n",
      "       'country', 'city', 'exp_group', 'os', 'source'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Переименование столбцов идентификаторов\n",
    "user_data = user_data.rename(columns={'id': 'user_id'})\n",
    "post_text_df = post_text_df.rename(columns={'id': 'post_id'})\n",
    "\n",
    "# Объединение таблиц\n",
    "data = feed_data.merge(user_data, on='user_id', how='left')\n",
    "large_data = data.merge(post_text_df, on='post_id', how='left')\n",
    "\n",
    "print(f\"Data shape after load_and_merge_data: {data.shape}\")\n",
    "print(data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обрезание датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data shape: (30757158, 18)\n"
     ]
    }
   ],
   "source": [
    "def sample_10_percent(group):\n",
    "    frac = 0.3\n",
    "    return group.sample(frac=frac)\n",
    "\n",
    "data = large_data.groupby('user_id', group_keys=False).apply(sample_10_percent)\n",
    "print(f\"Sampled data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the large_data\n",
    "large_data = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка временных меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps processed\n",
      "Data shape after timestamps processing: (30757158, 23)\n"
     ]
    }
   ],
   "source": [
    "# Преобразование формата временных меток в объект datetime\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "# Извлечение признаков из временных меток\n",
    "data['month'] = data['timestamp'].dt.month\n",
    "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
    "data['hour_of_day'] = data['timestamp'].dt.hour\n",
    "\n",
    "# Расчет времени с момента последнего действия для каждого пользователя\n",
    "data = data.sort_values(['user_id', 'timestamp'])\n",
    "data['time_since_last_action'] = data.groupby('user_id')['timestamp'].diff().dt.total_seconds()\n",
    "data['time_since_last_action'].fillna(0, inplace=True)\n",
    "\n",
    "# Extracting day of the month and year from the timestamp\n",
    "data['day_of_month'] = data['timestamp'].dt.day\n",
    "data['year'] = data['timestamp'].dt.year\n",
    "\n",
    "# Удаление столбца временных меток\n",
    "data = data.drop('timestamp', axis=1)\n",
    "\n",
    "print('Timestamps processed')\n",
    "print(f\"Data shape after timestamps processing: {data.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание дополнительных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional features created\n",
      "Data shape after additional features creation: (30757158, 25)\n"
     ]
    }
   ],
   "source": [
    "# Feature 1: Количество просмотров и лайков для каждого пользователя\n",
    "user_views_likes = data.groupby('user_id')['action'].value_counts().unstack().fillna(0)\n",
    "user_views_likes.columns = ['user_views', 'user_likes']\n",
    "data = data.merge(user_views_likes, on='user_id', how='left')\n",
    "\n",
    "# Преобразование категориальных признаков в строковый формат\n",
    "categorical_columns = ['country', 'city', 'topic', 'gender', 'os', 'source']\n",
    "data[categorical_columns] = data[categorical_columns].astype(str)\n",
    "\n",
    "print('Additional features created')\n",
    "print(f\"Data shape after additional features creation: {data.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наименование user-based признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'post_id', 'action', 'target', 'gender', 'age', 'country',\n",
      "       'city', 'exp_group', 'os', 'source', 'text', 'topic', 'word_count',\n",
      "       'sentence_count', 'avg_word_length', 'punctuation_count', 'month',\n",
      "       'day_of_week', 'hour_of_day', 'time_since_last_action', 'day_of_month',\n",
      "       'year', 'user_views', 'user_likes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Группировка юзеров с помощью KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Созранение дополнительных признаоков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional features created\n",
      "Data shape after additional features creation: (30757158, 41)\n"
     ]
    }
   ],
   "source": [
    "# Feature 2: Количество просмотров и лайков для каждого поста\n",
    "post_views_likes = data.groupby('post_id')['action'].value_counts().unstack().fillna(0)\n",
    "post_views_likes.columns = ['post_views', 'post_likes']\n",
    "data = data.merge(post_views_likes, on='post_id', how='left')\n",
    "\n",
    "# Feature 3: Количество просмотров и лайков для каждой группы тематик\n",
    "temp_df = data[['exp_group', 'topic', 'action']]\n",
    "\n",
    "# Создание колонок с количеством просмотров и лайков для каждой темы внутри группы\n",
    "topic_action_count = temp_df.pivot_table(index='exp_group', columns=['topic', 'action'], aggfunc=len, fill_value=0)\n",
    "topic_action_count.columns = [f'{col[0]}_exp_group_{col[1]}s' for col in topic_action_count.columns]\n",
    "grouped_data = topic_action_count.reset_index()\n",
    "\n",
    "data = data.merge(grouped_data, on='exp_group', how='left')\n",
    "\n",
    "print('Additional features created')\n",
    "print(f\"Data shape after additional features creation: {data.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated Singular Value Decomposition (Truncated SVD), also known as Latent Semantic Analysis (LSA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m# Initialize TF-IDF vectorizer\u001b[39;00m\n\u001b[0;32m      9\u001b[0m vectorizer \u001b[39m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m---> 10\u001b[0m tfidf_matrix \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     12\u001b[0m \u001b[39m# Initialize SVD\u001b[39;00m\n\u001b[0;32m     13\u001b[0m n_components \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2133\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[0;32m   2127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2128\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[0;32m   2129\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[0;32m   2130\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[0;32m   2131\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[0;32m   2132\u001b[0m )\n\u001b[1;32m-> 2133\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   2134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   2135\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m             )\n\u001b[0;32m   1386\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1391\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1286\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1282\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m   1283\u001b[0m         \u001b[39m# Ignore out-of-vocabulary items for fixed_vocab=True\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m-> 1286\u001b[0m j_indices\u001b[39m.\u001b[39;49mextend(feature_counter\u001b[39m.\u001b[39;49mkeys())\n\u001b[0;32m   1287\u001b[0m values\u001b[39m.\u001b[39mextend(feature_counter\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m   1288\u001b[0m indptr\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(j_indices))\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Take only 'text' and 'target' columns\n",
    "df = data[['text', 'target']]\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Initialize SVD\n",
    "n_components = 10\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "reduced_tfidf_matrix = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "reduced_df = pd.DataFrame(reduced_tfidf_matrix, columns=[f'component_{i}' for i in range(1, n_components+1)])\n",
    "reduced_df['target'] = df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15378483, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "      <th>component_6</th>\n",
       "      <th>component_7</th>\n",
       "      <th>component_8</th>\n",
       "      <th>component_9</th>\n",
       "      <th>component_10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.219580</td>\n",
       "      <td>-0.017638</td>\n",
       "      <td>-0.020689</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>-0.008848</td>\n",
       "      <td>0.049560</td>\n",
       "      <td>0.039237</td>\n",
       "      <td>-0.013185</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.035966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.064687</td>\n",
       "      <td>-0.047597</td>\n",
       "      <td>-0.052248</td>\n",
       "      <td>0.101186</td>\n",
       "      <td>-0.069884</td>\n",
       "      <td>-0.042457</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>-0.021705</td>\n",
       "      <td>-0.011001</td>\n",
       "      <td>-0.030190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.405443</td>\n",
       "      <td>-0.234049</td>\n",
       "      <td>-0.155049</td>\n",
       "      <td>-0.017235</td>\n",
       "      <td>0.087969</td>\n",
       "      <td>-0.060522</td>\n",
       "      <td>-0.073545</td>\n",
       "      <td>0.031013</td>\n",
       "      <td>0.042862</td>\n",
       "      <td>0.043258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.137285</td>\n",
       "      <td>-0.033293</td>\n",
       "      <td>-0.069082</td>\n",
       "      <td>0.106621</td>\n",
       "      <td>-0.068790</td>\n",
       "      <td>0.038433</td>\n",
       "      <td>-0.007784</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>-0.033078</td>\n",
       "      <td>-0.036161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.425986</td>\n",
       "      <td>-0.048044</td>\n",
       "      <td>0.023365</td>\n",
       "      <td>-0.045733</td>\n",
       "      <td>-0.138464</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.049314</td>\n",
       "      <td>-0.041455</td>\n",
       "      <td>-0.039026</td>\n",
       "      <td>-0.057057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   component_1  component_2  component_3  component_4  component_5   \n",
       "0    -0.219580    -0.017638    -0.020689     0.011861    -0.008848  \\\n",
       "1    -0.064687    -0.047597    -0.052248     0.101186    -0.069884   \n",
       "2    -0.405443    -0.234049    -0.155049    -0.017235     0.087969   \n",
       "3    -0.137285    -0.033293    -0.069082     0.106621    -0.068790   \n",
       "4    -0.425986    -0.048044     0.023365    -0.045733    -0.138464   \n",
       "\n",
       "   component_6  component_7  component_8  component_9  component_10  target  \n",
       "0     0.049560     0.039237    -0.013185     0.003749      0.035966       0  \n",
       "1    -0.042457     0.015479    -0.021705    -0.011001     -0.030190       0  \n",
       "2    -0.060522    -0.073545     0.031013     0.042862      0.043258       0  \n",
       "3     0.038433    -0.007784    -0.008507    -0.033078     -0.036161       0  \n",
       "4     0.005685     0.049314    -0.041455    -0.039026     -0.057057       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df['post_id'] = data['post_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id_x</th>\n",
       "      <th>action</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>exp_group</th>\n",
       "      <th>os</th>\n",
       "      <th>...</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "      <th>component_6</th>\n",
       "      <th>component_7</th>\n",
       "      <th>component_8</th>\n",
       "      <th>component_9</th>\n",
       "      <th>component_10</th>\n",
       "      <th>post_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>5057</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>651</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017638</td>\n",
       "      <td>-0.020689</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>-0.008848</td>\n",
       "      <td>0.049560</td>\n",
       "      <td>0.039237</td>\n",
       "      <td>-0.013185</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.035966</td>\n",
       "      <td>5057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>2489</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>651</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047597</td>\n",
       "      <td>-0.052248</td>\n",
       "      <td>0.101186</td>\n",
       "      <td>-0.069884</td>\n",
       "      <td>-0.042457</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>-0.021705</td>\n",
       "      <td>-0.011001</td>\n",
       "      <td>-0.030190</td>\n",
       "      <td>2489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>1244</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>651</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.234049</td>\n",
       "      <td>-0.155049</td>\n",
       "      <td>-0.017235</td>\n",
       "      <td>0.087969</td>\n",
       "      <td>-0.060522</td>\n",
       "      <td>-0.073545</td>\n",
       "      <td>0.031013</td>\n",
       "      <td>0.042862</td>\n",
       "      <td>0.043258</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>3263</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>651</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033293</td>\n",
       "      <td>-0.069082</td>\n",
       "      <td>0.106621</td>\n",
       "      <td>-0.068790</td>\n",
       "      <td>0.038433</td>\n",
       "      <td>-0.007784</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>-0.033078</td>\n",
       "      <td>-0.036161</td>\n",
       "      <td>3263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>668</td>\n",
       "      <td>like</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>651</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048044</td>\n",
       "      <td>0.023365</td>\n",
       "      <td>-0.045733</td>\n",
       "      <td>-0.138464</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.049314</td>\n",
       "      <td>-0.041455</td>\n",
       "      <td>-0.039026</td>\n",
       "      <td>-0.057057</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  post_id_x action  target gender  age country city  exp_group os   \n",
       "0      200       5057   view       0      1   34       7  651          3  0  \\\n",
       "1      200       2489   view       0      1   34       7  651          3  0   \n",
       "2      200       1244   view       0      1   34       7  651          3  0   \n",
       "3      200       3263   view       0      1   34       7  651          3  0   \n",
       "4      200        668   like       0      1   34       7  651          3  0   \n",
       "\n",
       "   ... component_2 component_3 component_4  component_5  component_6   \n",
       "0  ...   -0.017638   -0.020689    0.011861    -0.008848     0.049560  \\\n",
       "1  ...   -0.047597   -0.052248    0.101186    -0.069884    -0.042457   \n",
       "2  ...   -0.234049   -0.155049   -0.017235     0.087969    -0.060522   \n",
       "3  ...   -0.033293   -0.069082    0.106621    -0.068790     0.038433   \n",
       "4  ...   -0.048044    0.023365   -0.045733    -0.138464     0.005685   \n",
       "\n",
       "   component_7  component_8  component_9  component_10  post_id_y  \n",
       "0     0.039237    -0.013185     0.003749      0.035966       5057  \n",
       "1     0.015479    -0.021705    -0.011001     -0.030190       2489  \n",
       "2    -0.073545     0.031013     0.042862      0.043258       1244  \n",
       "3    -0.007784    -0.008507    -0.033078     -0.036161       3263  \n",
       "4     0.049314    -0.041455    -0.039026     -0.057057        668  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge reduced_df with data\n",
    "reduced_df.drop('target', axis=1, inplace=True)\n",
    "data = data.merge(reduced_df, left_index=True, right_index=True, how='left')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'post_id_x', 'action', 'target', 'gender', 'age', 'country',\n",
      "       'city', 'exp_group', 'os', 'source', 'text', 'topic', 'word_count',\n",
      "       'sentence_count', 'avg_word_length', 'punctuation_count', 'month',\n",
      "       'day_of_week', 'hour_of_day', 'time_since_last_action', 'day_of_month',\n",
      "       'year', 'user_views', 'user_likes', 'post_views', 'post_likes',\n",
      "       '0_exp_group_likes', '0_exp_group_views', '1_exp_group_likes',\n",
      "       '1_exp_group_views', '2_exp_group_likes', '2_exp_group_views',\n",
      "       '3_exp_group_likes', '3_exp_group_views', '4_exp_group_likes',\n",
      "       '4_exp_group_views', '5_exp_group_likes', '5_exp_group_views',\n",
      "       '6_exp_group_likes', '6_exp_group_views', 'component_1', 'component_2',\n",
      "       'component_3', 'component_4', 'component_5', 'component_6',\n",
      "       'component_7', 'component_8', 'component_9', 'component_10',\n",
      "       'post_id_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print data columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the text column\n",
    "data.drop('text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data_for_training to csv in desctop\n",
    "import os\n",
    "\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "file_path = os.path.join(desktop_path, \"04_data_for_training.csv\")\n",
    "\n",
    "data.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
