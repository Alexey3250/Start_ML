{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут мы реализуем сервис записи фичей в новую таблицу для того чтобы не загружать основной алгоритм обработкой данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка фичей из базы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "def load_and_merge_data(engine, chunksize=200000):\n",
    "    # Чтение данных таблицы user_data\n",
    "    query = \"SELECT * FROM user_data\"\n",
    "    user_data = pd.read_sql(query, engine)\n",
    "    print(f\"User data shape: {user_data.shape}\")\n",
    "\n",
    "    # Чтение данных таблицы post_text_df\n",
    "    query = \"SELECT * FROM post_text_df\"\n",
    "    post_text_df = pd.read_sql(query, engine)\n",
    "    print(f\"Post text data shape: {post_text_df.shape}\")\n",
    "\n",
    "    # Чтение ограниченного количества данных таблицы feed_data\n",
    "    query = f\"SELECT * FROM feed_data\"\n",
    "    feed_data = batch_load_sql_timed(engine, query, chunksize)\n",
    "    print(f\"Feed data shape: {feed_data.shape}\")\n",
    "\n",
    "    # Переименование столбцов идентификаторов\n",
    "    user_data = user_data.rename(columns={'id': 'user_id'})\n",
    "    post_text_df = post_text_df.rename(columns={'id': 'post_id'})\n",
    "\n",
    "    # Объединение таблиц\n",
    "    data = feed_data.merge(user_data, on='user_id', how='left')\n",
    "    data = data.merge(post_text_df, on='post_id', how='left')\n",
    "\n",
    "    print(f\"Data shape after load_and_merge_data: {data.shape}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def batch_load_sql(engine, query: str, chunksize: int) -> pd.DataFrame:\n",
    "    conn = engine.connect().execution_options(stream_results=True)\n",
    "    chunks = []\n",
    "    for chunk_dataframe in pd.read_sql(query, conn, chunksize=chunksize):\n",
    "        chunks.append(chunk_dataframe)\n",
    "    conn.close()\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "import time\n",
    "\n",
    "def batch_load_sql_timed(engine, query: str, chunksize: int) -> pd.DataFrame:\n",
    "    conn = engine.connect().execution_options(stream_results=True)\n",
    "    chunks = []\n",
    "    row_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for chunk_dataframe in pd.read_sql(query, conn, chunksize=chunksize):\n",
    "        chunks.append(chunk_dataframe)\n",
    "        row_count += len(chunk_dataframe)\n",
    "        print(f\"Loaded {row_count} rows, elapsed time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    conn.close()\n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "        \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )\n",
    "\n",
    "chunksize = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User data shape: (163205, 8)\n"
     ]
    }
   ],
   "source": [
    "# Чтение данных таблицы user_data\n",
    "query = \"SELECT * FROM user_data\"\n",
    "user_data = pd.read_sql(query, engine)\n",
    "print(f\"User data shape: {user_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post text data shape: (7023, 3)\n"
     ]
    }
   ],
   "source": [
    "# Чтение данных таблицы post_text_df\n",
    "query = \"SELECT * FROM post_text_df\"\n",
    "post_text_df = pd.read_sql(query, engine)\n",
    "print(f\"Post text data shape: {post_text_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def batch_load_sql_timed(engine, query: str, chunksize: int) -> pd.DataFrame:\n",
    "    conn = engine.connect().execution_options(stream_results=True)\n",
    "    chunks = []\n",
    "    row_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for chunk_dataframe in pd.read_sql(query, conn, chunksize=chunksize):\n",
    "        chunks.append(chunk_dataframe)\n",
    "        row_count += len(chunk_dataframe)\n",
    "        print(f\"Loaded {row_count} rows, elapsed time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    conn.close()\n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000000 rows, elapsed time: 23.64 seconds\n",
      "Loaded 2000000 rows, elapsed time: 39.26 seconds\n",
      "Loaded 3000000 rows, elapsed time: 56.54 seconds\n",
      "Loaded 4000000 rows, elapsed time: 70.47 seconds\n",
      "Loaded 5000000 rows, elapsed time: 91.23 seconds\n",
      "Loaded 6000000 rows, elapsed time: 118.89 seconds\n",
      "Loaded 7000000 rows, elapsed time: 140.45 seconds\n",
      "Loaded 8000000 rows, elapsed time: 166.71 seconds\n",
      "Loaded 9000000 rows, elapsed time: 203.59 seconds\n",
      "Loaded 10000000 rows, elapsed time: 228.68 seconds\n",
      "Loaded 11000000 rows, elapsed time: 253.18 seconds\n",
      "Loaded 12000000 rows, elapsed time: 276.47 seconds\n",
      "Loaded 13000000 rows, elapsed time: 303.22 seconds\n",
      "Loaded 14000000 rows, elapsed time: 323.59 seconds\n",
      "Loaded 15000000 rows, elapsed time: 348.35 seconds\n",
      "Loaded 16000000 rows, elapsed time: 380.08 seconds\n",
      "Loaded 17000000 rows, elapsed time: 416.70 seconds\n",
      "Loaded 18000000 rows, elapsed time: 436.11 seconds\n",
      "Loaded 19000000 rows, elapsed time: 453.57 seconds\n",
      "Loaded 20000000 rows, elapsed time: 478.46 seconds\n",
      "Loaded 21000000 rows, elapsed time: 500.26 seconds\n",
      "Loaded 22000000 rows, elapsed time: 528.71 seconds\n",
      "Loaded 23000000 rows, elapsed time: 557.44 seconds\n",
      "Loaded 24000000 rows, elapsed time: 578.53 seconds\n",
      "Loaded 25000000 rows, elapsed time: 606.52 seconds\n",
      "Loaded 26000000 rows, elapsed time: 626.56 seconds\n",
      "Loaded 27000000 rows, elapsed time: 645.16 seconds\n",
      "Loaded 28000000 rows, elapsed time: 665.11 seconds\n",
      "Loaded 29000000 rows, elapsed time: 690.97 seconds\n",
      "Loaded 30000000 rows, elapsed time: 715.80 seconds\n",
      "Loaded 31000000 rows, elapsed time: 738.52 seconds\n",
      "Loaded 32000000 rows, elapsed time: 762.28 seconds\n",
      "Loaded 33000000 rows, elapsed time: 786.50 seconds\n",
      "Loaded 34000000 rows, elapsed time: 805.40 seconds\n",
      "Loaded 35000000 rows, elapsed time: 835.91 seconds\n",
      "Loaded 36000000 rows, elapsed time: 867.21 seconds\n",
      "Loaded 37000000 rows, elapsed time: 884.45 seconds\n",
      "Loaded 38000000 rows, elapsed time: 906.22 seconds\n",
      "Loaded 39000000 rows, elapsed time: 925.53 seconds\n",
      "Loaded 40000000 rows, elapsed time: 952.91 seconds\n",
      "Loaded 41000000 rows, elapsed time: 976.38 seconds\n",
      "Loaded 42000000 rows, elapsed time: 1002.91 seconds\n",
      "Loaded 43000000 rows, elapsed time: 1025.30 seconds\n",
      "Loaded 44000000 rows, elapsed time: 1053.94 seconds\n",
      "Loaded 45000000 rows, elapsed time: 1087.53 seconds\n",
      "Loaded 46000000 rows, elapsed time: 1116.82 seconds\n",
      "Loaded 47000000 rows, elapsed time: 1142.10 seconds\n",
      "Loaded 48000000 rows, elapsed time: 1164.98 seconds\n",
      "Loaded 49000000 rows, elapsed time: 1201.37 seconds\n",
      "Loaded 50000000 rows, elapsed time: 1232.64 seconds\n",
      "Loaded 51000000 rows, elapsed time: 1261.30 seconds\n",
      "Loaded 52000000 rows, elapsed time: 1301.42 seconds\n",
      "Loaded 53000000 rows, elapsed time: 1342.09 seconds\n",
      "Loaded 54000000 rows, elapsed time: 1368.71 seconds\n",
      "Loaded 55000000 rows, elapsed time: 1405.62 seconds\n",
      "Loaded 56000000 rows, elapsed time: 1444.07 seconds\n",
      "Loaded 57000000 rows, elapsed time: 1484.94 seconds\n",
      "Loaded 58000000 rows, elapsed time: 1519.21 seconds\n",
      "Loaded 59000000 rows, elapsed time: 1545.34 seconds\n",
      "Loaded 60000000 rows, elapsed time: 1579.66 seconds\n",
      "Loaded 61000000 rows, elapsed time: 1610.69 seconds\n",
      "Loaded 62000000 rows, elapsed time: 1644.03 seconds\n",
      "Loaded 63000000 rows, elapsed time: 1684.43 seconds\n",
      "Loaded 64000000 rows, elapsed time: 1713.15 seconds\n",
      "Loaded 65000000 rows, elapsed time: 1749.66 seconds\n",
      "Loaded 66000000 rows, elapsed time: 1777.06 seconds\n",
      "Loaded 67000000 rows, elapsed time: 1812.21 seconds\n",
      "Loaded 68000000 rows, elapsed time: 1844.32 seconds\n",
      "Loaded 69000000 rows, elapsed time: 1870.79 seconds\n",
      "Loaded 70000000 rows, elapsed time: 1890.98 seconds\n",
      "Loaded 71000000 rows, elapsed time: 1914.96 seconds\n",
      "Loaded 72000000 rows, elapsed time: 1939.42 seconds\n",
      "Loaded 73000000 rows, elapsed time: 1967.44 seconds\n",
      "Loaded 74000000 rows, elapsed time: 1997.05 seconds\n",
      "Loaded 75000000 rows, elapsed time: 2031.61 seconds\n",
      "Loaded 76000000 rows, elapsed time: 2062.43 seconds\n",
      "Loaded 76892800 rows, elapsed time: 2100.90 seconds\n",
      "Feed data shape: (76892800, 5)\n"
     ]
    }
   ],
   "source": [
    "# Чтение ограниченного количества данных таблицы feed_data\n",
    "query = \"SELECT * FROM feed_data\"\n",
    "feed_data = batch_load_sql_timed(engine, query, chunksize)\n",
    "print(f\"Feed data shape: {feed_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after load_and_merge_data: (76892800, 14)\n"
     ]
    }
   ],
   "source": [
    "# Переименование столбцов идентификаторов\n",
    "user_data = user_data.rename(columns={'id': 'user_id'})\n",
    "post_text_df = post_text_df.rename(columns={'id': 'post_id'})\n",
    "\n",
    "# Объединение таблиц\n",
    "data = feed_data.merge(user_data, on='user_id', how='left')\n",
    "data = data.merge(post_text_df, on='post_id', how='left')\n",
    "\n",
    "print(f\"Data shape after load_and_merge_data: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка временных меток"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding year and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps processed\n",
      "Data shape after timestamps processing: (76892800, 18)\n"
     ]
    }
   ],
   "source": [
    "# Преобразование формата временных меток в объект datetime\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "# Извлечение признаков из временных меток\n",
    "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
    "data['hour_of_day'] = data['timestamp'].dt.hour\n",
    "\n",
    "# Расчет времени с момента последнего действия для каждого пользователя\n",
    "data = data.sort_values(['user_id', 'timestamp'])\n",
    "data['time_since_last_action'] = data.groupby('user_id')['timestamp'].diff().dt.total_seconds()\n",
    "data['time_since_last_action'].fillna(0, inplace=True)\n",
    "\n",
    "# Extracting day of the month and year from the timestamp\n",
    "data['day_of_month'] = data['timestamp'].dt.day\n",
    "data['year'] = data['timestamp'].dt.year\n",
    "\n",
    "# Удаление столбца временных меток\n",
    "data = data.drop('timestamp', axis=1)\n",
    "\n",
    "print('Timestamps processed')\n",
    "print(f\"Data shape after timestamps processing: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание дополнительных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional features created\n",
      "Data shape after additional features creation: (76892800, 36)\n"
     ]
    }
   ],
   "source": [
    "# Feature 1: Количество просмотров и лайков для каждого пользователя\n",
    "user_views_likes = data.groupby('user_id')['action'].value_counts().unstack().fillna(0)\n",
    "user_views_likes.columns = ['user_views', 'user_likes']\n",
    "data = data.merge(user_views_likes, on='user_id', how='left')\n",
    "\n",
    "# Feature 2: Количество просмотров и лайков для каждого поста\n",
    "post_views_likes = data.groupby('post_id')['action'].value_counts().unstack().fillna(0)\n",
    "post_views_likes.columns = ['post_views', 'post_likes']\n",
    "data = data.merge(post_views_likes, on='post_id', how='left')\n",
    "\n",
    "# Feature 3: Количество просмотров и лайков для каждой группы тематик\n",
    "temp_df = data[['exp_group', 'topic', 'action']]\n",
    "\n",
    "# Создание колонок с количеством просмотров и лайков для каждой темы внутри группы\n",
    "topic_action_count = temp_df.pivot_table(index='exp_group', columns=['topic', 'action'], aggfunc=len, fill_value=0)\n",
    "topic_action_count.columns = [f'{col[0]}_exp_group_{col[1]}s' for col in topic_action_count.columns]\n",
    "grouped_data = topic_action_count.reset_index()\n",
    "\n",
    "data = data.merge(grouped_data, on='exp_group', how='left')\n",
    "\n",
    "# Преобразование категориальных признаков в строковый формат\n",
    "categorical_columns = ['country', 'city', 'topic', 'gender', 'os', 'source']\n",
    "data[categorical_columns] = data[categorical_columns].astype(str)\n",
    "\n",
    "print('Additional features created')\n",
    "print(f\"Data shape after additional features creation: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>action</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>exp_group</th>\n",
       "      <th>os</th>\n",
       "      <th>...</th>\n",
       "      <th>entertainment_exp_group_likes</th>\n",
       "      <th>entertainment_exp_group_views</th>\n",
       "      <th>movie_exp_group_likes</th>\n",
       "      <th>movie_exp_group_views</th>\n",
       "      <th>politics_exp_group_likes</th>\n",
       "      <th>politics_exp_group_views</th>\n",
       "      <th>sport_exp_group_likes</th>\n",
       "      <th>sport_exp_group_views</th>\n",
       "      <th>tech_exp_group_likes</th>\n",
       "      <th>tech_exp_group_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>5057</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>4872</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>5431</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>6829</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>3146</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  post_id action  target gender  age country       city  exp_group   \n",
       "0      200     5057   view       0      1   34  Russia  Degtyarsk          3  \\\n",
       "1      200     4872   view       0      1   34  Russia  Degtyarsk          3   \n",
       "2      200     5431   view       0      1   34  Russia  Degtyarsk          3   \n",
       "3      200     6829   view       0      1   34  Russia  Degtyarsk          3   \n",
       "4      200     3146   view       0      1   34  Russia  Degtyarsk          3   \n",
       "\n",
       "        os  ... entertainment_exp_group_likes entertainment_exp_group_views   \n",
       "0  Android  ...                         67970                        697043  \\\n",
       "1  Android  ...                         67970                        697043   \n",
       "2  Android  ...                         67970                        697043   \n",
       "3  Android  ...                         67970                        697043   \n",
       "4  Android  ...                         67970                        697043   \n",
       "\n",
       "  movie_exp_group_likes  movie_exp_group_views  politics_exp_group_likes   \n",
       "0                486469                5091113                    123438  \\\n",
       "1                486469                5091113                    123438   \n",
       "2                486469                5091113                    123438   \n",
       "3                486469                5091113                    123438   \n",
       "4                486469                5091113                    123438   \n",
       "\n",
       "   politics_exp_group_views  sport_exp_group_likes  sport_exp_group_views   \n",
       "0                   1386641                 180690                1828124  \\\n",
       "1                   1386641                 180690                1828124   \n",
       "2                   1386641                 180690                1828124   \n",
       "3                   1386641                 180690                1828124   \n",
       "4                   1386641                 180690                1828124   \n",
       "\n",
       "   tech_exp_group_likes  tech_exp_group_views  \n",
       "0                 41879                559936  \n",
       "1                 41879                559936  \n",
       "2                 41879                559936  \n",
       "3                 41879                559936  \n",
       "4                 41879                559936  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to a-efimik_features_lesson_22:   0%|          | 3/769 [23:49<100:32:03, 472.48s/it]"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def upload_dataframe_in_chunks(data, table_name, engine, chunksize=10000):\n",
    "    total_chunks = math.ceil(len(data) / chunksize)\n",
    "    for i in tqdm(range(total_chunks), desc=f\"Uploading to {table_name}\"):\n",
    "        chunk = data[i * chunksize : (i + 1) * chunksize]\n",
    "        if_exists = \"replace\" if i == 0 else \"append\"\n",
    "        chunk.to_sql(table_name, con=engine, if_exists=if_exists, index=False, method=\"multi\")\n",
    "\n",
    "chunksize = 100000\n",
    "upload_dataframe_in_chunks(data, \"a-efimik_features_lesson_22\", engine, chunksize=chunksize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.SyntaxError) syntax error at or near \"-\"\nLINE 1: SELECT * FROM a-efimik_features_lesson_22 LIMIT 1000\n                       ^\n\n[SQL: SELECT * FROM a-efimik_features_lesson_22 LIMIT 1000]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1963\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1964\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1965\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[0;32m   1966\u001b[0m         )\n\u001b[0;32m   1968\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\default.py:748\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 748\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mSyntaxError\u001b[0m: syntax error at or near \"-\"\nLINE 1: SELECT * FROM a-efimik_features_lesson_22 LIMIT 1000\n                       ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql(\u001b[39m'\u001b[39;49m\u001b[39mSELECT * FROM a-efimik_features_lesson_22 LIMIT 1000\u001b[39;49m\u001b[39m'\u001b[39;49m, con\u001b[39m=\u001b[39;49mengine) \u001b[39m# считываем таблицу\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:661\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    651\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    652\u001b[0m         sql,\n\u001b[0;32m    653\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    658\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    659\u001b[0m     )\n\u001b[0;32m    660\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 661\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[0;32m    662\u001b[0m         sql,\n\u001b[0;32m    663\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    664\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    665\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[0;32m    666\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    667\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    668\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    669\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    670\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:1736\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[0;32m   1680\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1681\u001b[0m     sql: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     dtype_backend: DtypeBackend \u001b[39m|\u001b[39m Literal[\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1689\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   1690\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1691\u001b[0m \u001b[39m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1692\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \n\u001b[0;32m   1735\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1736\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(sql, params)\n\u001b[0;32m   1737\u001b[0m     columns \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mkeys()\n\u001b[0;32m   1739\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:1560\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   1558\u001b[0m args \u001b[39m=\u001b[39m [] \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m [params]\n\u001b[0;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(sql, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 1560\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcon\u001b[39m.\u001b[39;49mexec_driver_sql(sql, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1561\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon\u001b[39m.\u001b[39mexecute(sql, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1772\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1767\u001b[0m execution_options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execution_options\u001b[39m.\u001b[39mmerge_with(\n\u001b[0;32m   1768\u001b[0m     execution_options\n\u001b[0;32m   1769\u001b[0m )\n\u001b[0;32m   1771\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[1;32m-> 1772\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[0;32m   1773\u001b[0m     dialect,\n\u001b[0;32m   1774\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_statement,\n\u001b[0;32m   1775\u001b[0m     statement,\n\u001b[0;32m   1776\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1777\u001b[0m     execution_options,\n\u001b[0;32m   1778\u001b[0m     statement,\n\u001b[0;32m   1779\u001b[0m     distilled_parameters,\n\u001b[0;32m   1780\u001b[0m )\n\u001b[0;32m   1782\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1842\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1837\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[0;32m   1838\u001b[0m         dialect,\n\u001b[0;32m   1839\u001b[0m         context,\n\u001b[0;32m   1840\u001b[0m     )\n\u001b[0;32m   1841\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1842\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[0;32m   1843\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1980\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1982\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1983\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[0;32m   1984\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[0;32m   1985\u001b[0m     )\n\u001b[0;32m   1987\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2326\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2324\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2325\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2326\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   2327\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2328\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1962\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1963\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1964\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1965\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[0;32m   1966\u001b[0m         )\n\u001b[0;32m   1968\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[0;32m   1969\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1970\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1971\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1975\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[0;32m   1976\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\default.py:748\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 748\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (psycopg2.errors.SyntaxError) syntax error at or near \"-\"\nLINE 1: SELECT * FROM a-efimik_features_lesson_22 LIMIT 1000\n                       ^\n\n[SQL: SELECT * FROM a-efimik_features_lesson_22 LIMIT 1000]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql('SELECT * FROM a-efimik_features_lesson_22 LIMIT 1000', con=engine) # считываем таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>action</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>exp_group</th>\n",
       "      <th>...</th>\n",
       "      <th>entertainment_exp_group_likes</th>\n",
       "      <th>entertainment_exp_group_views</th>\n",
       "      <th>movie_exp_group_likes</th>\n",
       "      <th>movie_exp_group_views</th>\n",
       "      <th>politics_exp_group_likes</th>\n",
       "      <th>politics_exp_group_views</th>\n",
       "      <th>sport_exp_group_likes</th>\n",
       "      <th>sport_exp_group_views</th>\n",
       "      <th>tech_exp_group_likes</th>\n",
       "      <th>tech_exp_group_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, user_id, post_id, action, target, gender, age, country, city, exp_group, os, source, text, topic, day_of_week, hour_of_day, time_since_last_action, user_views, user_likes, post_views, post_likes, business_exp_group_likes, business_exp_group_views, covid_exp_group_likes, covid_exp_group_views, entertainment_exp_group_likes, entertainment_exp_group_views, movie_exp_group_likes, movie_exp_group_views, politics_exp_group_likes, politics_exp_group_views, sport_exp_group_likes, sport_exp_group_views, tech_exp_group_likes, tech_exp_group_views]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 35 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6v/_xvyw44141s6_68z7m_2yyp80000gn/T/ipykernel_22973/1472378890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем ненужные столбцы\n",
    "X = data.drop(['target', 'action', 'text'], axis=1)\n",
    "\n",
    "categorical_columns = ['country', 'topic', 'city', 'gender', 'os', 'source']\n",
    "\n",
    "# Создание ID группы на основе столбца 'user_id'\n",
    "unique_user_ids = X['user_id'].unique()\n",
    "group_id_dict = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}\n",
    "X['group_id'] = X['user_id'].map(group_id_dict)\n",
    "\n",
    "# Сортировка набора данных для предсказаний по 'group_id'\n",
    "X = X.sort_values(by='group_id')\n",
    "\n",
    "# Убедитесь, что категориальные переменные представлены в виде строк\n",
    "X[categorical_columns] = X[categorical_columns].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запись фичей в базу данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# То что будет в сервисе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool\n",
    "\n",
    "## TODO: надо просто передать лист с индексами категориальных признаков\n",
    "# Получение индексов категориальных столбцов\n",
    "cat_features = [X.drop(columns=['user_id']).columns.get_loc(col) for col in categorical_columns]\n",
    "\n",
    "# Создание объекта Pool для набора данных предсказаний с колонкой 'group_id' и категориальными признаками\n",
    "prediction_pool = Pool(X.drop(columns=['user_id']), cat_features=cat_features, group_id=X['group_id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5525e501b23e2010ab883f77d6209697fb9a7ecd2dc8bb136f049441ff2c9ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
