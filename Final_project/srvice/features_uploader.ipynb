{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут мы реализуем сервис записи фичей в новую таблицу для того чтобы не загружать основной алгоритм обработкой данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка фичей из базы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "def load_and_merge_data(engine, chunksize=200000):\n",
    "    # Чтение данных таблицы user_data\n",
    "    query = \"SELECT * FROM user_data\"\n",
    "    user_data = pd.read_sql(query, engine)\n",
    "    print(f\"User data shape: {user_data.shape}\")\n",
    "\n",
    "    # Чтение данных таблицы post_text_df\n",
    "    query = \"SELECT * FROM post_text_df\"\n",
    "    post_text_df = pd.read_sql(query, engine)\n",
    "    print(f\"Post text data shape: {post_text_df.shape}\")\n",
    "\n",
    "    # Чтение ограниченного количества данных таблицы feed_data\n",
    "    query = f\"SELECT * FROM feed_data\"\n",
    "    feed_data = batch_load_sql_timed(engine, query, chunksize)\n",
    "    print(f\"Feed data shape: {feed_data.shape}\")\n",
    "\n",
    "    # Переименование столбцов идентификаторов\n",
    "    user_data = user_data.rename(columns={'id': 'user_id'})\n",
    "    post_text_df = post_text_df.rename(columns={'id': 'post_id'})\n",
    "\n",
    "    # Объединение таблиц\n",
    "    data = feed_data.merge(user_data, on='user_id', how='left')\n",
    "    data = data.merge(post_text_df, on='post_id', how='left')\n",
    "\n",
    "    print(f\"Data shape after load_and_merge_data: {data.shape}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def batch_load_sql(engine, query: str, chunksize: int) -> pd.DataFrame:\n",
    "    conn = engine.connect().execution_options(stream_results=True)\n",
    "    chunks = []\n",
    "    for chunk_dataframe in pd.read_sql(query, conn, chunksize=chunksize):\n",
    "        chunks.append(chunk_dataframe)\n",
    "    conn.close()\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "import time\n",
    "\n",
    "def batch_load_sql_timed(engine, query: str, chunksize: int) -> pd.DataFrame:\n",
    "    conn = engine.connect().execution_options(stream_results=True)\n",
    "    chunks = []\n",
    "    row_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for chunk_dataframe in pd.read_sql(query, conn, chunksize=chunksize):\n",
    "        chunks.append(chunk_dataframe)\n",
    "        row_count += len(chunk_dataframe)\n",
    "        print(f\"Loaded {row_count} rows, elapsed time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    conn.close()\n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "        \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )\n",
    "\n",
    "chunksize = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User data shape: (163205, 8)\n"
     ]
    }
   ],
   "source": [
    "# Чтение данных таблицы user_data\n",
    "query = \"SELECT * FROM user_data\"\n",
    "user_data = pd.read_sql(query, engine)\n",
    "print(f\"User data shape: {user_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post text data shape: (7023, 3)\n"
     ]
    }
   ],
   "source": [
    "# Чтение данных таблицы post_text_df\n",
    "query = \"SELECT * FROM post_text_df\"\n",
    "post_text_df = pd.read_sql(query, engine)\n",
    "print(f\"Post text data shape: {post_text_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def batch_load_sql_timed(engine, query: str, chunksize: int) -> pd.DataFrame:\n",
    "    conn = engine.connect().execution_options(stream_results=True)\n",
    "    chunks = []\n",
    "    row_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for chunk_dataframe in pd.read_sql(query, conn, chunksize=chunksize):\n",
    "        chunks.append(chunk_dataframe)\n",
    "        row_count += len(chunk_dataframe)\n",
    "        print(f\"Loaded {row_count} rows, elapsed time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    conn.close()\n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000000 rows, elapsed time: 21.91 seconds\n",
      "Loaded 2000000 rows, elapsed time: 42.54 seconds\n",
      "Loaded 3000000 rows, elapsed time: 69.46 seconds\n",
      "Loaded 4000000 rows, elapsed time: 90.11 seconds\n",
      "Loaded 5000000 rows, elapsed time: 110.14 seconds\n",
      "Loaded 6000000 rows, elapsed time: 130.89 seconds\n",
      "Loaded 7000000 rows, elapsed time: 150.95 seconds\n",
      "Loaded 8000000 rows, elapsed time: 175.28 seconds\n",
      "Loaded 9000000 rows, elapsed time: 203.56 seconds\n",
      "Loaded 10000000 rows, elapsed time: 235.35 seconds\n",
      "Loaded 11000000 rows, elapsed time: 264.20 seconds\n",
      "Loaded 12000000 rows, elapsed time: 292.51 seconds\n",
      "Loaded 13000000 rows, elapsed time: 311.50 seconds\n",
      "Loaded 14000000 rows, elapsed time: 339.91 seconds\n",
      "Loaded 15000000 rows, elapsed time: 369.02 seconds\n",
      "Loaded 16000000 rows, elapsed time: 396.95 seconds\n",
      "Loaded 17000000 rows, elapsed time: 420.77 seconds\n",
      "Loaded 18000000 rows, elapsed time: 444.33 seconds\n",
      "Loaded 19000000 rows, elapsed time: 474.09 seconds\n",
      "Loaded 20000000 rows, elapsed time: 513.10 seconds\n",
      "Loaded 21000000 rows, elapsed time: 542.92 seconds\n",
      "Loaded 22000000 rows, elapsed time: 560.92 seconds\n",
      "Loaded 23000000 rows, elapsed time: 581.23 seconds\n",
      "Loaded 24000000 rows, elapsed time: 606.29 seconds\n",
      "Loaded 25000000 rows, elapsed time: 631.60 seconds\n",
      "Loaded 26000000 rows, elapsed time: 655.29 seconds\n",
      "Loaded 27000000 rows, elapsed time: 677.12 seconds\n",
      "Loaded 28000000 rows, elapsed time: 696.56 seconds\n",
      "Loaded 29000000 rows, elapsed time: 717.92 seconds\n",
      "Loaded 30000000 rows, elapsed time: 742.18 seconds\n",
      "Loaded 31000000 rows, elapsed time: 765.09 seconds\n",
      "Loaded 32000000 rows, elapsed time: 785.08 seconds\n",
      "Loaded 33000000 rows, elapsed time: 808.55 seconds\n",
      "Loaded 34000000 rows, elapsed time: 836.24 seconds\n",
      "Loaded 35000000 rows, elapsed time: 859.37 seconds\n",
      "Loaded 36000000 rows, elapsed time: 882.52 seconds\n",
      "Loaded 37000000 rows, elapsed time: 906.99 seconds\n",
      "Loaded 38000000 rows, elapsed time: 929.91 seconds\n",
      "Loaded 39000000 rows, elapsed time: 951.43 seconds\n",
      "Loaded 40000000 rows, elapsed time: 972.51 seconds\n",
      "Loaded 41000000 rows, elapsed time: 996.87 seconds\n",
      "Loaded 42000000 rows, elapsed time: 1019.01 seconds\n",
      "Loaded 43000000 rows, elapsed time: 1044.43 seconds\n",
      "Loaded 44000000 rows, elapsed time: 1071.99 seconds\n",
      "Loaded 45000000 rows, elapsed time: 1094.27 seconds\n",
      "Loaded 46000000 rows, elapsed time: 1110.47 seconds\n",
      "Loaded 47000000 rows, elapsed time: 1133.47 seconds\n",
      "Loaded 48000000 rows, elapsed time: 1159.69 seconds\n",
      "Loaded 49000000 rows, elapsed time: 1187.37 seconds\n",
      "Loaded 50000000 rows, elapsed time: 1206.61 seconds\n",
      "Loaded 51000000 rows, elapsed time: 1229.84 seconds\n",
      "Loaded 52000000 rows, elapsed time: 1251.17 seconds\n",
      "Loaded 53000000 rows, elapsed time: 1284.76 seconds\n",
      "Loaded 54000000 rows, elapsed time: 1329.37 seconds\n",
      "Loaded 55000000 rows, elapsed time: 1349.81 seconds\n",
      "Loaded 56000000 rows, elapsed time: 1364.30 seconds\n",
      "Loaded 57000000 rows, elapsed time: 1384.86 seconds\n",
      "Loaded 58000000 rows, elapsed time: 1406.62 seconds\n",
      "Loaded 59000000 rows, elapsed time: 1426.20 seconds\n",
      "Loaded 60000000 rows, elapsed time: 1448.68 seconds\n",
      "Loaded 61000000 rows, elapsed time: 1473.11 seconds\n",
      "Loaded 62000000 rows, elapsed time: 1496.81 seconds\n",
      "Loaded 63000000 rows, elapsed time: 1524.19 seconds\n",
      "Loaded 64000000 rows, elapsed time: 1544.24 seconds\n",
      "Loaded 65000000 rows, elapsed time: 1566.49 seconds\n",
      "Loaded 66000000 rows, elapsed time: 1586.68 seconds\n",
      "Loaded 67000000 rows, elapsed time: 1609.41 seconds\n",
      "Loaded 68000000 rows, elapsed time: 1631.69 seconds\n",
      "Loaded 69000000 rows, elapsed time: 1658.68 seconds\n",
      "Loaded 70000000 rows, elapsed time: 1683.65 seconds\n",
      "Loaded 71000000 rows, elapsed time: 1705.87 seconds\n",
      "Loaded 72000000 rows, elapsed time: 1722.47 seconds\n",
      "Loaded 73000000 rows, elapsed time: 1742.40 seconds\n",
      "Loaded 74000000 rows, elapsed time: 1768.31 seconds\n",
      "Loaded 75000000 rows, elapsed time: 1789.80 seconds\n",
      "Loaded 76000000 rows, elapsed time: 1811.67 seconds\n",
      "Loaded 76892800 rows, elapsed time: 1828.88 seconds\n",
      "Feed data shape: (76892800, 5)\n"
     ]
    }
   ],
   "source": [
    "# Чтение ограниченного количества данных таблицы feed_data\n",
    "query = \"SELECT * FROM feed_data\"\n",
    "feed_data = batch_load_sql_timed(engine, query, chunksize)\n",
    "print(f\"Feed data shape: {feed_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after load_and_merge_data: (76892800, 14)\n"
     ]
    }
   ],
   "source": [
    "# Переименование столбцов идентификаторов\n",
    "user_data = user_data.rename(columns={'id': 'user_id'})\n",
    "post_text_df = post_text_df.rename(columns={'id': 'post_id'})\n",
    "\n",
    "# Объединение таблиц\n",
    "data = feed_data.merge(user_data, on='user_id', how='left')\n",
    "data = data.merge(post_text_df, on='post_id', how='left')\n",
    "\n",
    "print(f\"Data shape after load_and_merge_data: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка временных меток"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding year and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps processed\n",
      "Data shape after timestamps processing: (76892800, 18)\n"
     ]
    }
   ],
   "source": [
    "# Преобразование формата временных меток в объект datetime\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "# Извлечение признаков из временных меток\n",
    "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
    "data['hour_of_day'] = data['timestamp'].dt.hour\n",
    "\n",
    "# Расчет времени с момента последнего действия для каждого пользователя\n",
    "data = data.sort_values(['user_id', 'timestamp'])\n",
    "data['time_since_last_action'] = data.groupby('user_id')['timestamp'].diff().dt.total_seconds()\n",
    "data['time_since_last_action'].fillna(0, inplace=True)\n",
    "\n",
    "# Extracting day of the month and year from the timestamp\n",
    "data['day_of_month'] = data['timestamp'].dt.day\n",
    "data['year'] = data['timestamp'].dt.year\n",
    "\n",
    "# Удаление столбца временных меток\n",
    "data = data.drop('timestamp', axis=1)\n",
    "\n",
    "print('Timestamps processed')\n",
    "print(f\"Data shape after timestamps processing: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание дополнительных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional features created\n",
      "Data shape after additional features creation: (76892800, 36)\n"
     ]
    }
   ],
   "source": [
    "# Feature 1: Количество просмотров и лайков для каждого пользователя\n",
    "user_views_likes = data.groupby('user_id')['action'].value_counts().unstack().fillna(0)\n",
    "user_views_likes.columns = ['user_views', 'user_likes']\n",
    "data = data.merge(user_views_likes, on='user_id', how='left')\n",
    "\n",
    "# Feature 2: Количество просмотров и лайков для каждого поста\n",
    "post_views_likes = data.groupby('post_id')['action'].value_counts().unstack().fillna(0)\n",
    "post_views_likes.columns = ['post_views', 'post_likes']\n",
    "data = data.merge(post_views_likes, on='post_id', how='left')\n",
    "\n",
    "# Feature 3: Количество просмотров и лайков для каждой группы тематик\n",
    "temp_df = data[['exp_group', 'topic', 'action']]\n",
    "\n",
    "# Создание колонок с количеством просмотров и лайков для каждой темы внутри группы\n",
    "topic_action_count = temp_df.pivot_table(index='exp_group', columns=['topic', 'action'], aggfunc=len, fill_value=0)\n",
    "topic_action_count.columns = [f'{col[0]}_exp_group_{col[1]}s' for col in topic_action_count.columns]\n",
    "grouped_data = topic_action_count.reset_index()\n",
    "\n",
    "data = data.merge(grouped_data, on='exp_group', how='left')\n",
    "\n",
    "# Преобразование категориальных признаков в строковый формат\n",
    "categorical_columns = ['country', 'city', 'topic', 'gender', 'os', 'source']\n",
    "data[categorical_columns] = data[categorical_columns].astype(str)\n",
    "\n",
    "print('Additional features created')\n",
    "print(f\"Data shape after additional features creation: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>action</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>exp_group</th>\n",
       "      <th>os</th>\n",
       "      <th>...</th>\n",
       "      <th>entertainment_exp_group_likes</th>\n",
       "      <th>entertainment_exp_group_views</th>\n",
       "      <th>movie_exp_group_likes</th>\n",
       "      <th>movie_exp_group_views</th>\n",
       "      <th>politics_exp_group_likes</th>\n",
       "      <th>politics_exp_group_views</th>\n",
       "      <th>sport_exp_group_likes</th>\n",
       "      <th>sport_exp_group_views</th>\n",
       "      <th>tech_exp_group_likes</th>\n",
       "      <th>tech_exp_group_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>5057</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>4872</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>5431</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>6829</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>3146</td>\n",
       "      <td>view</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Degtyarsk</td>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>...</td>\n",
       "      <td>67970</td>\n",
       "      <td>697043</td>\n",
       "      <td>486469</td>\n",
       "      <td>5091113</td>\n",
       "      <td>123438</td>\n",
       "      <td>1386641</td>\n",
       "      <td>180690</td>\n",
       "      <td>1828124</td>\n",
       "      <td>41879</td>\n",
       "      <td>559936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  post_id action  target gender  age country       city  exp_group   \n",
       "0      200     5057   view       0      1   34  Russia  Degtyarsk          3  \\\n",
       "1      200     4872   view       0      1   34  Russia  Degtyarsk          3   \n",
       "2      200     5431   view       0      1   34  Russia  Degtyarsk          3   \n",
       "3      200     6829   view       0      1   34  Russia  Degtyarsk          3   \n",
       "4      200     3146   view       0      1   34  Russia  Degtyarsk          3   \n",
       "\n",
       "        os  ... entertainment_exp_group_likes entertainment_exp_group_views   \n",
       "0  Android  ...                         67970                        697043  \\\n",
       "1  Android  ...                         67970                        697043   \n",
       "2  Android  ...                         67970                        697043   \n",
       "3  Android  ...                         67970                        697043   \n",
       "4  Android  ...                         67970                        697043   \n",
       "\n",
       "  movie_exp_group_likes  movie_exp_group_views  politics_exp_group_likes   \n",
       "0                486469                5091113                    123438  \\\n",
       "1                486469                5091113                    123438   \n",
       "2                486469                5091113                    123438   \n",
       "3                486469                5091113                    123438   \n",
       "4                486469                5091113                    123438   \n",
       "\n",
       "   politics_exp_group_views  sport_exp_group_likes  sport_exp_group_views   \n",
       "0                   1386641                 180690                1828124  \\\n",
       "1                   1386641                 180690                1828124   \n",
       "2                   1386641                 180690                1828124   \n",
       "3                   1386641                 180690                1828124   \n",
       "4                   1386641                 180690                1828124   \n",
       "\n",
       "   tech_exp_group_likes  tech_exp_group_views  \n",
       "0                 41879                559936  \n",
       "1                 41879                559936  \n",
       "2                 41879                559936  \n",
       "3                 41879                559936  \n",
       "4                 41879                559936  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to csv\n",
    "import os\n",
    "\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "file_path = os.path.join(desktop_path, \"data.csv\")\n",
    "\n",
    "data.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to a-efimik_features_lesson_22:   0%|          | 3/769 [23:49<100:32:03, 472.48s/it]"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def upload_dataframe_in_chunks(data, table_name, engine, chunksize=10000):\n",
    "    total_chunks = math.ceil(len(data) / chunksize)\n",
    "    for i in tqdm(range(total_chunks), desc=f\"Uploading to {table_name}\"):\n",
    "        chunk = data[i * chunksize : (i + 1) * chunksize]\n",
    "        if_exists = \"replace\" if i == 0 else \"append\"\n",
    "        chunk.to_sql(table_name, con=engine, if_exists=if_exists, index=False, method=\"multi\")\n",
    "\n",
    "chunksize = 100000\n",
    "upload_dataframe_in_chunks(data, \"a-efimik_features_lesson_22\", engine, chunksize=chunksize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM public.yancharskaya_features_lesson_22 LIMIT 1000', con=engine) # считываем таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  total_size table_size indexes_size\n",
      "0     359 MB     321 MB        38 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "size_query = '''\n",
    "SELECT \n",
    "    pg_size_pretty(pg_total_relation_size('public.yancharskaya_features_lesson_22')) AS total_size,\n",
    "    pg_size_pretty(pg_relation_size('public.yancharskaya_features_lesson_22')) AS table_size,\n",
    "    pg_size_pretty(pg_total_relation_size('public.yancharskaya_features_lesson_22') - pg_relation_size('public.yancharskaya_features_lesson_22')) AS indexes_size\n",
    "FROM\n",
    "    information_schema.tables\n",
    "WHERE\n",
    "    table_schema='public' AND table_name='yancharskaya_features_lesson_22';\n",
    "'''\n",
    "\n",
    "size_df = pd.read_sql(size_query, con=engine)\n",
    "print(size_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_count  column_count\n",
      "0    1768926            20\n"
     ]
    }
   ],
   "source": [
    "dimensions_query = '''\n",
    "SELECT\n",
    "    COUNT(*) AS row_count,\n",
    "    (SELECT COUNT(*)\n",
    "     FROM information_schema.columns\n",
    "     WHERE table_schema = 'public'\n",
    "     AND table_name = 'yancharskaya_features_lesson_22') AS column_count\n",
    "FROM\n",
    "    public.yancharskaya_features_lesson_22;\n",
    "'''\n",
    "\n",
    "dimensions_df = pd.read_sql(dimensions_query, con=engine)\n",
    "print(dimensions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>exp_group</th>\n",
       "      <th>source</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>text_size</th>\n",
       "      <th>iOS</th>\n",
       "      <th>covid</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>movie</th>\n",
       "      <th>politics</th>\n",
       "      <th>sport</th>\n",
       "      <th>tech</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1232208</td>\n",
       "      <td>157937</td>\n",
       "      <td>5416</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.132464</td>\n",
       "      <td>0.102506</td>\n",
       "      <td>2</td>\n",
       "      <td>0.139363</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1232209</td>\n",
       "      <td>3192</td>\n",
       "      <td>1156</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.195424</td>\n",
       "      <td>0.184388</td>\n",
       "      <td>3</td>\n",
       "      <td>0.139631</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1232210</td>\n",
       "      <td>16804</td>\n",
       "      <td>7087</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.132464</td>\n",
       "      <td>0.079235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139631</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>993</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1232211</td>\n",
       "      <td>37226</td>\n",
       "      <td>7147</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.132464</td>\n",
       "      <td>0.176157</td>\n",
       "      <td>2</td>\n",
       "      <td>0.139631</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1232212</td>\n",
       "      <td>137700</td>\n",
       "      <td>5049</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.132464</td>\n",
       "      <td>0.129808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139363</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>428</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  user_id  post_id  gender  age   country      city  exp_group   \n",
       "0  1232208   157937     5416       1   19  0.132464  0.102506          2  \\\n",
       "1  1232209     3192     1156       0   19  0.195424  0.184388          3   \n",
       "2  1232210    16804     7087       0   19  0.132464  0.079235          1   \n",
       "3  1232211    37226     7147       1   38  0.132464  0.176157          2   \n",
       "4  1232212   137700     5049       1   28  0.132464  0.129808          0   \n",
       "\n",
       "     source  day_of_week  hour  text_size  iOS  covid  entertainment  movie   \n",
       "0  0.139363            3     8        631    0      0              0      1  \\\n",
       "1  0.139631            3     8       3080    1      0              0      0   \n",
       "2  0.139631            3     8        993    1      0              0      1   \n",
       "3  0.139631            3     8       5500    0      0              0      1   \n",
       "4  0.139363            3     8        428    0      0              0      1   \n",
       "\n",
       "   politics  sport  tech  top_words  \n",
       "0         0      0     0          0  \n",
       "1         1      0     0          0  \n",
       "2         0      0     0          0  \n",
       "3         0      0     0          1  \n",
       "4         0      0     0          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6v/_xvyw44141s6_68z7m_2yyp80000gn/T/ipykernel_22973/1472378890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем ненужные столбцы\n",
    "X = data.drop(['target', 'action', 'text'], axis=1)\n",
    "\n",
    "categorical_columns = ['country', 'topic', 'city', 'gender', 'os', 'source']\n",
    "\n",
    "# Создание ID группы на основе столбца 'user_id'\n",
    "unique_user_ids = X['user_id'].unique()\n",
    "group_id_dict = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}\n",
    "X['group_id'] = X['user_id'].map(group_id_dict)\n",
    "\n",
    "# Сортировка набора данных для предсказаний по 'group_id'\n",
    "X = X.sort_values(by='group_id')\n",
    "\n",
    "# Убедитесь, что категориальные переменные представлены в виде строк\n",
    "X[categorical_columns] = X[categorical_columns].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запись фичей в базу данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# То что будет в сервисе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool\n",
    "\n",
    "## TODO: надо просто передать лист с индексами категориальных признаков\n",
    "# Получение индексов категориальных столбцов\n",
    "cat_features = [X.drop(columns=['user_id']).columns.get_loc(col) for col in categorical_columns]\n",
    "\n",
    "# Создание объекта Pool для набора данных предсказаний с колонкой 'group_id' и категориальными признаками\n",
    "prediction_pool = Pool(X.drop(columns=['user_id']), cat_features=cat_features, group_id=X['group_id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5525e501b23e2010ab883f77d6209697fb9a7ecd2dc8bb136f049441ff2c9ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
