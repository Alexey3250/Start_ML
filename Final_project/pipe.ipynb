{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "        \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )\n",
    "\n",
    "# Чтение данных таблицы user_data\n",
    "query = \"SELECT * FROM user_data\"\n",
    "user_data = pd.read_sql(query, engine)\n",
    "\n",
    "# Чтение данных таблицы post_text_df\n",
    "query = \"SELECT * FROM post_text_df\"\n",
    "post_text_df = pd.read_sql(query, engine)\n",
    "\n",
    "# Чтение ограниченного количества данных таблицы feed_data\n",
    "query = \"SELECT * FROM feed_data LIMIT 100000\"\n",
    "feed_data = pd.read_sql(query, engine)\n",
    "\n",
    "# Переименование столбцов идентификаторов\n",
    "user_data = user_data.rename(columns={'id': 'user_id'})\n",
    "post_text_df = post_text_df.rename(columns={'id': 'post_id'})\n",
    "\n",
    "# Объединение таблиц\n",
    "data = feed_data.merge(user_data, on='user_id', how='left')\n",
    "data = data.merge(post_text_df, on='post_id', how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка временных меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование формата временных меток в объект datetime\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "# Извлечение признаков из временных меток\n",
    "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
    "data['hour_of_day'] = data['timestamp'].dt.hour\n",
    "\n",
    "# Расчет времени с момента последнего действия для каждого пользователя\n",
    "data = data.sort_values(['user_id', 'timestamp'])\n",
    "data['time_since_last_action'] = data.groupby('user_id')['timestamp'].diff().dt.total_seconds()\n",
    "data['time_since_last_action'].fillna(0, inplace=True)\n",
    "\n",
    "# Удаление столбца временных меток\n",
    "data = data.drop('timestamp', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кодирование категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding для 'country', 'city' и 'topic'\n",
    "data = pd.get_dummies(data, columns=['country', 'city', 'topic'], prefix=['country', 'city', 'topic'])\n",
    "\n",
    "le_gender = LabelEncoder()\n",
    "le_os = LabelEncoder()\n",
    "le_source = LabelEncoder()\n",
    "le_action = LabelEncoder()\n",
    "\n",
    "# Label encoding для 'gender', 'os' и 'source'\n",
    "data['gender'] = le_gender.fit_transform(data['gender'])\n",
    "data['os'] = le_os.fit_transform(data['os'])\n",
    "data['source'] = le_source.fit_transform(data['source'])\n",
    "data['action'] = le_action.fit_transform(data['action'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание дополнительных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(X):\n",
    "    return np.array([len(re.findall(r'\\b\\w+\\b', text)) for text in X])\n",
    "def sentence_count(X):\n",
    "    return np.array([len(re.findall(r'[.!?]+', text)) for text in X])\n",
    "def avg_word_length(X):\n",
    "    return np.array([sum(len(word) for word in re.findall(r'\\b\\w+\\b', text)) / len(re.findall(r'\\b\\w+\\b', text)) if len(re.findall(r'\\b\\w+\\b', text)) > 0 else 0 for text in X])\n",
    "def punctuation_count(X):\n",
    "    return np.array([sum(1 for char in text if char in punctuation) for text in X])\n",
    "\n",
    "# Применение функций извлечения признаков к столбцу 'text'\n",
    "word_counts = word_count(data['text'])\n",
    "sentence_counts = sentence_count(data['text'])\n",
    "avg_word_lengths = avg_word_length(data['text'])\n",
    "punctuation_counts = punctuation_count(data['text'])\n",
    "\n",
    "# Добавление новых признаков в виде столбцов в DataFrame\n",
    "data['word_count'] = word_counts\n",
    "data['sentence_count'] = sentence_counts\n",
    "data['avg_word_length'] = avg_word_lengths\n",
    "data['punctuation_count'] = punctuation_counts\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000) # Вы можете настроить max_features в зависимости от ваших потребностей\n",
    "\n",
    "# Обучение vectorizer на столбце 'text' и преобразование текстовых данных\n",
    "tfidf_matrix = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Преобразование матрицы TF-IDF в DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Конкатенация исходных данных с DataFrame TF-IDF\n",
    "data_with_tfidf = pd.concat([data.drop(columns=['text']), tfidf_df], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отбор признаков на основе взаимной информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_with_tfidf.drop(['target', 'action'], axis=1)\n",
    "y = data_with_tfidf['target']\n",
    "\n",
    "# Вычисление взаимной информации между каждым признаком и целевой переменной\n",
    "mi_scores = mutual_info_classif(X, y, random_state=42)\n",
    "\n",
    "# Создание DataFrame с именами признаков и соответствующими им оценками MI\n",
    "mi_scores_df = pd.DataFrame({'feature': X.columns, 'mi_score': mi_scores})\n",
    "\n",
    "# Сортировка DataFrame по оценкам MI в порядке убывания\n",
    "mi_scores_df = mi_scores_df.sort_values('mi_score', ascending=False)\n",
    "\n",
    "# При необходимости выберите k лучших признаков с помощью SelectKBest\n",
    "selector = SelectKBest(mutual_info_classif, k=50)\n",
    "selector.fit(X, y)\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "print(\"Top k features based on mutual information:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of top features to display\n",
    "top_k = 30\n",
    "\n",
    "# Get the top k features\n",
    "top_k_features = mi_scores_df.head(top_k)\n",
    "\n",
    "# Plot the top k features\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_k_features['feature'], top_k_features['mi_score'], align='center')\n",
    "plt.xlabel('Mutual Information Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top {} Features Based on Mutual Information'.format(top_k))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели CatBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with selected features, top k with mutual information, without data leakage, timestamp, 'action' and 'text'\n",
    "X = data_with_tfidf[selected_features]\n",
    "y = data_with_tfidf['target']\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the train and test sets by 'group_id'\n",
    "X_train = X_train.sort_values(by='group_id')\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "X_test = X_test.sort_values(by='group_id')\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "# Create train and test Pool objects with the 'group_id' column\n",
    "train_pool = Pool(X_train.drop(columns=['user_id']), y_train, group_id=X_train['group_id'])\n",
    "test_pool = Pool(X_test.drop(columns=['user_id']), y_test, group_id=X_test['group_id'])\n",
    "\n",
    "# Train the CatBoost model using PrecisionAt:top=5 evaluation metric\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(iterations=1000,\n",
    "                           learning_rate=0.1,\n",
    "                           depth=6,\n",
    "                           custom_metric='PrecisionAt:top=5',\n",
    "                           eval_metric='PrecisionAt:top=5',\n",
    "                           random_seed=42,\n",
    "                           verbose=100)\n",
    "\n",
    "model.fit(train_pool, eval_set=test_pool)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение и загрузка модели CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
