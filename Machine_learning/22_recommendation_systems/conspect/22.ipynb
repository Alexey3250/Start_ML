{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конспект > 22 урок > Рекомендательные системы\n",
    "\n",
    "Рекомендательные системы — программы, основанные на алгоритмах, предсказывающих на основе данных о пользователе, какие релевантные объекты (книги, фильмы, музыка, новости) ему будут интересны.\n",
    "\n",
    "Пример рекомендательной системы - портал Кинопоиск, где на основе оценок пользователей осуществляется подбор наиболее подходящих по мнению алгоритма фильмов.\n",
    "\n",
    "Обозначим набор пользователей как множество\n",
    "\n",
    "$U={\\{u_i}\\}_{i=1}^n$\n",
    "\n",
    "Набор айтемов(фильмов)\n",
    "\n",
    "$I={\\{i_i}\\}_{i=1}^m$\n",
    "\n",
    "Задача на основании данных наблюдений понять, какую рекомендацию фильма $(i_i)$ выдать тому или иному пользователю $(u_i)$.\n",
    "\n",
    "Оценки фильмов пользователями можно представить в виде матрицы $R$ размером $nxm$, где каждой ячейке будет соответствовать оценка от 0 до 10 того или иного фильма пользователем $r_{ui}$, для непросмотренных фильмов будет стоять прочерк.\n",
    "\n",
    "# >Контентная рекомендация\n",
    "\n",
    "Рассмотрим общий алгоритм построения рекомендательной системы.\n",
    "\n",
    "Шаг 1: По парам (u,i) построим пайплайн выделения l признаков \n",
    "\n",
    "$x_{ui} = (d_1^{ui}, …, d_l^{ui})$\n",
    "\n",
    "Получаем пары объект-ответ: $(x_{ui}, r_{ui})_{j=1}^n$ на которых можно применить уже привычное нам обучение с учителем.\n",
    "\n",
    "Шаг 2: Обучение выбранной модели\n",
    "\n",
    "Шаг 3: Вывод рекомендаций\n",
    "\n",
    "- Допустим обучили модель и получили некую оценку для каждой пары пользователь-фильм $a(u,i) \\approx r_{ui}$\n",
    "- Теперь наша задача дать некоторое количество $(k)$ рекомендаций данному пользователю $(u)$\n",
    "- Для этого прогоним модель по всем m айтемам и получим m прогнозов\n",
    "- Отсортируем данные прогнозы в порядке убывания\n",
    "- Выберем топ $k$ выходов - это и будут рекомендации для пользователя $u$\n",
    "\n",
    "Главный минус данного подхода - потребление огромного ресурса, так как для каждого пользователя будет необходимо прогнать модель на миллионах фильмов.\n",
    "\n",
    "На практике данная процеура имеет несколько иной вид:\n",
    "\n",
    "![2022-05-25_173321.png](%D0%9A%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%2022%20%D1%83%D1%80%D0%BE%D0%BA%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20c438338c75134e848e629d470a94ee64/2022-05-25_173321.png)\n",
    "\n",
    "Действительно, если пользователь никогда не выбирает фильмы определенных жанров или на пределенном языке, можно сразу же их отсеять и не использовать в построении рекомендаций. То есть будем “скармливать” модели не весь датасет, а лишь его часть.\n",
    "\n",
    "После этого мы дополнительно переранжируем выходы модели, добавив некие критерии, такие как новизна или известность фильма.\n",
    "\n",
    "Основной недостаток данного алгоритма - необходимость придумывать хорошие фичи,  трудозатраты на переранжирование и отбор айтемов.\n",
    "\n",
    "# >Коллаборативный подход\n",
    "\n",
    "Обойти недостатки предыдущих подходов позволяет коллаборативный подход, для реализации которого нужна только матрица $R$.\n",
    "\n",
    "Рассмотрим две реализации данного подхода \n",
    "\n",
    "# >USER-BASED\n",
    "\n",
    "Основан на схожести пользователей между собой. Если пользователи $u$ и $v$ похожи, то если $u$ оценил высоко фильм $i$, то высока вероятность, что и $v$ его оценит.\n",
    "\n",
    "Как же мы будем оценивать схожесть пользователей? Посмотрим на оценки данные ими относительно просмотренных фильмов, отберем фильмы, для который есть оценки обоих юзеров:\n",
    "\n",
    "$I_{u,v} = \\{i \\in I: \\exist r_{ui}$ & $\\exist r_{vi}\\}$\n",
    "\n",
    "![2022-05-27_180210.png](%D0%9A%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%2022%20%D1%83%D1%80%D0%BE%D0%BA%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20c438338c75134e848e629d470a94ee64/2022-05-27_180210.png)\n",
    "\n",
    "Посчитаем для айтемов из $I_{u,v}$ коэффициенты корреляции $w_{u,v}$ для определения того, насколько один пользователь похож на другого\n",
    "\n",
    "![2022-05-27_180132.png](%D0%9A%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%2022%20%D1%83%D1%80%D0%BE%D0%BA%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20c438338c75134e848e629d470a94ee64/2022-05-27_180132.png)\n",
    "\n",
    "$w_{u,v} = \\frac { \\sum_{i \\in I_{uv}} (r_{ui} - r_u^{ср})(r_{ui} - r_v^{ср}) } {\\sqrt {\\sum_i \\in I_{uv} (r_{ui} - r_u^{ср})^2}  \\sqrt {\\sum_i \\in I_{uv} (r_{ui} - r_v^{ср})^2} }$\n",
    "\n",
    "Далее для кадого пользователя $u_0$ будем отбирать похожих на него по некоторому порогу коэффициента корреляции:\n",
    "\n",
    "$U(u_0) = {v \\in U | w_{{u_0},v} > \\alpha}$\n",
    "\n",
    "Такое множество  U похожих пользователей принято называть коллаборацией\n",
    "\n",
    "Например если порог $\\alpha = 0.5$ \n",
    "$U(u_1) = {u_2}$\n",
    "\n",
    "Теперь мы можем на основе оценок пользователей из $U(u_0)$ прикинуть, какой рейтинг выставит пользователь $u_0$ для ряда непросмотренных фильмов.\n",
    "\n",
    "Для этого обозначим  $U(u_0)_i$  множество тех пользователей из $U(u_0)$, которые дали айтему $i$ какую-либо оценку.\n",
    "\n",
    "Спрогнозируем оценку, которую поставит пользователь $u_0$ фильму $i$:\n",
    "\n",
    "$a(u_0,i) = r^{ср}_{u_0} + \\frac{\\sum_{v \\ in U(u_0)_i}(r_{vi} - r^{ср}_v) \\cdot w_{u_ov}}{\\sum_{v \\in U(u_0)_i}{|{w_u}_o,v|}}$\n",
    "\n",
    "Данная формула описывает следующие действия:\n",
    "\n",
    "-Вычислить среднюю оценку пользователя по всем фильмам, которые он смотрел.\n",
    "\n",
    "-Вычислить разницу в оценках соседями пользователя данного фильма от их средних оценок, умноженную на коэффициент корреляции.\n",
    "\n",
    "-Разделить на сумму корреляций по модулю.\n",
    "\n",
    "Таким образом мы считаем предполагаемый “сдвиг оценки” и прибавляем его к средней оценке пользователя.\n",
    "\n",
    "# >ITEM-BASED\n",
    "\n",
    "Другой подход, симметричный предыдущему. Основная идея -  айтем понравится пользователю, если ему нравятся похожие айтемы. То есть в данном подходе рассматривается матрица оценок разных фильмов пользователем. \n",
    "\n",
    "Отберем юзеров, у которых есть оценки для обоих айтемов:\n",
    "\n",
    "$U_{i,j} = \\{ v \\in U: \\exist r_{vi}$ &  $\\exist r_{vj}\\}$\n",
    "\n",
    "Посчитаем коэффициент корреляции $w_{i,j}$ по оценкам обоих айтемов для юзеров $U_{i,j}$\n",
    "\n",
    "Здесь используется тот же принцип и та же формула, что использовалась для юзеров выше.\n",
    "\n",
    "![2022-05-27_192647.png](%D0%9A%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%2022%20%D1%83%D1%80%D0%BE%D0%BA%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20c438338c75134e848e629d470a94ee64/2022-05-27_192647.png)\n",
    "\n",
    "Для каждого айтема $i_0$ будем отбирать похожих на него по некоторому порогу корреляции\n",
    "\n",
    "$I(i_0) = {j \\in I | w_{i_0,j} > \\alpha}$ \n",
    "Такое множество также будет называться коллаборация\n",
    "\n",
    "Далее на основании оценок айтемов из $I(i_0)$ можно дать оценку, какой рейтинг выставят айтему $i_0$ пользователи, еще не давшие оценки.\n",
    "\n",
    "$I(i_0)_u$ - множество айтемов, которому пользователь u дал какую-то оценку.\n",
    "\n",
    "Далее также корректируем сдвиги от средней оценки фильма.\n",
    "\n",
    "# >Модель со скрытыми переменными\n",
    "\n",
    "Третий вариант коллаборативной фильтрации на основе матрицы $R$.\n",
    "\n",
    "Идея - закодировать каждый айтем и каждого юзера в виде $l$-мерного вектора\n",
    "\n",
    "Обозначим два вектора, для пользователя и айтема соответственно:\n",
    "\n",
    "$p_u = (d_1^u, …, d_l^u)$\n",
    "\n",
    "$q_i = (d_i^i,…,d_l^i)$\n",
    "\n",
    "Таким образом прогноз мождели можно представить в виде скалярного произведения между двумя векторами:\n",
    "\n",
    "$a(u,i) = \\lang p_u, q_i \\rang \\approx r_{ui}$\n",
    "\n",
    "Чтобы сгенерировать данные векторы из матрицы R используется следующая формула:\n",
    "\n",
    "$\\sum_{u,i,r_{ui} \\in R}(r_{ui} - b_u - b_i - \\lang p_u, q_i \\rang)^2 —> min_{b_u,b_i,p_u,q_i}$\n",
    "\n",
    "![2022-05-27_195616.png](%D0%9A%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%2022%20%D1%83%D1%80%D0%BE%D0%BA%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20c438338c75134e848e629d470a94ee64/2022-05-27_195616.png)\n",
    "\n",
    "*Матрица R*\n",
    "\n",
    "Решая данную задачу получаем две матрицы - для пользователей и айтемов:\n",
    "\n",
    "$P = (p_1|…|p_n)_{lxn}$\n",
    "\n",
    "$Q = (q_1|…|q_m)_{lxm}$\n",
    "\n",
    "При этом $(P^T \\cdot Q)_{ui}$ $= \\lang p_u, q_i \\rang$\n",
    "\n",
    "По факту строим такие эмбеддинги (кодировки $l$-мерных признаков), чтобы произведение двух матриц, состоящих из этих кодировок аппроксимировали нам изначальную матрицу $R$:\n",
    "\n",
    "$P^T \\cdot R \\approx R$\n",
    "\n",
    "Также в подобных задачах часто используется регуляризация.\n",
    "\n",
    "# >Минимизация модели со скрытыми переменными\n",
    "\n",
    "1. Стохастический градиентный спуск. Позволяет быстро находить оптимумы в сложных задачах. Но на практике дает плохие минимумы.\n",
    "2. ALS(Alternating least squares)\n",
    "\n",
    "$\\sum_{u,i,r_{ui} \\in R}(r_{ui} - b_u - b_i - \\lang p_u, q_i \\rang)^2 —> min_{b_u,b_i,p_u,q_i}$\n",
    "\n",
    "- Шаг 1: Инициализируем $P,Q$\n",
    "- Шаг 2: Фиксируем значения в $Q$, ищем P:\n",
    "\n",
    "$\\sum_{u,i,r_{ui} \\in R}(r_{ui} - b_u - b_i - \\lang p_u, q_i \\rang)^2 —> min_{p_u}$\n",
    "\n",
    "- Шаг 3: После того, как оптимальная матрица $P$ найдена, фиксируем  и ищем $Q$:\n",
    "\n",
    "$\\sum_{u,i,r_{ui} \\in R}(r_{ui} - b_u - b_i - \\lang p_u, q_i \\rang)^2 —> min_{q_i}$\n",
    "\n",
    "-Повторяем шаг 2,3 до сходимости\n",
    "\n",
    "По сути это то же самое, что мы делали, когда изучали линейную регрессию!\n",
    "\n",
    "## Сравнение контентного и коллаборативного подходов\n",
    "\n",
    "![2022-05-27_201432.png](%D0%9A%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%2022%20%D1%83%D1%80%D0%BE%D0%BA%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20c438338c75134e848e629d470a94ee64/2022-05-27_201432.png)\n",
    "\n",
    "# >Оценка качества работы рекомендательных системы и валидация\n",
    "\n",
    "В целом для оценки качества работы рекомендательных системы можно использовать классические метрики метрики регрессии или классификации.\n",
    "\n",
    "Рассмотрим также несколько новых метрик.\n",
    "\n",
    "$hitrate@k = [R_u(k) \\bigcap \\ L_u ≠ \\empty ]$\n",
    "\n",
    "$presicion@k = \\frac{|R_u(k) \\bigcap L_u|}{K}$\n",
    "\n",
    "$recall@k = \\frac{|R_u(k) \\bigcap L_u}{L_u},$\n",
    "\n",
    "где  $R_u(k)$ - топ $k$ рекомендаций пользователю $u$\n",
    "\n",
    "$L_u$ - айтемы, которые понравились пользователю\n",
    "\n",
    "Однако такие метрики обладают существенным недостатком - если первые рекомендации будут плохими, пользователь может проигнорировать оставшиеся рекомендации и прогноз получится провальным.\n",
    "\n",
    "## “Хитрые” метрики\n",
    "\n",
    "Отсортируем айтемы i для пользователей  по выходам модели $a_{ui} = a(u,i)$ и выберем топ $k$:\n",
    "\n",
    "$i_1,…,i_k: a_{u_1} ≥ … ≥ a_{u_k}$\n",
    "\n",
    "$DCG@k = \\sum_{p=1}^k g(r_ui_p) \\cdot d(p)$\n",
    "\n",
    "где p - порядок айтема, на который его поставили в отранжированном списке\n",
    "\n",
    "$g(r_{ui_p})$ - функция релевантности айтема\n",
    "\n",
    "$d(p)$ - штраф за позицию\n",
    "\n",
    "То есть такая модель, в отличие от предыдущих, учитывает то, в какой последовательности даются рекомендации (сначала - наиболее подходящие, затем менее)\n",
    "\n",
    "## Валидация\n",
    "\n",
    "Есть несколько подходов для валидации рекомендательных систем на исторических данных\n",
    "\n",
    "Допустим у нас есть данные от том, каким образом в прошлом пользователи оценивали те или иные фильмы/товары.\n",
    "\n",
    "Можем последний небольшой отрезок времени отрезать в качестве теста, а на остальных обучать модель.\n",
    "\n",
    "![Рисунок1.png](%D0%9A%D0%BE%D0%BD%D1%81%D0%BF%D0%B5%D0%BA%D1%82%2022%20%D1%83%D1%80%D0%BE%D0%BA%20%D0%A0%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20c438338c75134e848e629d470a94ee64/%D0%A0%D0%B8%D1%81%D1%83%D0%BD%D0%BE%D0%BA1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
