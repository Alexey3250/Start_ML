{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем работать с данными агрегатора такси [Sigma Cabs](https://www.kaggle.com/datasets/arashnic/taxi-pricing-with-mobility-analytics). В зависимости от характеристик поездки требуется предсказать один из трех типов повышенного ценообразования: [1, 2, 3]. Таким образом, это поможет компании оптимально мэтчить такси и клиентов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131662, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sigma_cabs.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Type_of_Cab</th>\n",
       "      <th>Customer_Since_Months</th>\n",
       "      <th>Life_Style_Index</th>\n",
       "      <th>Confidence_Life_Style_Index</th>\n",
       "      <th>Destination_Type</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Cancellation_Last_1Month</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Surge_Pricing_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T0005689460</th>\n",
       "      <td>6.77</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.42769</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>3.90500</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689461</th>\n",
       "      <td>29.47</td>\n",
       "      <td>B</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.78245</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>3.45000</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>56</td>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689464</th>\n",
       "      <td>41.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>3.50125</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>77</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689465</th>\n",
       "      <td>61.56</td>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>3.45375</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>74</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689467</th>\n",
       "      <td>54.95</td>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.03453</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>3.40250</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49</td>\n",
       "      <td>102</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Trip_Distance Type_of_Cab  Customer_Since_Months  \\\n",
       "Trip_ID                                                         \n",
       "T0005689460           6.77           B                    1.0   \n",
       "T0005689461          29.47           B                   10.0   \n",
       "T0005689464          41.58         NaN                   10.0   \n",
       "T0005689465          61.56           C                   10.0   \n",
       "T0005689467          54.95           C                   10.0   \n",
       "\n",
       "             Life_Style_Index Confidence_Life_Style_Index Destination_Type  \\\n",
       "Trip_ID                                                                      \n",
       "T0005689460           2.42769                           A                A   \n",
       "T0005689461           2.78245                           B                A   \n",
       "T0005689464               NaN                         NaN                E   \n",
       "T0005689465               NaN                         NaN                A   \n",
       "T0005689467           3.03453                           B                A   \n",
       "\n",
       "             Customer_Rating  Cancellation_Last_1Month  Var1  Var2  Var3  \\\n",
       "Trip_ID                                                                    \n",
       "T0005689460          3.90500                         0  40.0    46    60   \n",
       "T0005689461          3.45000                         0  38.0    56    78   \n",
       "T0005689464          3.50125                         2   NaN    56    77   \n",
       "T0005689465          3.45375                         0   NaN    52    74   \n",
       "T0005689467          3.40250                         4  51.0    49   102   \n",
       "\n",
       "             Gender  Surge_Pricing_Type  \n",
       "Trip_ID                                  \n",
       "T0005689460  Female                   2  \n",
       "T0005689461    Male                   2  \n",
       "T0005689464    Male                   2  \n",
       "T0005689465    Male                   3  \n",
       "T0005689467    Male                   2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Занесем индекс колонку\n",
    "df = df.set_index('Trip_ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание признаков:\n",
    "\n",
    "1. **Trip_ID**: ID for TRIP\n",
    "2. **Trip_Distance**: The distance for the trip requested by the customer\n",
    "3. **TypeofCab**: Category of the cab requested by the customer\n",
    "4. **CustomerSinceMonths**: Customer using cab services since n months; 0 month means current month\n",
    "5. **LifeStyleIndex**: Proprietary index created by Sigma Cabs showing lifestyle of the customer based on their behaviour\n",
    "6. **ConfidenceLifeStyle_Index**: Category showing confidence on the index mentioned above\n",
    "7. **Destination_Type**: Sigma Cabs divides any destination in one of the 14 categories.\n",
    "8. **Customer_Rating**: Average of life time ratings of the customer till date\n",
    "9. **CancellationLast1Month**: Number of trips cancelled by the customer in last 1 month\n",
    "10. **Var1**, **Var2** and **Var3**: Continuous variables masked by the company. Can be used for modelling purposes\n",
    "11. **Gender**: Gender of the customer\n",
    "\n",
    "**SurgePricingType**: Target (can be of 3 types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA \n",
    "Заполните пропуски в вещественных признаках медианой, а в категориальных - самым популярным классом. Изобразите марицу корреляций и выведите топ5 пар самых коррелированных признаков.\n",
    "\n",
    "Так как в сумме уникальных значений различных категориальных признаков окажется не супер-много, примените `One-Hot-Encoding` для них. Не забудьте в методе `pd.get_dummies` указать параметр `drop_first=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, \n",
    "                                                     test_size=0.2, \n",
    "                                                     shuffle=True, \n",
    "                                                     random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** Обучите One-vs-Rest Logreg. Не забудьте в шаг добавить стандартизацию данных (через `StandardScaler`) Посчитайте precision, recall, f1-score и усредните по всем классам с помощью micro, macro и weighted avg. Здесь и далее округляйте до 3 знака после запятой.\n",
    "\n",
    "Чтобы отдельно и долго не вычислять метрики, можно воспользоваться `classification_report` из `sklearn.metrics`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### Your code is here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите оптимальные гиперпараметры модели с помощью `GridSearchCV()` из предложенных. Для лучшего набора гиперпараметров посчитайте те же самые метрики. Валидировать параметры необходимо по `accuracy`. В этот раз проведем настояющую процедуру Кросс-Валидации! \n",
    "\n",
    "Для этого в метод `fit` передадим тренировочную часть наших данных, в параметр `cv` ничего не будем передавать (по дефолту 5-fold Кросс-Валидация будет проведена), а итоговые метрики замерим на тесте!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'one_vs_all__estimator__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'one_vs_all__estimator__C': [0.001, 0.01, 0.1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразите три калибровочные кривые для Logistic Classifier: 0-vs-rest, 1-vs-rest, 2-vs-rest. Хорошо ли откалиброван обученный классификатор? \n",
    "\n",
    "Заметьте, что `predict_proba` возвращает список из вероятностей для всех наших классов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.** Обучите логистическую регрессию с гиперпараметрами из первого задания на полиномиальных признаках до 4 степени. Сравните метрики с первым заданием.\n",
    "\n",
    "\n",
    "Пример: Пусть у нас был единственный признак \n",
    "\n",
    "$$\n",
    "d_j = [1, 2, 3, 4]\n",
    "$$\n",
    "\n",
    "Тогда полиномиальные признаки до 4 степени от такого будут иметь вид:\n",
    "\n",
    "$$\n",
    "d_j^1 = [1, 2, 3, 4]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^2 = [1, 4, 9, 16]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^3 = [1, 8, 27, 64]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^4 = [1, 16, 81, 256]\n",
    "$$\n",
    "\n",
    "P.S. Бинарные колонки нет смысла возводить в какие-то степени, поэтому возьмем исключительно вещественные из базовых. \n",
    "\n",
    "Для этого можно воспользоваться классическим циклом (или уроком из занятия про `Sberbank Housing Market`). Положите модифицированный датасет в переменную `X_polinomial`!\n",
    "\n",
    "P.S.S Зачастую еще, создаваю полиномиальные фичи, учитывают \"пересечения\" признаков, то есть, например, из векторов признаков $d_j, d_i$ генерируют не просто новые степени $d_j^2, d_i^2, d_j^3, d_i^3...$, а еще и признаки вида $d_j \\cdot d_i, d_j^2 \\cdot d_i, d_j \\cdot d_i^2...$, но здесь ограничьтесь просто степенями!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131662, 52)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Создание полиномиальных признаков\n",
    "\n",
    "X_polinomial = X.copy()\n",
    "\n",
    "\n",
    "### Your code is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pol_train, X_pol_test, y_train, y_test  = train_test_split(X_polinomial, y, \n",
    "                                                             test_size=0.2, \n",
    "                                                             shuffle=True, \n",
    "                                                             random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии с первым заданием изобразите три калибровочные кривые. Стало ли лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.** Обучите на датасете без полиномиальных признаков One-vs-One `SGDClassifier` из `sklearn.linear_model`, который использует стохастический градиентный спуск (узнаете о нем позже) и может обучать как `SVM`, так и, например, `LogReg`, если указать в качестве параметра `loss` либо `hinge`, либо `log` соответственно!\n",
    "\n",
    "Посчитайте precision, recall, f1-score и усредните по всем классам с помощью micro, macro и weighted avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, \n",
    "                                                     test_size=0.2, \n",
    "                                                     shuffle=True, \n",
    "                                                     random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "### Your code is here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите оптимальные гиперпараметры модели с помощью `GridSearchCV()`. При этом переберите всевозможные функции потерь. Таким образом, при `loss = 'hinge'`, мы обучим SVM, при `loss = 'log'` мы обучим логистическую регрессию и т.д.\n",
    "\n",
    "Используйте прием с Кросс-Валидацией при подборе параметров, как ранее, а также замерьте метрики на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'one_vs_one__estimator__loss': ['hinge', 'log', 'modified_huber'],\n",
    "              'one_vs_one__estimator__penalty': ['l1', 'l2'],\n",
    "              'one_vs_one__estimator__alpha': [0.001, 0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ли однозначно сказать, какой подход оказался лучше: One-vs-Rest или One-vs-One?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
