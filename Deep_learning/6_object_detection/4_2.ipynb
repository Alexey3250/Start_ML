{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Lambda\n",
    "import torchvision.transforms as T\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "\n",
    "class CustomOxfordIIITPet(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, target_transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(root_dir, 'images', '*.jpg')))\n",
    "        self.annotation_paths = sorted(glob.glob(os.path.join(root_dir, 'annotations', 'trimaps', '*.png')))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        annotation_path = self.annotation_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        annotation = Image.open(annotation_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            annotation = self.target_transform(annotation)\n",
    "\n",
    "        return image, annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def transform_data(path, batch_size=64, num_workers=2, pin_memory=True):\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.Resize((256, 256)),\n",
    "            T.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    target_transform = T.Compose(\n",
    "        [\n",
    "            T.Resize((256, 256)),\n",
    "            T.PILToTensor(),\n",
    "            T.Lambda(lambda x: (x - 1).long())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_dataset = CustomOxfordIIITPet(path, transform=transform, target_transform=target_transform)\n",
    "    valid_dataset = CustomOxfordIIITPet(path, transform=transform, target_transform=target_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = transform_data('./PETSdataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model) -> float:\n",
    "    \"\"\"\n",
    "    Эта функция отвечает за обучение модели на данных из набора train_loader. \n",
    "    На каждой итерации происходит расчет ошибки модели и обратное распространение ошибки.\n",
    "    Возвращаются средний loss и точность на данных для обучения.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for x, y in tqdm(train_loader, desc='Train'):\n",
    "        bs = y.size(0)\n",
    "\n",
    "        x, y = x.to(device), y.squeeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output.reshape(bs, 3, -1), y.reshape(bs, -1))\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        _, y_pred = output.max(dim=1)\n",
    "        total += y.size(0) * y.size(1) * y.size(2)\n",
    "        correct += (y == y_pred).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(model, loader) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Эта функция оценивает модель на валидационном наборе данных. \n",
    "    Она рассчитывает потери и точность модели на валидационных данных.\n",
    "    Возвращаются средний loss и точность на валидационных данных.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for x, y in tqdm(loader, desc='Evaluation'):\n",
    "        bs = y.size(0)\n",
    "\n",
    "        x, y = x.to(device), y.squeeze(1).to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output.reshape(bs, 3, -1), y.reshape(bs, -1))\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, y_pred = output.max(dim=1)\n",
    "        total += y.size(0) * y.size(1) * y.size(2)\n",
    "        correct += (y == y_pred).sum().item()\n",
    "\n",
    "    total_loss /= len(loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return total_loss, accuracy\n",
    "\n",
    "from IPython.display import clear_output\n",
    "def plot_stats(\n",
    "    train_loss: list[float],\n",
    "    valid_loss: list[float],\n",
    "    train_accuracy: list[float],\n",
    "    valid_accuracy: list[float],\n",
    "    title: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Эта функция отображает графики потерь и точности модели на данных для обучения и валидации. \n",
    "    Отдельно выводятся графики для потерь и точности.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' loss')\n",
    "\n",
    "    plt.plot(train_loss, label='Train loss')\n",
    "    plt.plot(valid_loss, label='Valid loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' accuracy')\n",
    "    \n",
    "    plt.plot(train_accuracy, label='Train accuracy')\n",
    "    plt.plot(valid_accuracy, label='Valid accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def visualize(model, batch):\n",
    "    \"\"\"\n",
    "    Эта функция визуализирует результаты модели, предсказывая сегментацию на изображениях из валидационного набора данных. \n",
    "    Она выводит оригинальное изображение, маску сегментации и предсказание модели.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    xs, ys = batch\n",
    "    \n",
    "    to_pil = T.ToPILImage()\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
    "        prediction = model(x.unsqueeze(0).cuda()).squeeze(0).max(dim=0)[1]\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(24, 8), facecolor='white')\n",
    "\n",
    "        ax[0].imshow(to_pil(x))\n",
    "        ax[1].imshow(to_pil(y.to(torch.uint8)))\n",
    "        ax[2].imshow(to_pil(prediction.to(torch.uint8)))\n",
    "\n",
    "        ax[0].axis('off')\n",
    "        ax[1].axis('off')\n",
    "        ax[2].axis('off')\n",
    "\n",
    "        ax[0].set_title('Original image')\n",
    "        ax[1].set_title('Segmentation mask')\n",
    "        ax[2].set_title('Prediction')\n",
    "\n",
    "        plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "        plt.show()\n",
    "\n",
    "        if i >= 9:\n",
    "            break\n",
    "            \n",
    "def whole_train_valid_cycle(model, num_epochs, title):\n",
    "    \"\"\"\n",
    "    Эта функция производит полный цикл обучения и валидации модели. \n",
    "    Она проводит заданное количество эпох, на каждой эпохе сначала обучая модель, затем валидируя ее. \n",
    "    В процессе сохраняются истории потерь и точности, которые затем визуализируются. \n",
    "    После каждой эпохи также выводятся визуализации предсказаний модели.\n",
    "    \"\"\"\n",
    "    train_loss_history, valid_loss_history = [], []\n",
    "    train_accuracy_history, valid_accuracy_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(model)\n",
    "        valid_loss, valid_accuracy = evaluate(model, valid_loader)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        valid_accuracy_history.append(valid_accuracy)\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "        plot_stats(\n",
    "            train_loss_history, valid_loss_history,\n",
    "            train_accuracy_history, valid_accuracy_history,\n",
    "            title\n",
    "        )\n",
    "\n",
    "        visualize(model, next(iter(valid_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv_plus_conv(in_channels: int, out_channels: int):\n",
    "    \"\"\"\n",
    "    Makes UNet block\n",
    "    :param in_channels: input channels\n",
    "    :param out_channels: output channels\n",
    "    :return: UNet block\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.BatchNorm2d(num_features=out_channels),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.BatchNorm2d(num_features=out_channels),\n",
    "        nn.LeakyReLU(0.2),\n",
    "    )\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        base_channels = 64\n",
    "\n",
    "        # Down-convolutions\n",
    "        self.down1 = conv_plus_conv(3, base_channels)\n",
    "        self.down2 = conv_plus_conv(base_channels, base_channels * 2)\n",
    "        self.down3 = conv_plus_conv(base_channels * 2, base_channels * 4)\n",
    "        self.down4 = conv_plus_conv(base_channels * 4, base_channels * 8)\n",
    "\n",
    "        # Up-convolutions\n",
    "        self.up1 = conv_plus_conv(base_channels * 12, base_channels * 4)\n",
    "        self.up2 = conv_plus_conv(base_channels * 6, base_channels * 2)\n",
    "        self.up3 = conv_plus_conv(base_channels * 3, base_channels)\n",
    "\n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(in_channels=base_channels, out_channels=3, kernel_size=1)\n",
    "\n",
    "        self.downsample = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Contracting Path\n",
    "        residual1 = self.down1(x)\n",
    "        x = self.downsample(residual1)\n",
    "\n",
    "        residual2 = self.down2(x)\n",
    "        x = self.downsample(residual2)\n",
    "\n",
    "        residual3 = self.down3(x)\n",
    "        x = self.downsample(residual3)\n",
    "\n",
    "        x = self.down4(x)\n",
    "\n",
    "        # Expansive Path\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat((x, residual3), dim=1)\n",
    "        x = self.up1(x)\n",
    "\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat((x, residual2), dim=1)\n",
    "        x = self.up2(x)\n",
    "\n",
    "        x = F.interpolate(x, scale_factor=2)\n",
    "        x = torch.cat((x, residual1), dim=1)\n",
    "        x = self.up3(x)\n",
    "\n",
    "        # Final Convolution\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = UNET().to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/116 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'transform_data.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m----> 2\u001b[0m whole_train_valid_cycle(model, \u001b[39m50\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mUNET segmentation\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[25], line 47\u001b[0m, in \u001b[0;36mwhole_train_valid_cycle\u001b[1;34m(model, num_epochs, title)\u001b[0m\n\u001b[0;32m     44\u001b[0m train_accuracy_history, valid_accuracy_history \u001b[39m=\u001b[39m [], []\n\u001b[0;32m     46\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 47\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m train(model)\n\u001b[0;32m     48\u001b[0m     valid_loss, valid_accuracy \u001b[39m=\u001b[39m evaluate(model, valid_loader)\n\u001b[0;32m     50\u001b[0m     train_loss_history\u001b[39m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[24], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     10\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     11\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m tqdm(train_loader, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     14\u001b[0m     bs \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     16\u001b[0m     x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'transform_data.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "whole_train_valid_cycle(model, 50, 'UNET segmentation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
