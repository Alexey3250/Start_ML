{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import OxfordIIITPet\nfrom torchvision.transforms import Compose, Resize, ToTensor, Lambda\nimport torchvision.transforms as T\nimport logging\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# rest of your code\n","metadata":{"execution":{"iopub.status.busy":"2023-07-07T16:41:04.286906Z","iopub.execute_input":"2023-07-07T16:41:04.287489Z","iopub.status.idle":"2023-07-07T16:41:09.664873Z","shell.execute_reply.started":"2023-07-07T16:41:04.287455Z","shell.execute_reply":"2023-07-07T16:41:09.663820Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#!g1.1\nimport torchvision.transforms as T\nfrom torchvision.datasets import OxfordIIITPet\n\ndataset = OxfordIIITPet('/home/jupyter/mnt/datasets/pets', target_types='segmentation', download=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-07T16:41:09.666871Z","iopub.execute_input":"2023-07-07T16:41:09.667705Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to /home/jupyter/mnt/datasets/pets/oxford-iiit-pet/images.tar.gz\n","output_type":"stream"},{"name":"stderr","text":" 21%|██▏       | 168460288/791918971 [00:08<00:26, 23497575.55it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[0][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(dataset[0][1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = T.Compose(\n    [\n        T.Resize((128, 128)),\n        T.ToTensor(),\n    ]\n)\n\ntarget_transform = T.Compose(\n    [\n        T.Resize((128, 128)),\n        T.PILToTensor(),\n        T.Lambda(lambda x: (x - 1).long())\n    ]\n)\n\ntrain_dataset = OxfordIIITPet('/home/jupyter/mnt/datasets/pets', transform=transform, target_transform=target_transform, target_types='segmentation', download=True)\nvalid_dataset = OxfordIIITPet('/home/jupyter/mnt/datasets/pets', transform=transform, split='test', target_transform=target_transform, target_types='segmentation', download=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model) -> float:\n    \"\"\"\n    Эта функция отвечает за обучение модели на данных из набора train_loader. \n    На каждой итерации происходит расчет ошибки модели и обратное распространение ошибки.\n    Возвращаются средний loss и точность на данных для обучения.\n    \"\"\"\n    model.train()\n\n    train_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(train_loader, desc='Train'):\n        bs = y.size(0)\n\n        x, y = x.to(device), y.squeeze(1).to(device)\n\n        optimizer.zero_grad()\n\n        output = model(x)\n\n        loss = loss_fn(output.reshape(bs, 3, -1), y.reshape(bs, -1))\n\n        train_loss += loss.item()\n\n        loss.backward()\n\n        optimizer.step()\n\n        _, y_pred = output.max(dim=1)\n        total += y.size(0) * y.size(1) * y.size(2)\n        correct += (y == y_pred).sum().item()\n\n    train_loss /= len(train_loader)\n    accuracy = correct / total\n\n    return train_loss, accuracy\n\n@torch.inference_mode()\ndef evaluate(model, loader) -> tuple[float, float]:\n    \"\"\"\n    Эта функция оценивает модель на валидационном наборе данных. \n    Она рассчитывает потери и точность модели на валидационных данных.\n    Возвращаются средний loss и точность на валидационных данных.\n    \"\"\"\n    model.eval()\n\n    total_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(loader, desc='Evaluation'):\n        bs = y.size(0)\n\n        x, y = x.to(device), y.squeeze(1).to(device)\n\n        output = model(x)\n\n        loss = loss_fn(output.reshape(bs, 3, -1), y.reshape(bs, -1))\n\n        total_loss += loss.item()\n\n        _, y_pred = output.max(dim=1)\n        total += y.size(0) * y.size(1) * y.size(2)\n        correct += (y == y_pred).sum().item()\n\n    total_loss /= len(loader)\n    accuracy = correct / total\n\n    return total_loss, accuracy\n\nfrom IPython.display import clear_output\ndef plot_stats(\n    train_loss: list[float],\n    valid_loss: list[float],\n    train_accuracy: list[float],\n    valid_accuracy: list[float],\n    title: str\n):\n    \"\"\"\n    Эта функция отображает графики потерь и точности модели на данных для обучения и валидации. \n    Отдельно выводятся графики для потерь и точности.\n    \"\"\"\n    plt.figure(figsize=(16, 8))\n\n    plt.title(title + ' loss')\n\n    plt.plot(train_loss, label='Train loss')\n    plt.plot(valid_loss, label='Valid loss')\n    plt.legend()\n    plt.grid()\n\n    plt.show()\n\n    plt.figure(figsize=(16, 8))\n\n    plt.title(title + ' accuracy')\n    \n    plt.plot(train_accuracy, label='Train accuracy')\n    plt.plot(valid_accuracy, label='Valid accuracy')\n    plt.legend()\n    plt.grid()\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef visualize(model, batch):\n    \"\"\"\n    Эта функция визуализирует результаты модели, предсказывая сегментацию на изображениях из валидационного набора данных. \n    Она выводит оригинальное изображение, маску сегментации и предсказание модели.\n    \"\"\"\n    model.eval()\n\n    xs, ys = batch\n    \n    to_pil = T.ToPILImage()\n\n    for i, (x, y) in enumerate(zip(xs, ys)):\n        prediction = model(x.unsqueeze(0).cuda()).squeeze(0).max(dim=0)[1]\n\n        fig, ax = plt.subplots(1, 3, figsize=(24, 8), facecolor='white')\n\n        ax[0].imshow(to_pil(x))\n        ax[1].imshow(to_pil(y.to(torch.uint8)))\n        ax[2].imshow(to_pil(prediction.to(torch.uint8)))\n\n        ax[0].axis('off')\n        ax[1].axis('off')\n        ax[2].axis('off')\n\n        ax[0].set_title('Original image')\n        ax[1].set_title('Segmentation mask')\n        ax[2].set_title('Prediction')\n\n        plt.subplots_adjust(wspace=0, hspace=0.1)\n        plt.show()\n\n        if i >= 9:\n            break\n            \ndef whole_train_valid_cycle(model, num_epochs, title):\n    \"\"\"\n    Эта функция производит полный цикл обучения и валидации модели. \n    Она проводит заданное количество эпох, на каждой эпохе сначала обучая модель, затем валидируя ее. \n    В процессе сохраняются истории потерь и точности, которые затем визуализируются. \n    После каждой эпохи также выводятся визуализации предсказаний модели.\n    \"\"\"\n    train_loss_history, valid_loss_history = [], []\n    train_accuracy_history, valid_accuracy_history = [], []\n\n    for epoch in range(num_epochs):\n        train_loss, train_accuracy = train(model)\n        valid_loss, valid_accuracy = evaluate(model, valid_loader)\n\n        train_loss_history.append(train_loss)\n        valid_loss_history.append(valid_loss)\n\n        train_accuracy_history.append(train_accuracy)\n        valid_accuracy_history.append(valid_accuracy)\n\n        clear_output()\n\n        plot_stats(\n            train_loss_history, valid_loss_history,\n            train_accuracy_history, valid_accuracy_history,\n            title\n        )\n\n        visualize(model, next(iter(valid_loader)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\ndef conv_plus_conv(in_channels: int, out_channels: int):\n    \"\"\"\n    Makes UNet block\n    :param in_channels: input channels\n    :param out_channels: output channels\n    :return: UNet block\n    \"\"\"\n    return nn.Sequential(\n        nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=out_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1\n        ),\n        nn.BatchNorm2d(num_features=out_channels),\n        nn.LeakyReLU(0.2),\n        nn.Conv2d(\n            in_channels=out_channels,\n            out_channels=out_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1\n        ),\n        nn.BatchNorm2d(num_features=out_channels),\n        nn.LeakyReLU(0.2),\n    )\n\nclass UNET(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        base_channels = 64\n\n        # Down-convolutions\n        self.down1 = conv_plus_conv(3, base_channels)\n        self.down2 = conv_plus_conv(base_channels, base_channels * 2)\n        self.down3 = conv_plus_conv(base_channels * 2, base_channels * 4)\n        self.down4 = conv_plus_conv(base_channels * 4, base_channels * 8)\n\n        # Up-convolutions\n        self.up1 = conv_plus_conv(base_channels * 12, base_channels * 4)\n        self.up2 = conv_plus_conv(base_channels * 6, base_channels * 2)\n        self.up3 = conv_plus_conv(base_channels * 3, base_channels)\n\n        # Final convolution\n        self.final_conv = nn.Conv2d(in_channels=base_channels, out_channels=3, kernel_size=1)\n\n        self.downsample = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        # Resize the input to the desired size\n        x = F.interpolate(x, size=(256, 256))\n\n        # Contracting Path\n        residual1 = self.down1(x)\n        x = self.downsample(residual1)\n\n        residual2 = self.down2(x)\n        x = self.downsample(residual2)\n\n        residual3 = self.down3(x)\n        x = self.downsample(residual3)\n\n        x = self.down4(x)\n\n        # Expansive Path\n        x = F.interpolate(x, scale_factor=2)\n        x = torch.cat((x, residual3), dim=1)\n        x = self.up1(x)\n\n        x = F.interpolate(x, scale_factor=2)\n        x = torch.cat((x, residual2), dim=1)\n        x = self.up2(x)\n\n        x = F.interpolate(x, scale_factor=2)\n        x = torch.cat((x, residual1), dim=1)\n        x = self.up3(x)\n\n        # Final Convolution\n        x = self.final_conv(x)\n\n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nprint(device)\nprint(torch.cuda.get_device_name())\n\nloss_fn = nn.CrossEntropyLoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim import Adam\n\nmodel = UNET().to(device)\n\noptimizer = Adam(model.parameters(), lr=1e-3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nwhole_train_valid_cycle(model, 1, 'UNET segmentation')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Switch model to evaluation mode\nmodel.eval()\n\n# Evaluate the model\nvalid_loss, valid_accuracy = evaluate(model, valid_loader)\nprint(f'Validation accuracy: {valid_accuracy*100:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef predict(model: nn.Module, loader: DataLoader, device: torch.device):\n    model.eval()\n    predictions = []\n    for x, _ in loader:\n        x = x.to(device)\n        outputs = model(x)\n        y_pred = torch.argmax(outputs, dim=1).unsqueeze(1)  # Apply argmax over the correct dimension and add an extra dimension\n        predictions.append(y_pred)\n    result = torch.cat(predictions)\n\n    return result\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_uint8.size()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = predict(model, test_loader, device)\n\n# Check the size of the predictions\nprint(predictions.size())  # Should be [200, 1, 256, 256]\n\n# Save the predictions as torch.uint8\npredictions_uint8 = predictions.to(torch.uint8)\ntorch.save(predictions_uint8, 'predictions_uint8.pth')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"1+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}