{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f1744b56-434e-423c-af00-5dea114df663",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Импортируем необходимые библиотеки\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertModel\n",
        "from transformers import RobertaModel\n",
        "from transformers import DistilBertModel\n",
        "\n",
        "# Определяем функцию для загрузки предобученных моделей\n",
        "def get_model(model_name):\n",
        "    assert model_name in ['bert', 'roberta', 'distilbert']\n",
        "    checkpoint_names = {\n",
        "        'bert': 'bert-base-cased',\n",
        "        'roberta': 'roberta-base',\n",
        "        'distilbert': 'distilbert-base-cased'\n",
        "    }\n",
        "    model_classes = {\n",
        "        'bert': BertModel,\n",
        "        'roberta': RobertaModel,\n",
        "        'distilbert': DistilBertModel\n",
        "    }\n",
        "    return AutoTokenizer.from_pretrained(checkpoint_names[model_name]), model_classes[model_name].from_pretrained(checkpoint_names[model_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8d572c86-4450-494a-b793-14d00c7afbe5",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Определяем функцию для получения эмбеддингов и меток из модели\n",
        "@torch.inference_mode()\n",
        "def get_embeddings_labels(model, loader):\n",
        "    model.eval()\n",
        "    \n",
        "    total_embeddings = []\n",
        "    labels = []\n",
        "    \n",
        "    for batch in tqdm(loader):\n",
        "        labels.append(batch['labels'].unsqueeze(1))\n",
        "\n",
        "        batch = {key: batch[key].to(device) for key in ['attention_mask', 'input_ids']}\n",
        "\n",
        "        embeddings = model(**batch)['last_hidden_state'][:, 0, :]\n",
        "\n",
        "        total_embeddings.append(embeddings.cpu())\n",
        "\n",
        "    return torch.cat(total_embeddings, dim=0), torch.cat(labels, dim=0).to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dd74ff4a-193c-403e-8b8a-3dc271c24563",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset imdb (C:/Users/Alex/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Загружаем набор данных IMDB\n",
        "dataset = load_dataset(\"imdb\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f7bb5e1e-6afc-4d9e-9efe-cbbc7085a1ce",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Инициализируем модель и токенизатор\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer, model = get_model('roberta')\n",
        "model = model.to(device)\n",
        "\n",
        "# Определяем функцию для токенизации текста\n",
        "def tokenization(example):\n",
        "    return tokenizer.batch_encode_plus(example['text'], add_special_tokens=True, return_token_type_ids=False, truncation=True, padding='max_length', max_length=512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7aad271f-feff-4ed5-b71f-a701746335d7",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        }
      ],
      "source": [
        "# Применяем функцию токенизации к набору данных и устанавливаем формат набора данных\n",
        "dataset = dataset.map(tokenization, batched=True)\n",
        "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "abc9c135-a8cf-48a7-b459-c960b72e9ac5",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Генерируем 200 случайных индексов\n",
        "np.random.seed(100)\n",
        "idx = np.random.randint(len(dataset), size=200).tolist()\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# Создаем data_collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Создаем DataLoader с data_collator\n",
        "loader = DataLoader(Subset(dataset, idx), batch_size=16, shuffle=False, collate_fn=data_collator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e3533d0d-1804-4456-9e77-6fbf675b780d",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/13 [00:00<?, ?it/s]You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100%|██████████| 13/13 [00:03<00:00,  3.32it/s]\n"
          ]
        }
      ],
      "source": [
        "# Получаем эмбеддинги и метки из модели\n",
        "embeddings, labels = get_embeddings_labels(model, loader)\n",
        "\n",
        "# Проверяем размерность эмбеддингов\n",
        "assert embeddings.shape == (200, 768), 'The embeddings tensor has the wrong shape.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aa7bed8c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([200, 768]) torch.Size([200, 1])\n"
          ]
        }
      ],
      "source": [
        "print(embeddings.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce414d65",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(embeddings, 'wtf.pt')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "noteable": {
      "last_transaction_id": "a8d6e758-67f2-4e62-b093-43da3f8db52f"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "a20be4ef-40c7-5cb0-9b8a-d57750c27229",
        "openai_ephemeral_user_id": "e26a19cb-7f23-5dbf-a41a-8d60ec03599a",
        "openai_subdivision1_iso_code": "AE-DU"
      }
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
