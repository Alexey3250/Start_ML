{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Извлечение векторных представлений из моделей трансформеров\n",
        "\n",
        "В этом туториале мы рассмотрим, как извлекать векторные представления (также известные как эмбеддинги) из предобученных моделей трансформеров, таких как BERT, RoBERTa и DistilBERT. Эти векторные представления могут быть использованы в качестве входных данных для других моделей машинного обучения или для анализа и визуализации текстовых данных."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "ed3a7101-9e1d-4670-bfdd-d0579e455c61"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "from transformers import BertTokenizer, BertModel, DataCollatorWithPadding\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "dca7496c-5217-4eb0-8195-d6d129eb6422"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных\n",
        "\n",
        "Мы начнем с загрузки датасета IMDb, который содержит отзывы на фильмы. Мы будем использовать только обучающую выборку для этого туториала."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "376c1beb-6d4e-4b57-9307-9ad0b55e0ad1"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"imdb\", split=\"train\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "6b907dd5-1250-4402-b6f1-c2bc94b880ae"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных\n",
        "\n",
        "Для демонстрации мы будем использовать только подмножество данных. Мы случайным образом выберем 200 примеров из нашего датасета. Затем мы определим устройство, на котором будут выполняться наши вычисления (GPU, если доступно, иначе CPU)."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "e03abb38-9022-48ab-94b2-3aff73b75fc7"
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(100)\n",
        "\n",
        "idx = np.random.randint(len(dataset), size=200)\n",
        "\n",
        "index_list = idx.tolist()\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"Device:\", device)\n",
        "\n",
        "if device.type == 'cuda':\n",
        "\n",
        "    print(\"GPU:\", torch.cuda.get_device_name())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "b0b88474-c774-41bc-bc52-5c92ffac1614"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка модели BERT\n",
        "\n",
        "Мы начнем с загрузки предобученной модели BERT. Мы будем использовать базовую версию модели BERT, обученную на английском языке."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "4ae2c61f-faad-4493-9094-00c1774cea70"
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained(\"bert-base-cased\").to(device)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "c1975c06-4818-4603-b1d8-fc39c4a389d5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Токенизация\n",
        "\n",
        "Прежде чем мы сможем использовать наши текстовые данные с моделью BERT, нам нужно преобразовать их в формат, который модель может понять. Это процесс называется токенизацией. Мы будем использовать токенизатор, соответствующий нашей модели BERT."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "86b390c1-77db-4fa9-80ad-4291a21e0576"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "def tokenization(example):\n",
        "\n",
        "    return tokenizer.batch_encode_plus(example['text'], add_special_tokens=True, return_token_type_ids=False,\n",
        "\n",
        "                                       truncation=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "794aca71-a4ad-4615-8a72-8406d85c9acf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных для модели\n",
        "\n",
        "Теперь, когда у нас есть функция для токенизации наших данных, мы можем применить ее к нашему датасету. Затем мы установим формат нашего датасета на \"torch\", чтобы мы могли использовать его с нашей моделью PyTorch."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "5debf183-cb00-4ca3-a235-8d875c6500fc"
    },
    {
      "cell_type": "code",
      "source": [
        "subset = Subset(dataset, index_list)\n",
        "\n",
        "subset = subset.map(tokenization, batched=True, batch_size=len(subset))\n",
        "\n",
        "subset.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "d634ebe1-a63f-41a5-b100-cec9a918276c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Извлечение эмбеддингов\n",
        "\n",
        "Теперь, когда наши данные готовы, мы можем применить нашу модель BERT к ним, чтобы получить эмбеддинги. Мы будем использовать DataLoader для батчевой обработки наших данных. Затем мы пройдемся по каждому батчу, применим модель и сохраним полученные эмбеддинги."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "ba2a929a-a283-4a0b-befc-84696fc36e24"
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(subset, batch_size=16, shuffle=False)\n",
        "\n",
        "embeddings = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "\n",
        "        embeddings.append(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
        "\n",
        "embeddings = np.concatenate(embeddings)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "2acc7884-d085-4c41-80c2-15ed0fa666c6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Результаты\n",
        "\n",
        "Теперь у нас есть векторные представления для каждого примера в нашем датасете. Каждое представление имеет размерность 768, что соответствует размерности скрытого состояния модели BERT, которую мы использовали."
      ],
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "id": "aa195ca1-b871-4693-a1ba-0dc11a782007"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Embeddings shape:\", embeddings.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "id": "d0aea6e0-9780-4987-b895-5538f8d86af0"
    }
  ],
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "21db436d-3782-5a03-a366-8fd320462d17",
        "openai_ephemeral_user_id": "e26a19cb-7f23-5dbf-a41a-8d60ec03599a",
        "openai_subdivision1_iso_code": "AE-DU"
      }
    },
    "noteable": {
      "last_transaction_id": "23682d57-ab31-4ffa-b8cf-956145566ba3",
      "last_delta_id": "8d4bf9f8-13fb-4a70-b10c-5f3bc342299b"
    },
    "selected_hardware_size": "small",
    "nteract": {
      "version": "noteable@2.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}