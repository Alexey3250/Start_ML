{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c150cf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import DataCollatorWithPadding, AutoTokenizer, BertModel, RobertaModel, DistilBertModel\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Игнорируем предупреждения\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Определяем доступное устройство для вычислений (GPU если доступно, иначе CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def get_model(model_name):\n",
    "    \"\"\"Функция для получения предобученной модели и токенизатора по имени\"\"\"\n",
    "    \n",
    "    # Поддерживаемые модели\n",
    "    assert model_name in ['bert', 'roberta', 'distilbert']\n",
    "    \n",
    "    # Словарь с именами контрольных точек для каждой модели\n",
    "    checkpoint_names = {\n",
    "        'bert': 'bert-base-cased', \n",
    "        'roberta': 'roberta-base',\n",
    "        'distilbert': 'distilbert-base-cased'\n",
    "    }\n",
    "    \n",
    "    # Словарь с классами моделей\n",
    "    model_classes = {\n",
    "        'bert': BertModel,\n",
    "        'roberta': RobertaModel,\n",
    "        'distilbert': DistilBertModel\n",
    "    }\n",
    "    \n",
    "    # Возвращаем токенизатор и модель\n",
    "    return AutoTokenizer.from_pretrained(checkpoint_names[model_name]), model_classes[model_name].from_pretrained(checkpoint_names[model_name])\n",
    "\n",
    "def tokenization(example):\n",
    "    \"\"\"Функция для токенизации примеров из датасета\"\"\"\n",
    "    return tokenizer.batch_encode_plus(example['text'], add_special_tokens=True, return_token_type_ids=False, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a751f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Получаем токенизатор и модель BERT\n",
    "tokenizer, model = get_model('bert')\n",
    "\n",
    "# Переносим модель на устройство\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca6c3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (C:/Users/Alex/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Loading cached processed dataset at C:\\Users\\Alex\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-09c26827f4451b24.arrow\n"
     ]
    }
   ],
   "source": [
    "# Загружаем датасет IMDB\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "\n",
    "# Токенизируем датасет\n",
    "train_dataset = dataset.map(tokenization, batched=True)\n",
    "train_dataset.set_format(type=\"torch\", columns=[ 'label', 'input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f586b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем коллатор данных с автоматическим заполнением\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88cab869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем случайный набор данных для обучения\n",
    "np.random.seed(100)\n",
    "idx = np.random.randint(len(train_dataset), size=200).tolist()\n",
    "loader = DataLoader(Subset(train_dataset, idx), batch_size=64, collate_fn=data_collator, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de98158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6028,  0.1125, -0.2223,  ..., -0.1698,  0.1655,  0.0645],\n",
       "         [ 0.6183,  0.0239, -0.2428,  ..., -0.1532,  0.1792,  0.1111],\n",
       "         [ 0.3977,  0.1045, -0.1627,  ..., -0.0737,  0.2369,  0.1243],\n",
       "         ...,\n",
       "         [ 0.5241,  0.1857, -0.4136,  ..., -0.2503,  0.0959,  0.2350],\n",
       "         [ 0.6121,  0.0789, -0.1658,  ..., -0.1467,  0.4310,  0.1626],\n",
       "         [ 0.6343,  0.0062, -0.1479,  ..., -0.2116,  0.1337,  0.1664]]),\n",
       " tensor([[0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем эмбеддинги и метки\n",
    "\n",
    "@torch.inference_mode()\n",
    "def get_embeddings_labels(model, loader):\n",
    "    model.eval()\n",
    "    \n",
    "    total_embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        labels.append(batch['labels'].unsqueeze(1))\n",
    "\n",
    "        batch = {key: batch[key].to(device) for key in ['attention_mask', 'input_ids']}\n",
    "\n",
    "        embeddings = model(**batch)['last_hidden_state'][:, 0, :]\n",
    "\n",
    "        total_embeddings.append(embeddings.cpu())\n",
    "\n",
    "    return torch.cat(total_embeddings, dim=0), torch.cat(labels, dim=0).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a3aeae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings, train_labels = get_embeddings_labels(model, loader)\n",
    "torch.save(train_embeddings, \"train.pth\")\n",
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ab1777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# save embeddings\n",
    "save_path = 'embeddings.pt'\n",
    "torch.save(get_embeddings_labels(model, loader), save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
