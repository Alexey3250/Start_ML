{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-04T15:19:26.181802Z","iopub.execute_input":"2023-05-04T15:19:26.182130Z","iopub.status.idle":"2023-05-04T15:19:26.187666Z","shell.execute_reply.started":"2023-05-04T15:19:26.182104Z","shell.execute_reply":"2023-05-04T15:19:26.186786Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as T\nfrom IPython.display import clear_output\nfrom PIL import Image\nfrom matplotlib import cm\nfrom time import perf_counter\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import CIFAR10\nfrom tqdm import tqdm\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\n\nwarnings.filterwarnings('ignore')\n\nplt.rc('font', size=30)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:26.192433Z","iopub.execute_input":"2023-05-04T15:19:26.193114Z","iopub.status.idle":"2023-05-04T15:19:26.204723Z","shell.execute_reply.started":"2023-05-04T15:19:26.193079Z","shell.execute_reply":"2023-05-04T15:19:26.203871Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"means = (0.49139968, 0.48215841, 0.44653091)\nstds = (0.24703223, 0.24348513, 0.26158784)\n\ntrain_transforms = T.Compose(\n    [\n        T.RandomResizedCrop(size=32, scale=(0.8, 1.1)),\n        T.RandomHorizontalFlip(p=0.5),\n        T.RandomAdjustSharpness(sharpness_factor=2),\n        T.ToTensor(),\n        T.Normalize(mean=means, std=stds)\n    ]\n)\n\ntest_transforms = T.Compose(\n    [\n        T.ToTensor(),\n        T.Normalize(mean=means, std=stds)\n    ]\n)\n\n\ntrain_dataset = CIFAR10('/home/jupyter/mnt/datasets/cifar10', train=True, download=True, transform=train_transforms)\nvalid_dataset = CIFAR10('/home/jupyter/mnt/datasets/cifar10', train=False, download=True,transform=test_transforms)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:26.206715Z","iopub.execute_input":"2023-05-04T15:19:26.207399Z","iopub.status.idle":"2023-05-04T15:19:27.867619Z","shell.execute_reply.started":"2023-05-04T15:19:26.207368Z","shell.execute_reply":"2023-05-04T15:19:27.866729Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(model) -> float:\n    model.train()\n\n    train_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(train_loader, desc='Train'):\n        x, y = x.to(device), y.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(x)\n\n        loss = loss_fn(output, y)\n\n        train_loss += loss.item()\n\n        loss.backward()\n\n        optimizer.step()\n        \n        _, y_pred = torch.max(output, 1)\n        total += y.size(0)\n        correct += (y_pred == y).sum().item()\n\n    train_loss /= len(train_loader)\n    accuracy = correct / total\n\n    return train_loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:27.868913Z","iopub.execute_input":"2023-05-04T15:19:27.869295Z","iopub.status.idle":"2023-05-04T15:19:27.876363Z","shell.execute_reply.started":"2023-05-04T15:19:27.869261Z","shell.execute_reply":"2023-05-04T15:19:27.875356Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef evaluate(model, loader) -> tuple[float, float]:\n    model.eval()\n\n    total_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(loader, desc='Evaluation'):\n        x, y = x.to(device), y.to(device)\n\n        output = model(x)\n\n        loss = loss_fn(output, y)\n\n        total_loss += loss.item()\n\n        _, y_pred = torch.max(output, 1)\n        total += y.size(0)\n        correct += (y_pred == y).sum().item()\n\n    total_loss /= len(loader)\n    accuracy = correct / total\n\n    return total_loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:27.878891Z","iopub.execute_input":"2023-05-04T15:19:27.879419Z","iopub.status.idle":"2023-05-04T15:19:27.887118Z","shell.execute_reply.started":"2023-05-04T15:19:27.879381Z","shell.execute_reply":"2023-05-04T15:19:27.886207Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def plot_stats(\n    train_loss: list[float],\n    valid_loss: list[float],\n    train_accuracy: list[float],\n    valid_accuracy: list[float],\n    title: str\n):\n    plt.figure(figsize=(16, 8))\n\n    plt.title(title + ' loss')\n\n    plt.plot(train_loss, label='Train loss')\n    plt.plot(valid_loss, label='Valid loss')\n    plt.legend()\n    plt.grid()\n\n    plt.show()\n\n    plt.figure(figsize=(16, 8))\n\n    plt.title(title + ' accuracy')\n    \n    plt.plot(train_accuracy, label='Train accuracy')\n    plt.plot(valid_accuracy, label='Valid accuracy')\n    plt.legend()\n    plt.grid()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:27.888286Z","iopub.execute_input":"2023-05-04T15:19:27.889282Z","iopub.status.idle":"2023-05-04T15:19:27.902208Z","shell.execute_reply.started":"2023-05-04T15:19:27.889248Z","shell.execute_reply":"2023-05-04T15:19:27.901434Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef predict(model: nn.Module, loader: DataLoader, device: torch.device):\n    model.eval()\n    preds = []\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        output = model(x)\n        preds.append(output)\n    return torch.cat(preds)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:27.903424Z","iopub.execute_input":"2023-05-04T15:19:27.903873Z","iopub.status.idle":"2023-05-04T15:19:27.914671Z","shell.execute_reply.started":"2023-05-04T15:19:27.903837Z","shell.execute_reply":"2023-05-04T15:19:27.913802Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef predict_tta(model: nn.Module, loader: DataLoader, device: torch.device, iterations: int = 2):\n    model.eval()\n    prediction = []\n\n    for i in range(iterations):\n        single_prediction = []\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            output = model(x)\n            single_prediction.append(output)\n        prediction.append(torch.cat(single_prediction))\n     \n    prediction = torch.stack(prediction).mean(dim=0)\n    prediction = torch.argmax(prediction, dim=1)\n    return prediction","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:27.915990Z","iopub.execute_input":"2023-05-04T15:19:27.916487Z","iopub.status.idle":"2023-05-04T15:19:27.924994Z","shell.execute_reply.started":"2023-05-04T15:19:27.916457Z","shell.execute_reply":"2023-05-04T15:19:27.923897Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"### Функция для сохранения предсказаний обученной модели\n\ndef save_data(preds, name):\n    torch.save(preds, f'/kaggle/working/{name}')","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:27.926145Z","iopub.execute_input":"2023-05-04T15:19:27.926534Z","iopub.status.idle":"2023-05-04T15:19:27.934924Z","shell.execute_reply.started":"2023-05-04T15:19:27.926505Z","shell.execute_reply":"2023-05-04T15:19:27.934038Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def whole_train_valid_cycle_with_schedule(model, title):\n    train_loss_history, valid_loss_history = [], []\n    train_accuracy_history, valid_accuracy_history = [], []\n    \n    valid_accuracy = 0\n    num_epochs = 0\n    \n\n    while valid_accuracy < 0.9:\n        \n        num_epochs += 1 \n        \n        train_loss, train_accuracy = train(model)\n        valid_loss, valid_accuracy = evaluate(model, valid_loader)\n\n        train_loss_history.append(train_loss)\n        valid_loss_history.append(valid_loss)\n\n        train_accuracy_history.append(train_accuracy)\n        valid_accuracy_history.append(valid_accuracy)\n\n        clear_output()\n\n        plot_stats(\n            train_loss_history, valid_loss_history,\n            train_accuracy_history, valid_accuracy_history,\n            f'{title}, {num_epochs} epoch'\n        )\n        \n        scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:27.936124Z","iopub.execute_input":"2023-05-04T15:19:27.937051Z","iopub.status.idle":"2023-05-04T15:19:27.949937Z","shell.execute_reply.started":"2023-05-04T15:19:27.937020Z","shell.execute_reply":"2023-05-04T15:19:27.948972Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def create_advanced_conv_cifar():\n    return nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),  # 32 x 32 x 32\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),  # 32 x 32 x 32\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n\n            nn.MaxPool2d(2),  # 16 x 16 x 32\n            nn.Dropout2d(p=0.2),\n\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),  # 16 x 16 x 64\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),  # 16 x 16 x 64\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n\n            nn.MaxPool2d(2),  # 8 x 8 x 32\n            nn.Dropout2d(p=0.2),\n            \n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),  # 8 x 8 x 128\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),  # 8 x 8 x 128\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n\n            nn.MaxPool2d(2),  # 4 x 4 x 128\n            nn.Dropout2d(p=0.2),\n\n            nn.Flatten(),\n\n            nn.Linear(4 * 4 * 128, 512),\n            nn.BatchNorm1d(512),\n            nn.Dropout(p=0.3),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:27.953270Z","iopub.execute_input":"2023-05-04T15:19:27.954139Z","iopub.status.idle":"2023-05-04T15:19:27.963207Z","shell.execute_reply.started":"2023-05-04T15:19:27.954108Z","shell.execute_reply":"2023-05-04T15:19:27.962697Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0')\nmodel = create_advanced_conv_cifar().to(device)\noptimizer = Adam(model.parameters(), lr=1e-3)\nscheduler = StepLR(optimizer, step_size=25)\nloss_fn = nn.CrossEntropyLoss()\n\n# whole_train_valid_cycle_with_schedule(model, 'ex_10')","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:27.964420Z","iopub.execute_input":"2023-05-04T15:19:27.965347Z","iopub.status.idle":"2023-05-04T15:19:27.998029Z","shell.execute_reply.started":"2023-05-04T15:19:27.965316Z","shell.execute_reply":"2023-05-04T15:19:27.997234Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Lesson 5, ex. 7","metadata":{}},{"cell_type":"code","source":"class Model_with_skip_connection(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.block1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1), \n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n    \n        self.block2 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), \n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n\n        self.block3 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),  \n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n\n        self.block4 = nn.Sequential( \n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),  \n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n            \n        self.block5 = nn.Sequential(    \n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n\n        self.block6 = nn.Sequential(     \n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n        \n        self.pool_n_dropout = nn.Sequential(\n            nn.MaxPool2d(2), \n            nn.Dropout2d(p=0.2)\n         )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(4 * 4 * 128, 512),\n            nn.BatchNorm1d(512),\n            nn.Dropout(p=0.3),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n    \n    def forward(self, x):\n        block_num = 0\n        for block in (self.block1, self.block2, self.block3,\n                      self.block4, self.block5, self.block6):\n            x = block(x) + x\n            block_num += 1     \n            if (block_num % 2) == 0:\n                x = self.pool_n_dpopout(x) # Пулинг и дропаут после каждой второй свертки      \n        x = self.classifier(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:52.903415Z","iopub.execute_input":"2023-05-04T15:19:52.904182Z","iopub.status.idle":"2023-05-04T15:19:52.917646Z","shell.execute_reply.started":"2023-05-04T15:19:52.904148Z","shell.execute_reply":"2023-05-04T15:19:52.915283Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def create_advanced_skip_connection_conv_cifar():\n    return Model_with_skip_connection()","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:28.011747Z","iopub.execute_input":"2023-05-04T15:19:28.012700Z","iopub.status.idle":"2023-05-04T15:19:28.025763Z","shell.execute_reply.started":"2023-05-04T15:19:28.012668Z","shell.execute_reply":"2023-05-04T15:19:28.024966Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0')\nmodel = create_advanced_skip_connection_conv_cifar().to(device)\noptimizer = Adam(model.parameters(), lr=1e-3)\nscheduler = StepLR(optimizer, step_size=25)\nloss_fn = nn.CrossEntropyLoss()\n\nwhole_train_valid_cycle_with_schedule(model, 'ex_7')","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:55.154599Z","iopub.execute_input":"2023-05-04T15:19:55.154934Z","iopub.status.idle":"2023-05-04T15:20:02.090086Z","shell.execute_reply.started":"2023-05-04T15:19:55.154906Z","shell.execute_reply":"2023-05-04T15:20:02.088743Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Train:   0%|          | 0/391 [00:06<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m StepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m      5\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mwhole_train_valid_cycle_with_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mex_7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[35], line 13\u001b[0m, in \u001b[0;36mwhole_train_valid_cycle_with_schedule\u001b[0;34m(model, title)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m valid_accuracy \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.9\u001b[39m:\n\u001b[1;32m     11\u001b[0m     num_epochs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[0;32m---> 13\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, valid_loader)\n\u001b[1;32m     16\u001b[0m     train_loss_history\u001b[38;5;241m.\u001b[39mappend(train_loss)\n","Cell \u001b[0;32mIn[29], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      9\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, y)\n\u001b[1;32m     17\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[41], line 59\u001b[0m, in \u001b[0;36mModel_with_skip_connection.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m block_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock3,\n\u001b[1;32m     58\u001b[0m               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock4, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock5, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock6):\n\u001b[0;32m---> 59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[1;32m     60\u001b[0m     block_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m     \n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (block_num \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (3) at non-singleton dimension 1"],"ename":"RuntimeError","evalue":"The size of tensor a (64) must match the size of tensor b (3) at non-singleton dimension 1","output_type":"error"}]},{"cell_type":"code","source":"# preds = predict(model=model, loader=valid_loader, device=device)\n# preds_tta = predict_tta(model=model, loader=valid_loader, device=device)\n\n# save_data(preds, 'ex_10_preds')\n# save_data(preds_tta, 'ex_10_preds_tta')\n# save_data(model.state_dict(), 'ex_10_params')","metadata":{"execution":{"iopub.status.busy":"2023-05-04T15:19:30.044837Z","iopub.status.idle":"2023-05-04T15:19:30.046055Z","shell.execute_reply.started":"2023-05-04T15:19:30.045831Z","shell.execute_reply":"2023-05-04T15:19:30.045853Z"},"trusted":true},"execution_count":null,"outputs":[]}]}