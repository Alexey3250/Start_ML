{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f0231b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Airflow\" data-toc-modified-id=\"Airflow-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Airflow</a></span><ul class=\"toc-item\"><li><span><a href=\"#Зачем?\" data-toc-modified-id=\"Зачем?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Зачем?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проблема-batch-запуска\" data-toc-modified-id=\"Проблема-batch-запуска-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Проблема batch-запуска</a></span></li><li><span><a href=\"#Простое-решение\" data-toc-modified-id=\"Простое-решение-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Простое решение</a></span></li><li><span><a href=\"#Готовые-решения\" data-toc-modified-id=\"Готовые-решения-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Готовые решения</a></span></li></ul></li><li><span><a href=\"#Основные-концепции\" data-toc-modified-id=\"Основные-концепции-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Основные концепции</a></span><ul class=\"toc-item\"><li><span><a href=\"#DAG\" data-toc-modified-id=\"DAG-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>DAG</a></span></li></ul></li><li><span><a href=\"#Оператор\" data-toc-modified-id=\"Оператор-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Оператор</a></span><ul class=\"toc-item\"><li><span><a href=\"#BashOperator\" data-toc-modified-id=\"BashOperator-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>BashOperator</a></span></li><li><span><a href=\"#PythonOperator\" data-toc-modified-id=\"PythonOperator-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>PythonOperator</a></span></li></ul></li><li><span><a href=\"#Про-даты\" data-toc-modified-id=\"Про-даты-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Про даты</a></span></li><li><span><a href=\"#Передача-информации\" data-toc-modified-id=\"Передача-информации-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Передача информации</a></span><ul class=\"toc-item\"><li><span><a href=\"#XCom\" data-toc-modified-id=\"XCom-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>XCom</a></span></li></ul></li><li><span><a href=\"#Connections,-Variables\" data-toc-modified-id=\"Connections,-Variables-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Connections, Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Connections\" data-toc-modified-id=\"Connections-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Connections</a></span></li><li><span><a href=\"#Variables\" data-toc-modified-id=\"Variables-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>Variables</a></span></li></ul></li><li><span><a href=\"#Best-practices\" data-toc-modified-id=\"Best-practices-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Best practices</a></span><ul class=\"toc-item\"><li><span><a href=\"#Идемпотентность\" data-toc-modified-id=\"Идемпотентность-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>Идемпотентность</a></span></li><li><span><a href=\"#Один-таск-=-одна-законченная-операция\" data-toc-modified-id=\"Один-таск-=-одна-законченная-операция-1.7.2\"><span class=\"toc-item-num\">1.7.2&nbsp;&nbsp;</span>Один таск = одна законченная операция</a></span></li><li><span><a href=\"#Осторожнее-с-datetime.now()\" data-toc-modified-id=\"Осторожнее-с-datetime.now()-1.7.3\"><span class=\"toc-item-num\">1.7.3&nbsp;&nbsp;</span>Осторожнее с <code>datetime.now()</code></a></span></li><li><span><a href=\"#Не-хранить-много-в-XCom\" data-toc-modified-id=\"Не-хранить-много-в-XCom-1.7.4\"><span class=\"toc-item-num\">1.7.4&nbsp;&nbsp;</span>Не хранить много в XCom</a></span></li><li><span><a href=\"#Использовать-Airflow-как-орекстратор\" data-toc-modified-id=\"Использовать-Airflow-как-орекстратор-1.7.5\"><span class=\"toc-item-num\">1.7.5&nbsp;&nbsp;</span>Использовать Airflow как орекстратор</a></span></li><li><span><a href=\"#Тестировать-код-Airflow\" data-toc-modified-id=\"Тестировать-код-Airflow-1.7.6\"><span class=\"toc-item-num\">1.7.6&nbsp;&nbsp;</span>Тестировать код Airflow</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9d8192",
   "metadata": {},
   "source": [
    "# Airflow\n",
    "## Зачем?\n",
    "### Проблема batch-запуска\n",
    "Представим, что вы с командой довели ML-модель до рабочего состояния, увидели первые результаты в юпитер-ноутбуке (или на простых скриптах) и теперь хотите поставить на поток расчеты.\n",
    "\n",
    "Мы уже умеет выставить API для доступа к модели через веб. Тем не менее, использование модели через API означает, что модель будет считаться _по запросу_, а не регулярно. Как же быть, если мы захотим считать предсказания каждый день?\n",
    "\n",
    "_Такой режим запуска называется batch-режимом._\n",
    "\n",
    "### Простое решение\n",
    "Кажется, что можно решить вопрос в два этапа:\n",
    "1. Сделать скрипт/обертку над ноутбуком, который можно запустить простой командой и результатом будут все предсказания.\n",
    "2. Руками запускать скрипт каждый день.\n",
    "\n",
    "Есть как минимум три проблемы. Во-первых, модель вы будете запускать, скорее всего, не на рабочем компьютере, а на сервере. Значит, вам придется каждый день подключаться к серверу, запускать скрипт и затем каким-то образом получать результаты с сервера.\n",
    "Во-вторых, моделей может стать много, и запускать каждую из них может быть утомительно (поверьте, через неделю вам это надоест).\n",
    "В-третьих, вы не имеете _наблюдаемости_ - скрипт модели может упасть через час после того, как вы вручную его запустите, и вы узнаете об этом только на следующий день. Если, скажем, захочется иметь автоматический перезапуск - придется его реализовывать самостоятельно.\n",
    "\n",
    "### Готовые решения\n",
    "Для решения проблемы с регулярного запуском существует несколько готовых инструментов. Вот два самых популярных:\n",
    "- [Luigi](https://github.com/spotify/luigi)\n",
    "- [Airflow](https://airflow.apache.org)\n",
    "\n",
    "В этом курсе мы остановимся на Airflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1cc5e8",
   "metadata": {},
   "source": [
    "## Основные концепции\n",
    "Airflow базируется на следующих принципах:\n",
    "- Сложный процесс обработки данных разбивается на шаги.\n",
    "- Из шагов выстраивается _граф зависимостей_ - какие шаги выполнять первыми и кому чьи результаты нужны.\n",
    "- Этот _граф зависимостей_ должен быть без циклов. В терминологии Airflow он называется **DAG** (_directed acyclic graph_).\n",
    "- DAG описывается программно из Python. То есть, весь граф можно динамически построить в цикле, а можно заранее прописать кодом.\n",
    "- DAG имеет информацию по своем запуску:\n",
    "    - когда начать запускать\n",
    "    - с какой периодичностью\n",
    "    - сколько раз пытаться\n",
    "    - кому писать email в случае провала\n",
    "    - сколько раз пытаться перезапустить в случае провала\n",
    "- Система самостоятельно запускает DAG в соответствии с информацией по запуску.\n",
    "\n",
    "Airflow поддерживает запуск не только Python-кода, но и shell скриптов, docker контейнеров - словом, может запускать много чего.\n",
    "### DAG\n",
    "DAG хранит описание процесса обработки данных. Пример DAG ниже:\n",
    "<div>\n",
    "<img src=\"https://airflow.apache.org/docs/apache-airflow/stable/_images/branch_note.png\" width=\"900\"/>\n",
    "</div>\n",
    "DAG может ветвиться, задачи в нем могут иметь условия (например, если сегодня выходной, то пропустить стадию из DAG).\n",
    "\n",
    "Посмотрим на пример DAG из [документации](https://airflow.apache.org/docs/apache-airflow/stable/tutorial.html) (не запустится в Jupyter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d95e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T13:13:10.006144Z",
     "start_time": "2022-03-01T13:13:09.870847Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OSError while attempting to symlink the latest log directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">C:\\Users\\aefim\\AppData\\Local\\Temp\\ipykernel_45976\\</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3748364993.</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">13</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> RemovedInAirflow3Warning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mC:\\Users\\aefim\\AppData\\Local\\Temp\\ipykernel_45976\\\u001b[0m\u001b[1;33m3748364993.\u001b[0m\u001b[1;33mpy:\u001b[0m\u001b[1;33m13\u001b[0m\u001b[1;33m RemovedInAirflow3Warning\u001b[0m\u001b[33m: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test documentation\n",
    "\"\"\"\n",
    "from datetime import datetime, timedelta\n",
    "from textwrap import dedent\n",
    "\n",
    "# Для объявления DAG нужно импортировать класс из airflow\n",
    "from airflow import DAG\n",
    "\n",
    "# Операторы - это кирпичики DAG, они являются звеньями в графе\n",
    "# Будем иногда называть операторы тасками (tasks)\n",
    "from airflow.operators.bash import BashOperator\n",
    "with DAG(\n",
    "    'tutorial',\n",
    "    # Параметры по умолчанию для тасок\n",
    "    default_args={\n",
    "        # Если прошлые запуски упали, надо ли ждать их успеха\n",
    "        'depends_on_past': False,\n",
    "        # Кому писать при провале\n",
    "        'email': ['airflow@example.com'],\n",
    "        # А писать ли вообще при провале?\n",
    "        'email_on_failure': False,\n",
    "        # Писать ли при автоматическом перезапуске по провалу\n",
    "        'email_on_retry': False,\n",
    "        # Сколько раз пытаться запустить, далее помечать как failed\n",
    "        'retries': 1,\n",
    "        # Сколько ждать между перезапусками\n",
    "        'retry_delay': timedelta(minutes=5),  # timedelta из пакета datetime\n",
    "    },\n",
    "    # Описание DAG (не тасок, а самого DAG)\n",
    "    description='A simple tutorial DAG',\n",
    "    # Как часто запускать DAG\n",
    "    schedule_interval=timedelta(days=1),\n",
    "    # С какой даты начать запускать DAG\n",
    "    # Каждый DAG \"видит\" свою \"дату запуска\"\n",
    "    # это когда он предположительно должен был\n",
    "    # запуститься. Не всегда совпадает с датой на вашем компьютере\n",
    "    start_date=datetime(2022, 1, 1),\n",
    "    # Запустить за старые даты относительно сегодня\n",
    "    # https://airflow.apache.org/docs/apache-airflow/stable/dag-run.html\n",
    "    catchup=False,\n",
    "    # теги, способ помечать даги\n",
    "    tags=['example'],\n",
    ") as dag:\n",
    "\n",
    "    # t1, t2, t3 - это операторы (они формируют таски, а таски формируют даг)\n",
    "    t1 = BashOperator(\n",
    "        task_id='print_date',  # id, будет отображаться в интерфейсе\n",
    "        bash_command='date',  # какую bash команду выполнить в этом таске\n",
    "    )\n",
    "\n",
    "    t2 = BashOperator(\n",
    "        task_id='sleep',\n",
    "        depends_on_past=False,  # переопределили настройку из DAG\n",
    "        bash_command='sleep 5',\n",
    "        retries=3,  # тоже переопределили retries (было 1)\n",
    "    )\n",
    "    t1.doc_md = dedent(\n",
    "        \"\"\"\\\n",
    "    #### Task Documentation\n",
    "    You can document your task using the attributes `doc_md` (markdown),\n",
    "    `doc` (plain text), `doc_rst`, `doc_json`, `doc_yaml` which gets\n",
    "    rendered in the UI's Task Instance Details page.\n",
    "    ![img](http://montcs.bloomu.edu/~bobmon/Semesters/2012-01/491/import%20soul.png)\n",
    "\n",
    "    \"\"\"\n",
    "    )  # dedent - это особенность Airflow, в него нужно оборачивать всю доку\n",
    "\n",
    "    dag.doc_md = __doc__  # Можно забрать докстрингу из начала файла вот так\n",
    "    dag.doc_md = \"\"\"\n",
    "    This is a documentation placed anywhere\n",
    "    \"\"\"  # а можно явно написать\n",
    "    # формат ds: 2021-12-25\n",
    "    templated_command = dedent(\n",
    "        \"\"\"\n",
    "    {% for i in range(5) %}\n",
    "        echo \"{{ ds }}\"\n",
    "        echo \"{{ macros.ds_add(ds, 7)}}\"\n",
    "    {% endfor %}\n",
    "    \"\"\"\n",
    "    )  # поддерживается шаблонизация через Jinja\n",
    "    # https://airflow.apache.org/docs/apache-airflow/stable/concepts/operators.html#concepts-jinja-templating\n",
    "\n",
    "    t3 = BashOperator(\n",
    "        task_id='templated',\n",
    "        depends_on_past=False,\n",
    "        bash_command=templated_command,\n",
    "    )\n",
    "\n",
    "    # А вот так в Airflow указывается последовательность задач\n",
    "    t1 >> [t2, t3]\n",
    "    # будет выглядеть вот так\n",
    "    #      -> t2\n",
    "    #  t1 | \n",
    "    #      -> t3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0ce5e",
   "metadata": {},
   "source": [
    "## Оператор\n",
    "Оператор - это описание действия, которые нужно выполнить. Операторы образуют таски (_tasks_, _задачи_), они могут зависеть друг от друга. Мы уже видели `BashOperator`.\n",
    "\n",
    "Каждый оператор должен иметь **уникальный** ID.\n",
    "Помимо этого оператор может иметь много информации о себе: число retry, документацию и т.д.\n",
    "\n",
    "Познакомимся с основыми операторами.\n",
    "\n",
    "### BashOperator\n",
    "Служил для выполнения bash-команд (команд консоли Linux). Может исполнять одну команду, а может целый скрипт.\n",
    "\n",
    "[Документация](https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/bash.html)\n",
    "\n",
    "```python\n",
    "# вот так можно попросить Airflow подставить логическую дату\n",
    "# в формате YYYY-MM-DD\n",
    "date = \"{{ ds }}\"\n",
    "t = BashOperator(\n",
    "    task_id=\"test_env\",\n",
    "    bash_command=\"/tmp/test.sh \",  # обратите внимание на пробел в конце!\n",
    "    # пробел в конце нужен в случае BashOperator из-за проблем с шаблонизацией\n",
    "    # вики на проблему https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=62694614\n",
    "    # и обсуждение https://github.com/apache/airflow/issues/1017\n",
    "    dag=dag,  # говорим, что таска принадлежит дагу из переменной dag\n",
    "    env={\"DATA_INTERVAL_START\": date},  # задает переменные окружения\n",
    ")\n",
    "```\n",
    "\n",
    "`BashOperator` может понадобиться, когда у вас есть готовые shell-скрипты или shell команды, которые нужно регулярно выполнять.\n",
    "Это может быть выгрузка данных (если она идет не через Python) или очищение временных папок.\n",
    "\n",
    "### PythonOperator\n",
    "Запускает python-функцию с аргументами.\n",
    "\n",
    "[Документация](https://airflow.apache.org/docs/apache-airflow/2.2.2/howto/operator/python.html)\n",
    "\n",
    "```python\n",
    "def print_context(ds, **kwargs):\n",
    "    \"\"\"Пример PythonOperator\"\"\"\n",
    "    # Через синтаксис **kwargs можно получить словарь\n",
    "    # с настройками Airflow. Значения оттуда могут пригодиться.\n",
    "    # Пока нам не нужно\n",
    "    print(kwargs)\n",
    "    # В ds Airflow за нас подставит текущую логическую дату - строку в формате YYYY-MM-DD\n",
    "    print(ds)\n",
    "    return 'Whatever you return gets printed in the logs'\n",
    "\n",
    "run_this = PythonOperator(\n",
    "    task_id='print_the_context',  # нужен task_id, как и всем операторам\n",
    "    python_callable=print_context,  # свойственен только для PythonOperator - передаем саму функцию\n",
    ")\n",
    "```\n",
    "_Пример взят из официальной документации_.\n",
    "\n",
    "В `PythonOperator` можно попросить передавать аргументы функции при вызове:\n",
    "```python\n",
    "def my_sleeping_function(random_base):\n",
    "    \"\"\"Заснуть на random_base секунд\"\"\"\n",
    "    time.sleep(random_base)\n",
    "\n",
    "# Генерируем таски в цикле - так тоже можно\n",
    "for i in range(5):\n",
    "    # Каждый таск будет спать некое количество секунд\n",
    "    task = PythonOperator(\n",
    "        task_id='sleep_for_' + str(i),  # в id можно делать все, что разрешают строки в python\n",
    "        python_callable=my_sleeping_function,\n",
    "        # передаем в аргумент с названием random_base значение float(i) / 10\n",
    "        op_kwargs={'random_base': float(i) / 10},\n",
    "    )\n",
    "    # настраиваем зависимости между задачами\n",
    "    # run_this - это некий таск, объявленный ранее (в этом примере не объявлен)\n",
    "    run_this >> task\n",
    "```\n",
    "_Пример взят из официальной документации._\n",
    "\n",
    "Красота состоит в том, что в таски можно передавать шаблоны (например, строку `\"{{ ds }}\"`, куда Airflow подставит дату), можно использовать f-strings, вычисления из Python, использовать kwargs для приема настроек Airflow и контекста (набора параметров сервера \"здесь и сейчас\") - и с использованием всего этого писать функции с очень динамичным поведением.\n",
    "\n",
    "[Справочник по шаблонам Airflow](https://airflow.apache.org/docs/apache-airflow/stable/templates-ref.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947664ad",
   "metadata": {},
   "source": [
    "## Про даты\n",
    "В Airflow имеется _логическая_ дата (передается как `ds`). Она говорит, какую дату обрабатывает конкретный запуск.\n",
    "\n",
    "Логическая дата **не всегда** совпадает с датой запуска!\n",
    "В нормальном функционировании Airflow запускает даг после окончания логической даты, чтобы убедиться в доступности всех данных.\n",
    "\n",
    "Например, если даг настроен на ежедневный запуск, то в день 2022-02-12 даг запустится с логической датой 2022-02-11 (вчера), потому что за 12-ое число данных еще может не быть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecccd2a1",
   "metadata": {},
   "source": [
    "## Передача информации\n",
    "Бывает необходимым передать информацию от одной задачи к другой. В целом, Airflow задуман больше как _орекстратор_, а не полная платформа для контроля исполнения задач.\n",
    "Поэтому Airflow имеет только простой интерфейс передачи данных - XCom (сокращенно от Cross Communication). XCom передает данные в формате ключ-значение и предназначен для хранения **небольших** данных (примерно до 1 Гб).\n",
    "\n",
    "Если вам нужно передавать большие данные между задачами, стоит сохранять их в отдельную от Airflow базу данных, либо в некое отдельное хранилище (S3, HDFS и т.п.).\n",
    "\n",
    "### XCom\n",
    "Построен очень просто: данные можно push (положить) и pull (получать)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'https://covidtracking.com/api/v1/states/'\n",
    "state = 'wa'\n",
    "\n",
    "def get_testing_increase(state, ti):\n",
    "    \"\"\"\n",
    "    Gets totalTestResultsIncrease field from Covid API for given state and returns value\n",
    "    \"\"\"\n",
    "    res = requests.get(url + '{0}/current.json'.format(state))\n",
    "    testing_increase = json.loads(res.text)['totalTestResultsIncrease']\n",
    "    # в ti уходит task_instance, его передает Airflow под таким названием\n",
    "    # когда вызывает функцию в ходе PythonOperator\n",
    "    ti.xcom_push(\n",
    "        key='testing_increase',\n",
    "        value=testing_increase\n",
    "    )\n",
    "\n",
    "def analyze_testing_increases(state, ti):\n",
    "    \"\"\"\n",
    "    Evaluates testing increase results\n",
    "    \"\"\"\n",
    "    testing_increases = ti.xcom_pull(\n",
    "        key='testing_increase',\n",
    "        task_ids='get_testing_increase_data_{0}'.format(state)\n",
    "    )\n",
    "    print('Testing increases for {0}:'.format(state), testing_increases)\n",
    "\n",
    "# Default settings applied to all tasks\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5)\n",
    "}\n",
    "\n",
    "with DAG(\n",
    "    'xcom_dag',\n",
    "    start_date=datetime(2021, 1, 1),\n",
    "    max_active_runs=2,\n",
    "    schedule_interval=timedelta(minutes=30),\n",
    "    default_args=default_args,\n",
    "    catchup=False\n",
    ") as dag:\n",
    "    opr_get_covid_data = PythonOperator(\n",
    "        task_id = 'get_testing_increase_data_{0}'.format(state),\n",
    "        python_callable=get_testing_increase,\n",
    "        op_kwargs={'state':state}\n",
    "    )\n",
    "    opr_analyze_testing_data = PythonOperator(\n",
    "        task_id = 'analyze_data',\n",
    "        python_callable=analyze_testing_increases,\n",
    "        op_kwargs={'state':state}\n",
    "    )\n",
    "\n",
    "    opr_get_covid_data >> opr_analyze_testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b268b",
   "metadata": {},
   "source": [
    "_Пример взят с [astronomer](https://www.astronomer.io/guides/airflow-passing-data-between-tasks/)._\n",
    "\n",
    "Кстати, можно не класть явно результаты в XCom. Все, что возвращает функция, будет автоматически положено в XCom, соответствующий этой стадии (такое поведение можно убрать, если выставить в настройках `{'do_xcom_push': False}`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02068226",
   "metadata": {},
   "source": [
    "## Connections, Variables\n",
    "В Airflow есть несколько полезных вещей, которые помогают разворачивать код\n",
    "\n",
    "### Connections\n",
    "Система хранения подключений. Стоит использовать, чтобы безопасно хранить логины/пароли.\n",
    "\n",
    "```python\n",
    "from airflow.hooks.base_hook import BaseHook\n",
    "\n",
    "connection = BaseHook.get_connection(\"conn_name\")\n",
    "conn_password = connection.password\n",
    "conn_login = connection.login\n",
    "```\n",
    "\n",
    "### Variables\n",
    "Динамические переменные, которые задаются в Airflow и которые можно доставать из кода:\n",
    "\n",
    "```python\n",
    "from airflow.models import Variable\n",
    "\n",
    "is_prod = Variable.get(\"is_prod\")  # необходимо передать имя, заданное при создании Variable\n",
    "# теперь в is_prod лежит значение Variable\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536141b",
   "metadata": {},
   "source": [
    "## Best practices\n",
    "Есть несколько правил \"хорошего\" DAG.\n",
    "\n",
    "[Документация по хорошим практикам](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html#).\n",
    "\n",
    "### Идемпотентность\n",
    "Повторные перезапуски задачи в DAG за тот же день должны возвращать одинаковые результаты.\n",
    "Это не всегда просто, но выстраивать свои процессы в Airflow стоит именно так, чтобы они обладали идемпотентностью.\n",
    "\n",
    "Мотивация: задачи могут перезапускаться в следующие дни, могут случайно перезапуститься - в обоих случаях хочется, чтобы запуски выдавали одинаковые значения.\n",
    "\n",
    "### Один таск = одна законченная операция\n",
    "Стоит смотреть на задачи как на транзакцию: проведение некой атомарной операции от начала до конца.\n",
    "Таск **не** должен оставлять систему в промежуточном состоянии.\n",
    "\n",
    "### Осторожнее с `datetime.now()`\n",
    "Питоновская `datetime.now()` возвращает текущее время. Оно может отличаться от \"логического\" времени на таск и на DAG, и это неприемлимо для идемпотентности. Можно использовать, например, шаблонизированный `{{ ds }}`, в который Airflow автоматически подставит логическую дату.\n",
    "\n",
    "### Не хранить много в XCom\n",
    "XCom для хранения данных использует СУБД (ее поднимают отдельно), и эти СУБД могут быть не спроектированы для хранения больших результатов.\n",
    "К тому же, большие данные в XCom могут привести к замедлению работы Airflow. Официальная документация не рекомендует хранить большие данные в XCom.\n",
    "\n",
    "### Использовать Airflow как орекстратор\n",
    "Иногда есть соблазн обернуть все коды внутри DAG и Task в Airflow. Это кажется быстрым решением, но не стоит забывать, что Airflow все-таки _оркестратор_, а не система \"все-в-одном\".\n",
    "\n",
    "Поэтому стоит хранить код в отдельном месте, затем доставлять его на Airflow (через импорты библиотек или докер-образы) и в Airflow хранить только коды с логикой Airflow (а не вашего приложения).\n",
    "\n",
    "### Тестировать код Airflow\n",
    "Стоит относиться к коду DAG с той же серьезностью, что и к коду всего проекта. Его точно так же стоит покрывать тестами, проверять DAG на валидность, делать тестовые прогоны. \n",
    "\n",
    "[Подробнее](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "cdaf845c447f5b8a88f1bde010b8054a6111556832cc2133cdddd7f2255dae56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
